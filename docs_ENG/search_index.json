[["index.html", "Workshop Materials", " Workshop Materials In the following link, you will find the R routines developed for the workshop.. Descargar "],["installation-of-libraries-and-required-software-for-bayesian-area-models..html", "Chapter 1 Installation of Libraries and Required Software for Bayesian Area Models. ", " Chapter 1 Installation of Libraries and Required Software for Bayesian Area Models. "],["step-1-installing-software.html", "1.1 Step 1: Installing Software", " 1.1 Step 1: Installing Software Below is a list of the necessary software for the proper development of the training. It is recommended to install these packages before starting with the practical development. Download and install Rbase (https://cran.r-project.org/bin/windows/base/) Download and install Rtools (https://cran.r-project.org/bin/windows/Rtools/) Download and install Rstudio (https://posit.co/download/rstudio-desktop/) Download and install Quarto (https://quarto.org/docs/get-started/) Download and install Anaconda (https://www.anaconda.com/products/individual) Download and install Google Cloud (https://cloud.google.com/sdk/docs/install?hl=es-419) "],["step-2-installing-the-following-libraries-in-r..html", "1.2 Step 2: Installing the following libraries in R.", " 1.2 Step 2: Installing the following libraries in R. 1.2.1 Data Visualization and Manipulation: tidyverse: A collection of packages for data manipulation and visualization. magrittr: Provides a pipe %&gt;% operator to make code more readable. scales: Tools for scaling visualizations, like adjusting axis breaks. sf: For working with spatial data and maps. tmap: Creates thematic maps and overlays. 1.2.2 Statistical Modeling: lme4: Fits linear and generalized linear mixed-effects models. rstanarm: Fits Bayesian models using Stan for various statistical tasks. 1.2.3 Survey Analysis: srvyr: Tools for working with survey data alongside the dplyr package. survey: For analyzing complex survey data. 1.2.4 Data Manipulation and Transformation: dplyr: Data manipulation tools. tidyr: Tools for reshaping and tidying data. reshape2: Reshaping data frames. 1.2.5 Bayesian Analysis: bayesplot: Visualization of Bayesian models. posterior: Tools for working with posterior distributions. rstan: R interface to Stan, a platform for Bayesian modeling. 1.2.6 Geospatial Analysis: rgee: Interface to Google Earth Engine. trafo: Tools for transforming spatial data. maptools: Tools for reading and manipulating geographic data. usmap: Maps of the United States. 1.2.7 Miscellaneous: sampling: Tools for survey sampling. haven: For reading and writing SPSS, Stata, and SAS files. RColorBrewer: Provides color palettes. kableExtra: Enhances table rendering in R Markdown. formatR: Formatting tools for R code. printr: Custom printing of data frames and tables. remotes: Tools for package development and installation. latex2exp: Converts LaTeX code into expressions. To install each package, use the command install.packages(\"package_name\"). install.packages(&quot;patchwork&quot;) install.packages(&quot;lme4&quot;) install.packages(&quot;tidyverse&quot;) install.packages(&quot;rstanarm&quot;) install.packages(&quot;magrittr&quot;) install.packages(&quot;reticulate&quot;) install.packages(&quot;rgee&quot;) install.packages(&quot;sf&quot;) install.packages(&quot;tmap&quot;) install.packages(&quot;trafo&quot;) install.packages(&quot;scales&quot;) install.packages(&quot;srvyr&quot;) install.packages(&quot;survey&quot;) install.packages(&quot;haven&quot;) install.packages(&quot;sampling&quot;) install.packages(&quot;RColorBrewer&quot;) install.packages(&quot;maptools&quot;) install.packages(&quot;data.table&quot;) install.packages(&quot;forcats&quot;) install.packages(&quot;tidyr&quot;) install.packages(&quot;reshape2&quot;) install.packages(&quot;bayesplot&quot;) install.packages(&quot;posterior&quot;) install.packages(&quot;gridExtra&quot;) install.packages(&quot;ggalt&quot;) install.packages(&quot;usmap&quot;) install.packages(&quot;kableExtra&quot;) install.packages(&quot;formatR&quot;) install.packages(&quot;printr&quot;) install.packages(&quot;remotes&quot;) install.packages(&quot;latex2exp&quot;) install.packages(&quot;gtsummary&quot;) 1.2.8 Step-by-Step Guide to Install rstan Follow these steps to install the rstan package: Install Rtools (if using Windows): Download and install Rtools. Install StanHeaders: Open R or RStudio. Run the command: install.packages(\"StanHeaders\", repos = c(\"https://mc-stan.org/r-packages/\", getOption(\"repos\"))). Install rstan: Run the command: install.packages(\"rstan\", repos=c(\"https://mc-stan.org/r-packages/\", getOption(\"repos\"))). Verify the installation: Load the package using: library(rstan). Validate the installation: Run a simple model to ensure that rstan is working properly. You can use the example code provided in the documentation. Remember to follow these steps carefully to ensure a successful installation of rstan and its dependencies. "],["step-3-validation-of-installation---ensuring-proper-rstan-installation.html", "1.3 Step 3: Validation of Installation - Ensuring Proper rstan Installation", " 1.3 Step 3: Validation of Installation - Ensuring Proper rstan Installation library(rstan) library(posterior) library(bayesplot) # Example Stan code stan_code &lt;- &quot; parameters { real y[2]; } model { y[1] ~ normal(0, 1); y[2] ~ double_exponential(0, 2); } &quot; # Fit the model fit1 &lt;- stan(model_code = stan_code, iter = 10, verbose = FALSE) # Print the fit1 object print(fit1) # Further fitting and summarizing fit2 &lt;- stan(fit = fit1, iter = 10000, verbose = FALSE) summary(fit2)$summary In this section, we validate the correct installation of rstan by running a simple Bayesian model. We load the required packages, including rstan, posterior, and bayesplot. We then define a basic Stan model using the Stan code provided. We fit this model using stan() with a small number of iterations (iter = 10) to quickly verify the installation. Next, we demonstrate fitting the model further (fit2) with more iterations (iter = 10000) to show how to perform a more comprehensive analysis. The summary of the fitted model is printed using the summary() function. Make sure to evaluate this code in an R environment after installing the required packages to verify that rstan has been installed correctly and is functioning as expected. "],["step-4-creating-a-google-earth-engine-account.html", "1.4 Step 4: Creating a Google Earth Engine Account:", " 1.4 Step 4: Creating a Google Earth Engine Account: https://developers.google.com/earth-engine/datasets/ After successfully creating your account, it’s important to follow these steps to ensure everything is set up correctly: Access the provided link: https://developers.google.com/earth-engine/datasets/catalog/WHRC_biomass_tropical. Scroll down to the bottom of the page and locate the code displayed in the image below: Click on the Open in Code Editor option, which will open a new browser tab. Follow the instructions provided until you achieve the result shown in the image below: In the previous tab, find and click the Run button to obtain the outcome displayed in the image below: Note: Repeat the process as needed to ensure you achieve the desired outcome. "],["standardization-and-validation-of-available-census-data-variables.html", "Chapter 2 Standardization and Validation of Available Census Data Variables", " Chapter 2 Standardization and Validation of Available Census Data Variables In the following code set, a series of processes are carried out for data cleaning and preparation. These steps include removing objects from the workspace, loading necessary libraries, reading census data, assigning missing values based on certain conditions, and calculating descriptive statistics for numeric and character variables. Additionally, adjustments are made to character variables to ensure consistent length. The final results are summarized in a data structure and saved in files for further analysis and reference. library(tidyverse) library(data.table) library(openxlsx) library(DataExplorer) library(magrittr) library(RColorBrewer) select&lt;- dplyr::select cat(&quot;\\f&quot;) censo &lt;- readRDS(&quot;Recursos/01_Input_Validation/Data/Data_census_V2023-06-12.rds&quot;) %&gt;% select(-geometry) %&gt;% as.data.frame() # Creating a summary data frame for column names and their respective data types. resumen &lt;- data.frame(Nombre_Columna = names(censo)) resumen %&lt;&gt;% mutate(tipo = map_chr(Nombre_Columna, function(x) class(censo[[x]]))) resumen &lt;- readRDS(&quot;Recursos/01_Input_Validation/RecurseBooks/resumen1.rds&quot;) tba(head(resumen,10)) Nombre_Columna tipo un_ID integer PROV_ID character CANT_ID character DIST_ID character UGM_ID character LLAVEV character RESUL_ENTREVISTA_VIV integer TIPO_VIVIENDA_PRECENSO character V01_TIPO_VIVIENDA integer V02_OCUPACION_VIVIENDA integer "],["assigning-missing-values-to-the-h01a_total_personas-variable.html", "2.1 Assigning Missing Values to the ‘H01A_TOTAL_PERSONAS’ Variable", " 2.1 Assigning Missing Values to the ‘H01A_TOTAL_PERSONAS’ Variable In this section, actions related to the ‘H01A_TOTAL_PERSONAS’ variable are performed. Missing values (NA) are assigned to this variable based on specific conditions, which include: Dwellings that were not visited (category 9). Dwellings that rejected the visit or are pending (classification 2). Dwellings with other reasons (category 8). Next, a count of cases before and after the assignment of missing values is conducted. The ‘mutate’ function is used to create a new temporary column ‘H01A_TOTAL_PERSONAS_temp’ in which NA values are assigned according to the specified conditions. The information is then grouped by the ‘V02_OCUPACION_VIVIENDA’ variable, and the number of missing values (‘nas’) before and after the assignment is calculated, along with the total count of missing values after the assignment. Subsequently, another assignment of missing values is performed directly to the ‘H01A_TOTAL_PERSONAS’ variable within the ‘censo’ dataset. This is done following the same conditions mentioned earlier. censo %&gt;% mutate( H01A_TOTAL_PERSONAS_temp = case_when( V02_OCUPACION_VIVIENDA == &quot;9&quot; ~ NA_real_, V02_OCUPACION_VIVIENDA == &quot;2&quot; ~ NA_real_, V02_OCUPACION_VIVIENDA == &quot;8&quot; ~ NA_real_, TRUE ~ H01A_TOTAL_PERSONAS ) ) %&gt;% group_by(V02_OCUPACION_VIVIENDA) %&gt;% summarise(nas_antes = sum(is.na(H01A_TOTAL_PERSONAS)), nas_despues = sum(is.na(H01A_TOTAL_PERSONAS_temp))) %&gt;% mutate(total_nas_despues = sum(nas_despues)) ## Assignment of Missing Values censo %&lt;&gt;% mutate( H01A_TOTAL_PERSONAS = case_when( V02_OCUPACION_VIVIENDA == &quot;9&quot; ~ NA_real_, V02_OCUPACION_VIVIENDA == &quot;2&quot; ~ NA_real_, V02_OCUPACION_VIVIENDA == &quot;8&quot; ~ NA_real_, TRUE ~ H01A_TOTAL_PERSONAS ) ) "],["descriptive-values-of-the-census-data.html", "2.2 Descriptive Values of the Census Data", " 2.2 Descriptive Values of the Census Data Numeric Variables In this section, various descriptive statistics are calculated for the numeric variables within the ‘censo’ dataset. These statistics provide insights into the distribution and characteristics of the numeric data. ‘max_values’: The maximum values of numeric and integer variables are calculated using the ‘summarise’ and ‘pivot_longer’ functions. The result is a table that lists the maximum values for each variable. ‘min_values’: Similarly, the minimum values of numeric and integer variables are computed and organized into a table format. ‘media_values’: The mean (average) values of numeric and integer variables are calculated and presented in tabular form. ‘mediana_values’: The median values of numeric and integer variables are determined and displayed as a table. ‘SD_values’: Standard deviations (SD) of numeric and integer variables are computed and organized into a table structure. ‘nas_values’: The number of missing values (NAs) for each numeric and integer variable is counted and presented in tabular format. max_values &lt;- censo %&gt;% summarise(across(where(is.numeric) | where(is.integer), max)) %&gt;% pivot_longer(everything(), names_to = &quot;Nombre_Columna&quot;, values_to = &quot;Valor_Maximo&quot;) min_values &lt;- censo %&gt;% summarise(across(where(is.numeric) | where(is.integer), min)) %&gt;% pivot_longer(everything(), names_to = &quot;Nombre_Columna&quot;, values_to = &quot;Valor_Minimo&quot;) media_values &lt;- censo %&gt;% summarise(across(where(is.numeric) | where(is.integer), mean)) %&gt;% pivot_longer(everything(), names_to = &quot;Nombre_Columna&quot;, values_to = &quot;Valor_Media&quot;) mediana_values &lt;- censo %&gt;% summarise(across(where(is.numeric) | where(is.integer), median)) %&gt;% pivot_longer(everything(), names_to = &quot;Nombre_Columna&quot;, values_to = &quot;Valor_Mediana&quot;) SD_values &lt;- censo %&gt;% summarise(across(where(is.numeric) | where(is.integer), sd)) %&gt;% pivot_longer(everything(), names_to = &quot;Nombre_Columna&quot;, values_to = &quot;Valor_sd&quot;) nas_values &lt;- censo %&gt;% summarise(across(where(is.numeric) | where(is.integer), function(x)sum(is.na(x)))) %&gt;% pivot_longer(everything(), names_to = &quot;Nombre_Columna&quot;, values_to = &quot;Num_nas&quot;) Character Variables For character variables within the ‘censo’ dataset, specific descriptive statistics are generated: ‘max_char’: This table contains the maximum lengths of character variables. It calculates the maximum number of characters within each character variable. ‘min_char’: Similar to ‘max_char’, this table provides the minimum lengths of character variables. ‘nas_values_char’: This table displays the counts of missing values (NAs) for each character variable. max_char &lt;- censo %&gt;% summarise(across(where(is.character), function(x)max(nchar(x)))) %&gt;% pivot_longer(everything(), names_to = &quot;Nombre_Columna&quot;, values_to = &quot;leng_max&quot;) min_char &lt;- censo %&gt;% summarise(across(where(is.character), function(x)min(nchar(x)))) %&gt;% pivot_longer(everything(), names_to = &quot;Nombre_Columna&quot;, values_to = &quot;leng_min&quot;) nas_values_char &lt;- censo %&gt;% summarise(across(where(is.character) , function(x)sum(is.na(x)))) %&gt;% pivot_longer(everything(), names_to = &quot;Nombre_Columna&quot;, values_to = &quot;Num_nas_char&quot;) "],["organizing-results-in-a-database.html", "2.3 Organizing Results in a Database", " 2.3 Organizing Results in a Database In this section, the collected descriptive statistics are organized and combined into a comprehensive summary database named ‘resumen2’. To achieve this, the ‘reduce’ function is used with a list of tables containing the various statistics. The tables include statistics related to character variables (‘nas_values_char’, ‘min_char’, ‘max_char’), numeric variables (‘nas_values’, ‘SD_values’, ‘mediana_values’, ‘media_values’, ‘min_values’, ‘max_values’), and a table that holds information about variable names and types (‘resumen’). The ‘full_join’ function is applied iteratively using ‘reduce’ to combine all these tables together. The ‘by’ parameter specifies that the join should be performed based on the ‘Nombre_Columna’ (Column Name) variable, ensuring that the statistics for each variable are correctly matched and aligned. The final result is the ‘resumen2’ database, which provides a consolidated view of descriptive statistics for each variable in the ‘censo’ dataset, incorporating information about NAs, minimums, maximums, standard deviations, medians, means, and more. resumen2 &lt;- reduce( list( nas_values_char, min_char, max_char, nas_values, SD_values, mediana_values, media_values, min_values, max_values ), full_join, by = join_by(Nombre_Columna) ) %&gt;% full_join(x = resumen, y = ., by = join_by(Nombre_Columna)) # save data openxlsx::write.xlsx(resumen2, file = &quot;Recursos/01_Input_Validation/Data/Estado_base.xlsx&quot;) openxlsx::openXL(&quot;Recursos/01_Input_Validation/Data/Estado_base.xlsx&quot;) Nombre_Columna tipo Num_nas_char leng_min leng_max Num_nas Valor_sd Valor_Mediana Valor_Media Valor_Minimo Valor_Maximo un_ID integer NA NA NA 0 503230.4746 871621 871621.0000 1 1743241 PROV_ID character 0 1 1 NA NA NA NA NA NA CANT_ID character 0 3 3 NA NA NA NA NA NA DIST_ID character 0 5 5 NA NA NA NA NA NA UGM_ID character 0 8 8 NA NA NA NA NA NA LLAVEV character 0 1 14 NA NA NA NA NA NA RESUL_ENTREVISTA_VIV integer NA NA NA 0 1.5899 1 2.2408 1 5 TIPO_VIVIENDA_PRECENSO character 0 1 22 NA NA NA NA NA NA V01_TIPO_VIVIENDA integer NA NA NA 0 4.6571 1 2.9378 1 15 V02_OCUPACION_VIVIENDA integer NA NA NA 0 2.8114 2 2.9311 1 9 "],["updating-the-dataset-based-on-report-results.html", "2.4 Updating the Dataset Based on Report Results", " 2.4 Updating the Dataset Based on Report Results In this part of the code, the ‘censo’ dataset is updated based on the results obtained from the report. First, the ‘Nombre_Columna’ vector is defined, which contains the names of the columns to be updated. Next, the ‘Tipo_actualizar’ vector is defined, which contains the type conversion functions to be applied to each corresponding column. Using the ‘map2’ function from the ‘purrr’ package, each pair of elements in ‘Nombre_Columna’ and ‘Tipo_actualizar’ is iterated over, applying the respective type conversion function to each column in the ‘censo’ dataset. This is achieved using the ‘&lt;&lt;-’ function to update values in the original dataset. Finally, a new dataset ‘censo2’ is created that only contains the columns specified in ‘Nombre_Columna’. This ensures that the dataset is updated according to the data types and modifications made based on the report results. Nombre_Columna &lt;- c( &quot;un_ID&quot; , &quot;PROV_ID&quot; , &quot;CANT_ID&quot; , &quot;DIST_ID&quot; , &quot;UGM_ID&quot; , &quot;LLAVEV&quot; , &quot;RESUL_ENTREVISTA_VIV&quot; , &quot;TIPO_VIVIENDA_PRECENSO&quot; , &quot;V01_TIPO_VIVIENDA&quot; , &quot;V02_OCUPACION_VIVIENDA&quot; , &quot;H01A_TOTAL_PERSONAS&quot; , &quot;greenpoint&quot; , &quot;ugm_viviendas_totales_censo&quot; , &quot;ugm_viviendas_ocupadas_censo&quot; , &quot;ugm_viviendas_desocupadas_censo&quot; , &quot;ugm_peligrosidad&quot; , &quot;ugm_problema_de_acceso&quot; , &quot;ugm_riesgos_amenazas&quot; , &quot;ugm_cobertura_telecomunicaciones&quot; , &quot;asent&quot; , &quot;ppp_CRI_v2&quot; , &quot;elev&quot; , &quot;indig&quot; , &quot;aprot&quot; , &quot;dist_permisos_de_construccion_2011_2022&quot; , &quot;dist_poblacion_proyeccion_ajustada_2022&quot; , &quot;dist_poblacion_ccss_abril_2023&quot; , &quot;dist_matricula_educacion_primaria_2021&quot; , &quot;dist_codigo_urbanidad&quot; , &quot;GHS_BUILT_S_E2020_GLOBE_R2023A_5367_CRI&quot; , &quot;urban_coverfraction&quot; , &quot;crops_coverfraction&quot; , &quot;ebais_tt&quot; , &quot;escu_tt&quot; , &quot;igl_tt&quot; , &quot;prov_nl_mean&quot; , &quot;cant_nl_mean&quot; , &quot;dist_nl_mean&quot; , &quot;wpop_sum&quot; ) Tipo_actualizar &lt;- c( as.character, as.character, as.character, as.character, as.character, as.character, as.character, as.character, as.character, as.character, as.numeric, as.character, as.numeric, as.numeric, as.numeric, as.character, as.character, as.character, as.character, as.character, as.numeric, as.numeric, as.character, as.character, as.numeric, as.numeric, as.numeric, as.numeric, as.character, as.numeric, as.numeric, as.numeric, as.numeric, as.numeric, as.numeric, as.numeric, as.numeric, as.numeric, as.numeric) map2(Nombre_Columna, Tipo_actualizar, function(nom,tipo){ censo[[nom]] &lt;&lt;- tipo(censo[[nom]]) }) # Selecting columns specified in &#39;Nombre_Columna&#39; censo2 &lt;- censo %&gt;% select(all_of(Nombre_Columna)) "],["dataset-refinement-and-analysis.html", "2.5 Dataset Refinement and Analysis", " 2.5 Dataset Refinement and Analysis In this section, the ‘censo’ dataset is refined further, and some descriptive analyses are conducted on the updated dataset. Additionally, the results of these analyses are saved in the specified directory. Summary of variables censo2 %&gt;% distinct(UGM_ID, wpop_sum) %&gt;% summarise(n = sum(wpop_sum)) %&gt;% tba() n 4653649 Count of ugm_viviendas_totales_censo == 0 censo2 %&gt;% distinct(UGM_ID, ugm_viviendas_totales_censo) %&gt;% mutate(categoria = cut(ugm_viviendas_totales_censo, breaks = c(-1:5, 10, 20, 50, max(ugm_viviendas_totales_censo) ))) %&gt;% group_by(categoria) %&gt;% tally() %&gt;% tba() categoria n (-1,0] 3744 (0,1] 1760 (1,2] 1441 (2,3] 1446 (3,4] 1412 (4,5] 1527 (5,10] 7317 (10,20] 11660 (20,50] 12516 (50,285] 5170 Comparing with the number of records per UGM ugm_cero_viviendas &lt;- censo2 %&gt;% distinct(UGM_ID, ugm_viviendas_totales_censo) %&gt;% filter(ugm_viviendas_totales_censo == 0) cont_registros_ugm &lt;- censo2 %&gt;% group_by(UGM_ID) %&gt;% tally(name = &quot;Total_vivienda_ugm&quot;) inner_join(ugm_cero_viviendas, cont_registros_ugm) %&gt;% summarise(n_ugm = n(), min = min(Total_vivienda_ugm), max = max(Total_vivienda_ugm), mediana = median(Total_vivienda_ugm)) %&gt;% tba() n_ugm min max mediana 3744 1 207 12 Summary of variables for specific condition censo2 %&gt;% filter(V02_OCUPACION_VIVIENDA == &quot;8&quot;) %&gt;% summarise(n_viviendas = n(), min = min(H01A_TOTAL_PERSONAS), max = max(H01A_TOTAL_PERSONAS), mediana = median(H01A_TOTAL_PERSONAS)) %&gt;% tba() n_viviendas min max mediana 74871 0 0 0 "],["summary-and-analysis-of-data.html", "2.6 Summary and Analysis of Data", " 2.6 Summary and Analysis of Data In this section, we are summarizing and analyzing the data in order to gain insights. We will calculate different measures to understand the characteristics of the variables. Creating a summary of the column names and their data types resumen &lt;- data.frame(Nombre_Columna = names(censo2)) resumen %&lt;&gt;% mutate(tipo = map_chr(Nombre_Columna, function(x)class(censo2[[x]]))) Checking for character variables and ensuring consistent character length tipo_char &lt;- resumen$Nombre_Columna[resumen$tipo == &quot;character&quot;] for(ii in tipo_char) { max_char &lt;- max(nchar(censo2[[ii]])) censo2[[ii]] &lt;- str_pad(string = censo2[[ii]], width = max_char, pad = &quot;0&quot;) } Summarizing character variables max_char &lt;- censo2 %&gt;% summarise(across(where(is.character), function(x)max(nchar(x)))) %&gt;% pivot_longer(everything(), names_to = &quot;Nombre_Columna&quot;, values_to = &quot;leng_max&quot;) min_char &lt;- censo2 %&gt;% summarise(across(where(is.character), function(x)min(nchar(x)))) %&gt;% pivot_longer(everything(), names_to = &quot;Nombre_Columna&quot;, values_to = &quot;leng_min&quot;) nas_values_char &lt;- censo2 %&gt;% summarise(across(where(is.character) , function(x)sum(is.na(x)))) %&gt;% pivot_longer(everything(), names_to = &quot;Nombre_Columna&quot;, values_to = &quot;Num_nas_char&quot;) Summarizing numeric variables max_values &lt;- censo2 %&gt;% summarise(across(where(is.numeric) | where(is.integer), max)) %&gt;% pivot_longer(everything(), names_to = &quot;Nombre_Columna&quot;, values_to = &quot;Valor_Maximo&quot;) min_values &lt;- censo2 %&gt;% summarise(across(where(is.numeric) | where(is.integer), min)) %&gt;% pivot_longer(everything(), names_to = &quot;Nombre_Columna&quot;, values_to = &quot;Valor_Minimo&quot;) media_values &lt;- censo2 %&gt;% summarise(across(where(is.numeric) | where(is.integer), mean)) %&gt;% pivot_longer(everything(), names_to = &quot;Nombre_Columna&quot;, values_to = &quot;Valor_Media&quot;) mediana_values &lt;- censo2 %&gt;% summarise(across(where(is.numeric) | where(is.integer), median)) %&gt;% pivot_longer(everything(), names_to = &quot;Nombre_Columna&quot;, values_to = &quot;Valor_Mediana&quot;) SD_values &lt;- censo2 %&gt;% summarise(across(where(is.numeric) | where(is.integer), sd)) %&gt;% pivot_longer(everything(), names_to = &quot;Nombre_Columna&quot;, values_to = &quot;Valor_sd&quot;) nas_values &lt;- censo2 %&gt;% summarise(across(where(is.numeric) | where(is.integer), function(x)sum(is.na(x)))) %&gt;% pivot_longer(everything(), names_to = &quot;Nombre_Columna&quot;, values_to = &quot;Num_nas&quot;) Combining all the summary information resumen2 &lt;- reduce( list(nas_values_char, min_char, max_char, nas_values, SD_values, mediana_values, media_values, min_values, max_values), full_join, by = join_by(Nombre_Columna)) %&gt;% full_join(x = resumen, y = ., by = join_by(Nombre_Columna)) Saving the summary results to an Excel file openxlsx::write.xlsx(resumen2, file = &quot;Recursos/01_Input_Validation/Data/Estado_base_despues.xlsx&quot;) Saving the standardized dataset saveRDS(censo2, file = &quot;Recursos/01_Input_Validation/Data/censo_estandarizado.rds&quot;) In this code block, we are creating summaries of the dataset variables to understand their characteristics. We are calculating different measures for both character and numeric variables, such as maximum, minimum, mean, median, and standard deviation. Additionally, we are counting missing values for character variables. "],["filtering-and-refining-census-data.html", "Chapter 3 Filtering and Refining Census Data", " Chapter 3 Filtering and Refining Census Data In the process of enhancing and purifying census database, it is imperative to establish consistent and replicable rules. In this context, the procedure of “Census Data Filtering and Refinement” becomes essential in improving data quality and eliminating irrelevant information. Throughout the following code blocks, we will explore how diverse filters and refinement techniques were applied to census data. These codes will guide us through a crucial process to ensure that the data is reliable and suitable for further analysis. Collectively, these steps will empower us to obtain more precise and valuable insights from census data. "],["reading-libraries-databases-and-other-inputs.html", "3.1 Reading Libraries, Databases, and Other Inputs", " 3.1 Reading Libraries, Databases, and Other Inputs In this section, we start by loading the necessary libraries used throughout the processing. Additionally, we define the columns that will be retained after applying the filters. We also make necessary adjustments to the databases, considering updates in the UGM codes. # Load necessary libraries library(tidyverse) # For data manipulation and visualization library(data.table) # For efficient data handling library(openxlsx) # For reading/writing Excel files library(magrittr) # For pipe operators select &lt;- dplyr::select # Alias for dplyr&#39;s select function cat(&quot;\\f&quot;) # Clear console output ## Census data reading ## Selection of columns of interest in the census. Nombre_Columna &lt;- c( &quot;un_ID&quot; , &quot;PROV_ID&quot; , &quot;CANT_ID&quot; , &quot;DIST_ID&quot; , &quot;UGM_ID&quot; , &quot;LLAVEV&quot; , &quot;V01_TIPO_VIVIENDA&quot; , &quot;V02_OCUPACION_VIVIENDA&quot; , &quot;H01A_TOTAL_PERSONAS&quot; , &quot;greenpoint2&quot;, &quot;Filters&quot; ) Reading Housing Data without Coordinates. In this section, we read the housing data from a CSV file that does not include coordinates. We then transform the data into the required format, including variables such as province ID, canton ID, and district ID based on the given codes. The resulting dataset will be used for further analysis and processing. Viviendas_sin_coordenadas &lt;- read_csv2(&quot;Recursos/02_Census_Filters/Data/Viviendas sin coordenadas.csv&quot;) # Transmute data to required format Viviendas_sin_coordenadas %&lt;&gt;% transmute( LLAVEV, PROV_ID = str_sub(CODIGO_PCD, 1,1), CANT_ID = str_sub(CODIGO_PCD, 1,3), DIST_ID = as.character(CODIGO_PCD), UGM_ID = paste0(CODIGO_PCD , ID_UGM), H01A_TOTAL_PERSONAS = H01A_TOTAL_RESIDENTES_HAB) Changing UGM Codes in the Housing Data. In this section, we modify the UGM (Urban Geographic Micro-data) codes in the housing data to ensure consistency and accuracy. Certain UGM codes are updated according to predefined mappings. This step is crucial for maintaining uniformity in the data for subsequent analysis. Viviendas_sin_coordenadas %&lt;&gt;% mutate(UGM_ID = case_when( UGM_ID == &quot;10108228&quot; ~ &quot;10108158&quot;, UGM_ID == &quot;10805037&quot; ~ &quot;10807037&quot;, UGM_ID == &quot;11803124&quot; ~ &quot;11803024&quot;, UGM_ID == &quot;11803150&quot; ~ &quot;11803050&quot;, UGM_ID == &quot;11803151&quot; ~ &quot;11803051&quot;, UGM_ID == &quot;20302131&quot; ~ &quot;20302031&quot;, UGM_ID == &quot;21305106&quot; ~ &quot;21305006&quot;, UGM_ID == &quot;30101232&quot; ~ &quot;30101132&quot;, UGM_ID == &quot;30201354&quot; ~ &quot;30201254&quot;, UGM_ID == &quot;30302158&quot; ~ &quot;30302133&quot;, UGM_ID == &quot;30305186&quot; ~ &quot;30305086&quot;, TRUE ~UGM_ID )) Read the Standardized Census Data. In this section, we read the standardized census data from a stored RDS (R Data Serialization) file. Similar to the previous step, we adjust the UGM codes to maintain data consistency. The standardized census data will serve as the foundation for the subsequent filtering and refinement processes. censo1 &lt;- readRDS(&quot;Recursos/02_Census_Filters/Data/censo_estandarizado.rds&quot;) %&gt;% mutate(UGM_ID = case_when( UGM_ID == &quot;10108228&quot; ~ &quot;10108158&quot;, UGM_ID == &quot;10805037&quot; ~ &quot;10807037&quot;, UGM_ID == &quot;11803124&quot; ~ &quot;11803024&quot;, UGM_ID == &quot;11803150&quot; ~ &quot;11803050&quot;, UGM_ID == &quot;11803151&quot; ~ &quot;11803051&quot;, UGM_ID == &quot;20302131&quot; ~ &quot;20302031&quot;, UGM_ID == &quot;21305106&quot; ~ &quot;21305006&quot;, UGM_ID == &quot;30101232&quot; ~ &quot;30101132&quot;, UGM_ID == &quot;30201354&quot; ~ &quot;30201254&quot;, UGM_ID == &quot;30302158&quot; ~ &quot;30302133&quot;, UGM_ID == &quot;30305186&quot; ~ &quot;30305086&quot;, TRUE ~UGM_ID )) Adding the Age-Sex Base. In this section, we incorporate the age-sex base into the analysis. The age-sex base is read from a stored RDS file. As in previous steps, we ensure consistency by adjusting the UGM codes. The age-sex base provides valuable demographic information and will be utilized in the subsequent filtering and refinement procedures. censo_sexo_edad &lt;- readRDS(&quot;Recursos/02_Census_Filters/Data/Censo con grupos por sexo.rds&quot;) %&gt;% select(-H01A_TOTAL_PERSONAS ) %&gt;% mutate(UGM_ID = case_when( UGM_ID == &quot;10108228&quot; ~ &quot;10108158&quot;, UGM_ID == &quot;10805037&quot; ~ &quot;10807037&quot;, UGM_ID == &quot;11803124&quot; ~ &quot;11803024&quot;, UGM_ID == &quot;11803150&quot; ~ &quot;11803050&quot;, UGM_ID == &quot;11803151&quot; ~ &quot;11803051&quot;, UGM_ID == &quot;20302131&quot; ~ &quot;20302031&quot;, UGM_ID == &quot;21305106&quot; ~ &quot;21305006&quot;, UGM_ID == &quot;30101232&quot; ~ &quot;30101132&quot;, UGM_ID == &quot;30201354&quot; ~ &quot;30201254&quot;, UGM_ID == &quot;30302158&quot; ~ &quot;30302133&quot;, UGM_ID == &quot;30305186&quot; ~ &quot;30305086&quot;, TRUE ~UGM_ID )) 3.1.1 Inner Join to Add the Age-Sex Base In this section, an inner join operation is performed to integrate the age-sex base with the census data. The difference in row count between the two bases corresponds to paper-censused households that are included later in the process. The number of rows in the age-sex base is compared to the census data and the housing data without coordinates to verify the match. ## The difference between the bases corresponds to paper-censused households ## that are included later nrow(censo_sexo_edad) - nrow(censo1) nrow(Viviendas_sin_coordenadas) ## Inner join to add the age-sex base censo1 &lt;- inner_join( censo1, censo_sexo_edad, join_by( un_ID, PROV_ID, CANT_ID, DIST_ID, UGM_ID, LLAVEV, V01_TIPO_VIVIENDA, V02_OCUPACION_VIVIENDA ) ) The code begins by calculating the difference in row count between the age-sex base (censo_sexo_edad) and the existing census data (censo1). This difference represents the number of paper-censused households that are not yet included in the census data. Additionally, the number of rows in the housing data without coordinates (Viviendas_sin_coordenadas) is determined for reference. The inner_join operation is then applied to merge the age-sex base with the census data. The join_by function specifies the columns used for the join operation, ensuring a comprehensive integration of data from both sources. This process enhances the dataset by incorporating important demographic information for further analysis. "],["applying-filters-and-analyzing-the-data.html", "3.2 Applying filters and analyzing the data", " 3.2 Applying filters and analyzing the data In this section, we’ll walk through the process of applying various filters and performing data analysis on the refined census data. 3.2.1 Applying the first filter: categorizing households with residents and determining greenpoint status In this code block, we introduce the first filter by categorizing households as having residents (&#39;si&#39;) or being empty (&#39;no&#39;) based on the total number of residents in each household. Additionally, we determine the greenpoint status of each household, considering whether the greenpoint value is &#39;0&#39; and the &#39;personas&#39; value is &#39;si&#39;. The &#39;greenpoint&#39; column is updated accordingly. # Create &#39;personas&#39; column to categorize households with or without residents censo1 %&lt;&gt;% mutate(personas = if_else(H01A_TOTAL_PERSONAS &gt; 0, &quot;si&quot;, &quot;no&quot;)) # Assign greenpoint status based on conditions censo1 %&lt;&gt;% mutate(greenpoint = if_else(greenpoint == &quot;0&quot; &amp; personas == &quot;si&quot;, &quot;1&quot;, greenpoint)) greenpoint: The house is reported as censused on the point map Analyzing the greenpoint distribution This code calculates the distribution of greenpoint status among households. It groups the data by ‘greenpoint’ status, counts the number of households in each category, and computes the percentage distribution. The results provide insights into the prevalence of greenpoint status among the census data. greenpoint_distribution &lt;- censo1 %&gt;% group_by(greenpoint) %&gt;% tally() %&gt;% # Counting households with and without greenpoint mutate(percentage = 100 * n / sum(n)) # Calculating the percentage of each category greenpoint_distribution greenpoint n percentage 0 471456 27.0448 1 1053477 60.4321 NA 218308 12.5231 Summarizing household characteristics by greenpoint status This code block summarizes household characteristics based on their greenpoint status. It calculates minimum and maximum numbers of residents in households, counts missing values for the total number of residents, and provides the total count of households for each greenpoint category. household_summary &lt;- censo1 %&gt;% group_by(greenpoint) %&gt;% summarise(min = min(H01A_TOTAL_PERSONAS), # Minimum number of residents in households max = max(H01A_TOTAL_PERSONAS), # Maximum number of residents in households num_na = sum(is.na(H01A_TOTAL_PERSONAS)), # Number of missing values for the total number of residents total = n()) # Total number of households household_summary greenpoint min max num_na total 0 0 0 0 471456 1 0 261 0 1053477 NA NA NA 218308 218308 Creating a contingency table for occupancy and greenpoint status Here, a contingency table is generated to explore the relationship between occupancy and greenpoint status. The table cross-tabulates the ‘V02_OCUPACION_VIVIENDA’ column (occupancy) with the ‘greenpoint’ column, accounting for missing values as well. This provides a visual representation of how these two variables are distributed among households. occupancy_greenpoint_table &lt;- table(censo1$V02_OCUPACION_VIVIENDA, censo1$greenpoint, useNA = &quot;a&quot;) occupancy_greenpoint_table 0 1 NA 1 0 772625 0 2 471456 3853 0 3 0 92465 0 4 0 31187 0 5 0 52463 0 6 0 23845 0 7 0 2168 0 8 0 74871 0 9 0 0 218308 NA 0 0 0 Applying the Second Filter and Refinement Continuing with the refinement process, the next filter is applied to further categorize households based on additional criteria. censo2 &lt;- censo1 %&gt;% mutate(greenpoint2 = case_when( H01A_TOTAL_PERSONAS &gt; 0 ~ &quot;Censado con informacion n&gt;0&quot;, RESUL_ENTREVISTA_VIV %in% c(1) &amp; H01A_TOTAL_PERSONAS == 0 ~ &quot;Censado con informacion n=0&quot;, RESUL_ENTREVISTA_VIV %in% c(3,4) ~ &quot;Sin informacion pero n&gt;0&quot;, is.na(greenpoint) &amp; is.na(personas) ~ &quot;Sin informacion pero n&gt;=0&quot;, V02_OCUPACION_VIVIENDA == &quot;8&quot; ~ &quot;Sin informacion pero n&gt;=0&quot;, TRUE ~ &quot;Resto&quot; )) We introduce the “greenpoint2” status to further categorize households based on various conditions. This is based on a combination of factors such as the number of residents, interview outcomes, and housing occupation. Each household is assigned to a specific category such as “Censado con informacion n&gt;0”, “Censado con informacion n=0”, and “Sin informacion pero n&gt;0”, among others. This provides a more detailed way to describe the status of households based on different criteria. readRDS(&quot;Recursos/02_Census_Filters/RecurseBooks/census2.rds&quot;) %&gt;% head(10) %&gt;% tba() 3.2.2 Applying the second filter: WorldPop criterion Starting from step 1, we also include all households with the WorldPop variable (WP) that are within 1 standard deviation from its average value. However, if these households have zero residents in the variable of interest, we mark that variable as “Not Available” (NA). Calculate summary statistics for the ‘wpop_sum’ variable Firstly, we calculate summary statistics for the ‘wpop_sum’ variable, which is a covariate related to WorldPop. The summary statistics include the mean, standard deviation, minimum, and maximum values of ‘wpop_sum’. These statistics help us establish the thresholds for the filter and are saved in a summary file. wpop_summary &lt;- censo2 %&gt;% distinct(UGM_ID,wpop_sum) %&gt;% summarise(media = mean(wpop_sum), # Mean value of &#39;wpop_sum&#39; sd = sd(wpop_sum), # Standard deviation of &#39;wpop_sum&#39; min = min(wpop_sum), # Minimum value of &#39;wpop_sum&#39; max = max(wpop_sum)) # Maximum value of &#39;wpop_sum&#39; wpop_summary media sd min max 96.9652 143.1986 0 6214.269 Calculation of Lower and Upper Thresholds We use the summary statistics to calculate the lower and upper thresholds based on one standard deviation from the mean. These thresholds will help us identify households that meet the criteria of the second filter. # Calculate the lower and upper thresholds based on one standard deviation from the mean li &lt;- 96.96515 - 143.1986 * 1 # Lower threshold ls &lt;- 96.96515 + 143.1986 * 1 # Upper threshold We identify and count households that meet the criteria of the second filter. We focus on households with zero residents (‘H01A_TOTAL_PERSONAS’) but have ‘wpop_sum’ values outside the calculated threshold. We perform this count and group it by the ‘V02_OCUPACION_VIVIENDA’ variable. # Identify and count households that meet the criteria for the second filter filter_2_counts &lt;- censo2 %&gt;% filter(H01A_TOTAL_PERSONAS == 0, wpop_sum &gt; ls | wpop_sum &lt; li) %&gt;% group_by(V02_OCUPACION_VIVIENDA) %&gt;% summarise(n = n()) filter_2_counts V02_OCUPACION_VIVIENDA n 2 129652 3 22968 4 8210 5 10514 6 4635 7 532 8 17160 Application of the Second Filter and Column Updates We apply the second filter to households and update the ‘greenpoint2’ and ‘Filtros’ columns accordingly. The ‘greenpoint2’ column is updated to reflect the new classification based on the WorldPop Criterion, while the ‘Filtros’ column indicates the application of the WorldPop Criterion or is set as NA as appropriate. # Apply the second filter and update &#39;greenpoint2&#39; and &#39;Filtros&#39; columns censo3 &lt;- censo2 %&gt;% mutate( greenpoint2 = case_when( H01A_TOTAL_PERSONAS == 0 &amp; (wpop_sum &gt; ls | wpop_sum &lt; li) ~ &quot;Sin informacion pero n&gt;=0&quot;, TRUE ~ greenpoint2 ), Filtros = case_when( H01A_TOTAL_PERSONAS == 0 &amp; (wpop_sum &gt; ls | wpop_sum &lt; li) ~ &quot;Criterio WorldPop&quot;, TRUE ~ NA_character_ ) ) un_ID PROV_ID CANT_ID DIST_ID UGM_ID LLAVEV RESUL_ENTREVISTA_VIV TIPO_VIVIENDA_PRECENSO V01_TIPO_VIVIENDA V02_OCUPACION_VIVIENDA H01A_TOTAL_PERSONAS greenpoint ugm_viviendas_totales_censo ugm_viviendas_ocupadas_censo ugm_viviendas_desocupadas_censo ugm_peligrosidad ugm_problema_de_acceso ugm_riesgos_amenazas ugm_cobertura_telecomunicaciones asent ppp_CRI_v2 elev indig aprot dist_permisos_de_construccion_2011_2022 dist_poblacion_proyeccion_ajustada_2022 dist_poblacion_ccss_abril_2023 dist_matricula_educacion_primaria_2021 dist_codigo_urbanidad GHS_BUILT_S_E2020_GLOBE_R2023A_5367_CRI urban_coverfraction crops_coverfraction ebais_tt escu_tt igl_tt prov_nl_mean cant_nl_mean dist_nl_mean wpop_sum HOMBRES_GRUPO1_sum HOMBRES_GRUPO2_sum HOMBRES_GRUPO3_sum HOMBRES_GRUPO4_sum HOMBRES_GRUPO5_sum HOMBRES_GRUPO6_sum HOMBRES_GRUPO7_sum HOMBRES_GRUPO8_sum HOMBRES_GRUPO9_sum HOMBRES_GRUPO10_sum HOMBRES_GRUPO11_sum HOMBRES_GRUPO12_sum HOMBRES_GRUPO13_sum HOMBRES_GRUPO14_sum HOMBRES_GRUPO15_sum HOMBRES_GRUPO16_sum HOMBRES_GRUPO17_sum HOMBRES_GRUPO18_sum HOMBRES_GRUPO19_sum HOMBRES_GRUPO20_sum MUJERES_GRUPO1_sum MUJERES_GRUPO2_sum MUJERES_GRUPO3_sum MUJERES_GRUPO4_sum MUJERES_GRUPO5_sum MUJERES_GRUPO6_sum MUJERES_GRUPO7_sum MUJERES_GRUPO8_sum MUJERES_GRUPO9_sum MUJERES_GRUPO10_sum MUJERES_GRUPO11_sum MUJERES_GRUPO12_sum MUJERES_GRUPO13_sum MUJERES_GRUPO14_sum MUJERES_GRUPO15_sum MUJERES_GRUPO16_sum MUJERES_GRUPO17_sum MUJERES_GRUPO18_sum MUJERES_GRUPO19_sum MUJERES_GRUPO20_sum personas greenpoint2 Filtros 0218491 1 101 10101 10101001 10101001001001 3 VIVIENDA EN APARTAMENT 01 2 0 0 0 0 0 2 2 2 1 0 17.4872 1157.488 0 0 413 3233 14597 1374 1 3773 100 0 44.0027 0 0.9933 10.802 62.9502 63 34.5930 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 no Sin informacion pero n&gt;0 NA 0141265 1 101 10101 10101002 10101001002001 1 VIVIENDA EN APARTAMENT 01 1 6 1 2 2 0 2 2 2 1 0 17.5313 1156.738 0 0 413 3233 14597 1374 1 4907 100 0 44.0000 0 0.0000 10.802 62.9502 63 9.4928 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 2 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 si Censado con informacion n&gt;0 NA 0151378 1 101 10101 10101002 10101001002002 1 VIVIENDA INDEPENDIENTE 01 1 3 1 2 2 0 2 2 2 1 0 17.5313 1158.038 0 0 413 3233 14597 1374 1 4907 100 0 44.9932 0 0.0000 10.802 62.9502 63 9.4928 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 si Censado con informacion n&gt;0 NA 0218056 1 101 10101 10101003 10101001003006 3 00VIVIENDA EN EDIFICIO 01 2 0 0 5 0 5 2 2 2 1 0 15.9573 1152.401 0 0 413 3233 14597 1374 1 4794 100 0 44.9932 0 0.0000 10.802 62.9502 63 13.1767 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 no Sin informacion pero n&gt;0 NA 0217145 1 101 10101 10101003 10101001003005 1 VIVIENDA INDEPENDIENTE 09 3 0 1 5 0 5 2 2 2 1 0 15.9573 1156.873 0 0 413 3233 14597 1374 1 4794 100 0 45.0000 0 0.9960 10.802 62.9502 63 13.1767 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 no Censado con informacion n=0 NA 0216224 1 101 10101 10101003 10101001003003 1 VIVIENDA INDEPENDIENTE 01 3 0 1 5 0 5 2 2 2 1 0 15.8496 1157.138 0 0 413 3233 14597 1374 1 3604 100 0 44.0027 0 0.9933 10.802 62.9502 63 13.1767 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 no Censado con informacion n=0 NA 0215255 1 101 10101 10101003 10101001003001 1 VIVIENDA EN APARTAMENT 01 3 0 1 5 0 5 2 2 2 1 0 15.8496 1157.801 0 0 413 3233 14597 1374 1 4794 100 0 44.0027 0 1.0000 10.802 62.9502 63 13.1767 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 no Censado con informacion n=0 NA 0215972 1 101 10101 10101003 10101001003002 1 VIVIENDA INDEPENDIENTE 01 3 0 1 5 0 5 2 2 2 1 0 15.8496 1157.138 0 0 413 3233 14597 1374 1 3604 100 0 44.0027 0 0.9933 10.802 62.9502 63 13.1767 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 no Censado con informacion n=0 NA 0216229 1 101 10101 10101003 10101001003004 1 VIVIENDA INDEPENDIENTE 01 3 0 1 5 0 5 2 2 2 1 0 15.8496 1157.138 0 0 413 3233 14597 1374 1 3604 100 0 44.0027 0 0.9933 10.802 62.9502 63 13.1767 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 no Censado con informacion n=0 NA 0925743 1 101 10101 10101004 10101001004002 3 VIVIENDA INDEPENDIENTE 04 2 0 0 1 0 1 2 2 2 1 0 17.4872 1158.147 0 0 413 3233 14597 1374 1 3773 100 0 44.0000 0 0.0027 10.802 62.9502 63 13.6008 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 no Sin informacion pero n&gt;0 NA Summary of Data Based on ‘greenpoint2’ We summarize the data based on the updated ‘greenpoint2’ variable. We calculate the distribution and percentages of households in each ‘greenpoint2’ category. These summaries help us understand the impact of the filter on household classification. # Summarizing the data based on the &#39;greenpoint2&#39; variable summary_greenpoint2 &lt;- censo3 %&gt;% group_by(greenpoint2) %&gt;% tally() %&gt;% mutate(percentage = 100 * n / sum(n)) summary_greenpoint2 greenpoint2 n percentage Censado con informacion n=0 175921 10.0916 Censado con informacion n&gt;0 776478 44.5422 Sin informacion pero n&gt;0 285810 16.3953 Sin informacion pero n&gt;=0 505032 28.9709 Summary of Data Based on ‘greenpoint2’ and ‘Filtros’ We generate an additional summary that considers the combination of the ‘greenpoint2’ and ‘Filtros’ variables. This provides more detailed information on how the WorldPop Criterion affects the existing categories. # Summarizing the data based on the combination of &#39;greenpoint2&#39; and &#39;Filtros&#39; variables summary_greenpoint2_filtros &lt;- censo3 %&gt;% group_by(greenpoint2, Filtros) %&gt;% tally() %&gt;% mutate(percentage = 100 * n / sum(n)) summary_greenpoint2_filtros greenpoint2 Filtros n percentage Censado con informacion n=0 Entrevista igual a 1 y Número de personas igual a 0 175921 10.0916 Censado con informacion n&gt;0 Número de personas mayor a 0 776478 44.5422 Sin informacion pero n&gt;0 Entrevista es 3 o 4 285810 16.3953 Sin informacion pero n&gt;=0 Criterio WorldPop 135370 7.7654 Sin informacion pero n&gt;=0 Fuera de periodo(20 días) 151354 8.6823 Sin informacion pero n&gt;=0 Sin conteo de personas 218308 12.5231 3.2.3 Summary of Statistics Based on ‘greenpoint2’ We calculate additional statistics for the ‘greenpoint2’ categories. These statistics include the minimum, maximum, number of missing values, and the total number of households in each category. This data is essential for understanding the distribution of residents in the filtered households. Each of these stages contributes to the process of applying the second filter and refining census data based on the WorldPop Criterion. The generated summaries and data are useful for further analysis and are saved for future reference. # Summarizing the data for &#39;greenpoint2&#39; variable summary_greenpoint2_stats &lt;- censo3 %&gt;% group_by(greenpoint2) %&gt;% summarise(min = min(H01A_TOTAL_PERSONAS), max = max(H01A_TOTAL_PERSONAS), num_na = sum(is.na(H01A_TOTAL_PERSONAS)), total = n()) summary_greenpoint2_stats greenpoint2 min max num_na total Censado con informacion n=0 0 0 0 212980 Censado con informacion n&gt;0 1 261 0 776478 Sin informacion pero n&gt;0 0 0 0 341804 Sin informacion pero n&gt;=0 NA NA 218308 411979 3.2.4 Defining the Third Filter In this section, we introduce the implementation of the third filter, building upon the foundation laid by Filters 1 and 2. The third filter addresses households within UGMs that were surveyed after an interval greater than 20 days, and despite being classified as unoccupied, there is a lack of certainty regarding their occupancy status. These households are reclassified as having an unknown status. Reading the ‘Desocupadas fuera periodo.xlsx’ File We start by reading the ‘Desocupadas fuera periodo.xlsx’ file to gather information about households that were vacant but visited outside the standard interval. We specifically extract the ‘UGM_ID’ column for further analysis. # Reading the &#39;Desocupadas fuera periodo.xlsx&#39; file and selecting the UGM_ID column upms_reporte &lt;- openxlsx::read.xlsx( xlsxFile = &quot;Recursos/02_Census_Filters/Data/Desocupadas fuera periodo.xlsx&quot;) %&gt;% select(UGM_ID = ID_UGM) Applying Filters Based on ‘upms_reporte’ and Specific Conditions Using the gathered information from ‘upms_reporte’ and considering certain conditions, we apply additional filters to the existing data. We update the ‘greenpoint2’ and ‘Filtros’ columns based on the specified criteria. # Creating &#39;censo4&#39; by applying filters based on &#39;upms_reporte&#39; and specific conditions censo4 &lt;- censo3 %&gt;% mutate( greenpoint2 = case_when( UGM_ID %in% upms_reporte$UGM_ID &amp; H01A_TOTAL_PERSONAS == 0 ~ &quot;Sin informacion pero n&gt;=0&quot;, TRUE ~ greenpoint2 ), Filtros = case_when( UGM_ID %in% upms_reporte$UGM_ID &amp; H01A_TOTAL_PERSONAS == 0 ~ &quot;Fuera de periodo(20 días)&quot;, TRUE ~ Filtros ) ) Applying Additional Filters and Creating ‘Filtros’ Values We proceed by further refining the data by applying additional filters. The ‘Filtros’ values are updated based on various conditions such as the number of residents, the result of the interview (‘RESUL_ENTREVISTA_VIV’), and the occupation of the dwelling (‘V02_OCUPACION_VIVIENDA’). # Applying additional filters and creating &#39;Filtros&#39; values censo4 %&lt;&gt;% mutate(Filtros = case_when( is.na(Filtros) &amp; H01A_TOTAL_PERSONAS &gt; 0 ~ &quot;Número de personas mayor a 0&quot;, is.na(Filtros) &amp; RESUL_ENTREVISTA_VIV %in% c(1) &amp; H01A_TOTAL_PERSONAS == 0 ~ &quot;Entrevista igual a 1 y Número de personas igual a 0&quot;, is.na(Filtros) &amp; RESUL_ENTREVISTA_VIV %in% c(3,4) ~ &quot;Entrevista es 3 o 4&quot;, is.na(Filtros) &amp; is.na(greenpoint) &amp; is.na(personas) ~ &quot;Sin conteo de personas&quot;, is.na(Filtros) &amp; V02_OCUPACION_VIVIENDA == &quot;8&quot; ~ &quot;Ocupación de la vivienda es 8&quot;, TRUE ~ Filtros )) Summarizing Data Based on ‘greenpoint2’ and ‘Filtros’ Variables We generate a summary of the data based on the updated ‘greenpoint2’ and ‘Filtros’ variables. The summary provides insights into the distribution of households across different categories. # Summarizing data based on &#39;greenpoint2&#39; and &#39;Filtros&#39; variables summary_greenpoint2_filtros &lt;- censo4 %&gt;% group_by(greenpoint2, Filtros) %&gt;% tally() %&gt;% ungroup() %&gt;% mutate(percentage = 100 * n / sum(n)) greenpoint2 Filtros n percentage Censado con informacion n=0 Entrevista igual a 1 y Número de personas igual a 0 175921 10.0916 Censado con informacion n&gt;0 Número de personas mayor a 0 776478 44.5422 Sin informacion pero n&gt;0 Entrevista es 3 o 4 285810 16.3953 Sin informacion pero n&gt;=0 Criterio WorldPop 135370 7.7654 Sin informacion pero n&gt;=0 Fuera de periodo(20 días) 151354 8.6823 Sin informacion pero n&gt;=0 Sin conteo de personas 218308 12.5231 Summarizing Data Based on ‘greenpoint2’ Variable Similarly, we create another summary of the data, this time focusing solely on the ‘greenpoint2’ variable. This summary helps us understand the impact of the third filter on the classification of households. # Summarizing data based on &#39;greenpoint2&#39; variable summary_greenpoint2 &lt;- censo4 %&gt;% group_by(greenpoint2) %&gt;% tally() %&gt;% mutate(percentage = 100 * n / sum(n)) greenpoint2 n percentage Censado con informacion n=0 175921 10.0916 Censado con informacion n&gt;0 776478 44.5422 Sin informacion pero n&gt;0 285810 16.3953 Sin informacion pero n&gt;=0 505032 28.9709 3.2.5 Combining non-coordinated houses Selecting non-coordinated houses from the ‘censo_sexo_edad’ dataset and inner joining with ‘Viviendas_sin_coordenadas’ # Filtering non-coordinated houses from &#39;censo_sexo_edad&#39; dataset Viviendas_sin_coordenadas2 &lt;- censo_sexo_edad %&gt;% filter(is.na(un_ID)) %&gt;% inner_join(Viviendas_sin_coordenadas) %&gt;% # Adding a unique identifier &#39;un_ID&#39; to the newly joined houses mutate(un_ID = paste0(&quot;A&quot;, 1:n())) # Adding the newly joined houses to the &#39;censo4&#39; dataset censo4 &lt;- bind_rows(censo4, Viviendas_sin_coordenadas2) # Modifying &#39;Filtros&#39; column based on &#39;greenpoint2&#39; values censo4 %&lt;&gt;% mutate(Filtros = ifelse(is.na(greenpoint2), &quot;Censado en papel&quot;, greenpoint2)) # Modifying &#39;greenpoint2&#39; column based on conditions censo4 %&lt;&gt;% mutate(greenpoint2 = case_when( Filtros == &quot;Censado en papel&quot; &amp; H01A_TOTAL_PERSONAS == 0 ~ &quot;Papel n=0&quot;, Filtros == &quot;Censado en papel&quot; &amp; H01A_TOTAL_PERSONAS &gt; 0 ~ &quot;Papel n&gt;0&quot;, TRUE ~greenpoint2 )) 3.2.6 Aggregating statistics and summaries # Summarizing statistics for the &#39;censo4&#39; dataset based on &#39;greenpoint2&#39; column summary1 &lt;- censo4 %&gt;% group_by(greenpoint2) %&gt;% summarise(min = min(H01A_TOTAL_PERSONAS), max = max(H01A_TOTAL_PERSONAS), num_na = sum(is.na(H01A_TOTAL_PERSONAS)), total = n()) greenpoint2 min max num_na total Censado con informacion n=0 0 0 0 175921 Censado con informacion n&gt;0 1 261 0 776478 Sin informacion pero n&gt;0 0 0 0 285810 Sin informacion pero n&gt;=0 NA NA 218308 505032 Summarizing statistics for the ‘censo4’ dataset based on ‘greenpoint2’ and ‘Filtros’ columns summary2 &lt;- censo4 %&gt;% group_by(greenpoint2, Filtros) %&gt;% summarise(min = min(H01A_TOTAL_PERSONAS), max = max(H01A_TOTAL_PERSONAS), num_na = sum(is.na(H01A_TOTAL_PERSONAS)), total = n()) greenpoint2 Filtros min max num_na total Censado con informacion n=0 Entrevista igual a 1 y Número de personas igual a 0 0 0 0 175921 Censado con informacion n&gt;0 Número de personas mayor a 0 1 261 0 776478 Sin informacion pero n&gt;0 Entrevista es 3 o 4 0 0 0 285810 Sin informacion pero n&gt;=0 Criterio WorldPop 0 0 0 135370 Sin informacion pero n&gt;=0 Fuera de periodo(20 días) 0 0 0 151354 Sin informacion pero n&gt;=0 Sin conteo de personas NA NA 218308 218308 Summarizing statistics for the ‘censo4’ dataset based on ‘greenpoint2’ and ‘Filtros’ columns summary3 &lt;- censo4 %&gt;% group_by(greenpoint2, Filtros) %&gt;% summarise(total = n(), nas = sum(is.na(H01A_TOTAL_PERSONAS))) greenpoint2 Filtros total nas Censado con informacion n=0 Entrevista igual a 1 y Número de personas igual a 0 175921 0 Censado con informacion n&gt;0 Número de personas mayor a 0 776478 0 Sin informacion pero n&gt;0 Entrevista es 3 o 4 285810 0 Sin informacion pero n&gt;=0 Criterio WorldPop 135370 0 Sin informacion pero n&gt;=0 Fuera de periodo(20 días) 151354 0 Sin informacion pero n&gt;=0 Sin conteo de personas 218308 218308 Counting occurrences of ‘un_ID’ and filtering for duplicates duplicated_un_ID &lt;- censo4 %&gt;% group_by(un_ID) %&gt;% tally() %&gt;% filter(n &gt; 1) duplicated_un_ID 3.2.7 Extracting and Saving Subset # Selecting columns from &#39;censo4&#39; that match &#39;Nombre_Columna&#39; and contain &#39;GRUPO&#39; paso &lt;- censo4 %&gt;% select( all_of(Nombre_Columna), matches(&quot;GRUPO&quot;) ) # Saving the &#39;paso&#39; dataset as an RDS file in the specified directory saveRDS(paso, file = &quot;Recursos/02_Census_Filters/data/censo_viviendas.rds&quot;) "],["standardization-and-validation-of-covariates.html", "Chapter 4 Standardization and validation of covariates", " Chapter 4 Standardization and validation of covariates Similarly, just as the census variables underwent a validation process, the covariates dataset is subject to a similar procedure. This involves ensuring uniformity in the length of identifiers such as UGM, Cantos, regions, etc. Additionally, a validation is conducted to identify any missing values (NAs) in the dataset. Following this, a descriptive analysis is performed on the data. "],["environment-preparation-and-library-loading.html", "4.1 Environment Preparation and Library Loading", " 4.1 Environment Preparation and Library Loading This code is responsible for reviewing and improving the data we have. First, it clears anything we have in memory. Then, it loads some special tools that we are going to use. After that, it reads information about the census and geographic areas. # Clear the workspace by removing all variables rm(list = ls()) ################# ### Libraries ### ################# # Load required libraries library(tidyverse) # For data manipulation and visualization library(data.table) # For efficient data manipulation library(openxlsx) # For reading Excel files library(magrittr) # For data handling operations # Clear the console cat(&quot;\\f&quot;) ## Reading census data. # Load the &#39;censo_viviendas.rds&#39; file containing census data censo1 &lt;- readRDS(&quot;Recursos/03_Input_Validation_Cov/Data/censo_viviendas.rds&quot;) ## Reading UGMS bases. # Load the &#39;ugm_merged.rds&#39; file containing UGMS base data Base_ugms &lt;- readRDS(&quot;Recursos/03_Input_Validation_Cov/Data/ugm_merged.rds&quot;) # Count distinct UGM_ID values in census data n_distinct(censo1$UGM_ID) ## [1] 48060 #48060 # Count distinct UGM_ID values in UGMS base data n_distinct(Base_ugms$UGM_ID) # Not all UGMs have houses ## [1] 50760 #50760 "],["descriptive-values-of-the-ugms-base.html", "4.2 Descriptive values of the UGMS base", " 4.2 Descriptive values of the UGMS base We begin by creating a summary dataframe that includes the column names and their corresponding data types. Subsequently, we enhance this summary by adding a column indicating the data type of each column, achieved through the use of the map_chr function on the column names and their corresponding data. # Create a summary dataframe with column names and their data types resumen &lt;- data.frame(Nombre_Columna = names(Base_ugms)) resumen %&lt;&gt;% mutate(tipo = map_chr(Nombre_Columna, function(x)class(Base_ugms[[x]]))) Numeric Variables # Calculate maximum values for numeric and integer columns max_values &lt;- Base_ugms %&gt;% summarise(across(where(is.numeric) | where(is.integer), max)) %&gt;% pivot_longer(everything(), names_to = &quot;Nombre_Columna&quot;, values_to = &quot;Valor_Maximo&quot;) # Calculate minimum values for numeric and integer columns min_values &lt;- Base_ugms %&gt;% summarise(across(where(is.numeric) | where(is.integer), min)) %&gt;% pivot_longer(everything(), names_to = &quot;Nombre_Columna&quot;, values_to = &quot;Valor_Minimo&quot;) # Calculate mean values for numeric and integer columns media_values &lt;- Base_ugms %&gt;% summarise(across(where(is.numeric) | where(is.integer), mean)) %&gt;% pivot_longer(everything(), names_to = &quot;Nombre_Columna&quot;, values_to = &quot;Valor_Media&quot;) # Calculate median values for numeric and integer columns mediana_values &lt;- Base_ugms %&gt;% summarise(across(where(is.numeric) | where(is.integer), median)) %&gt;% pivot_longer(everything(), names_to = &quot;Nombre_Columna&quot;, values_to = &quot;Valor_Mediana&quot;) # Calculate standard deviation values for numeric and integer columns SD_values &lt;- Base_ugms %&gt;% summarise(across(where(is.numeric) | where(is.integer), sd)) %&gt;% pivot_longer(everything(), names_to = &quot;Nombre_Columna&quot;, values_to = &quot;Valor_sd&quot;) # Calculate the number of missing values for numeric and integer columns nas_values &lt;- Base_ugms %&gt;% summarise(across(where(is.numeric) | where(is.integer), function(x)sum(is.na(x)))) %&gt;% pivot_longer(everything(), names_to = &quot;Nombre_Columna&quot;, values_to = &quot;Num_nas&quot;) Character Variables # Calculate maximum lengths of characters for character columns max_char &lt;- Base_ugms %&gt;% summarise(across(where(is.character), function(x)max(nchar(x)))) %&gt;% pivot_longer(everything(), names_to = &quot;Nombre_Columna&quot;, values_to = &quot;leng_max&quot;) # Calculate minimum lengths of characters for character columns min_char &lt;- Base_ugms %&gt;% summarise(across(where(is.character), function(x)min(nchar(x)))) %&gt;% pivot_longer(everything(), names_to = &quot;Nombre_Columna&quot;, values_to = &quot;leng_min&quot;) # Calculate the number of missing values for character columns nas_values_char &lt;- Base_ugms %&gt;% summarise(across(where(is.character) , function(x)sum(is.na(x)))) %&gt;% pivot_longer(everything(), names_to = &quot;Nombre_Columna&quot;, values_to = &quot;Num_nas_char&quot;) Organizing results in a database. # Combine all results into a single dataframe resumen2 &lt;- reduce( list( nas_values_char, min_char, max_char, nas_values, SD_values, mediana_values, media_values, min_values, max_values ), full_join, by = join_by(Nombre_Columna) ) %&gt;% full_join(x = resumen, y = ., by = join_by(Nombre_Columna)) resumen2 %&gt;% head(10) %&gt;% tba() Nombre_Columna tipo Num_nas_char leng_min leng_max Num_nas Valor_sd Valor_Mediana Valor_Media Valor_Minimo Valor_Maximo un_id integer NA NA NA 0 14653.29 25380.5 25380.5 1 50760 PROV_ID character 0 1 1 NA NA NA NA NA NA CANT_ID character 0 3 3 NA NA NA NA NA NA DIST_ID character 0 5 5 NA NA NA NA NA NA UGM_ID character 0 8 8 NA NA NA NA NA NA ugm_viviendas_totales_censo integer NA NA NA 1 NA NA NA NA NA ugm_viviendas_ocupadas_censo integer NA NA NA 1 NA NA NA NA NA ugm_viviendas_desocupadas_censo integer NA NA NA 1 NA NA NA NA NA ugm_peligrosidad numeric NA NA NA 1 NA NA NA NA NA ugm_problema_de_acceso numeric NA NA NA 1 NA NA NA NA NA Variables of interest Nombre_Columna &lt;- c( &quot;un_id&quot;, &quot;PROV_ID&quot;, &quot;CANT_ID&quot;, &quot;DIST_ID&quot;, &quot;UGM_ID&quot;, &quot;ugm_viviendas_totales_censo&quot;, &quot;ugm_viviendas_ocupadas_censo&quot;, &quot;ugm_viviendas_desocupadas_censo&quot;, &quot;ugm_peligrosidad&quot;, &quot;ugm_problema_de_acceso&quot;, &quot;ugm_riesgos_amenazas&quot;, &quot;ugm_cobertura_telecomunicaciones&quot;, &quot;ugm_area_m2&quot;, &quot;asent&quot;, &quot;ppp_CRI_v2&quot;, &quot;elev&quot;, &quot;indig&quot;, &quot;aprot&quot;, &quot;dist_permisos_de_construccion_2011_2022&quot;, &quot;dist_poblacion_proyeccion_ajustada_2022&quot;, &quot;dist_poblacion_rup&quot;, &quot;dist_poblacion_ccss_abril_2023&quot;, &quot;dist_matricula_educacion_primaria_2021&quot;, &quot;dist_matricula_educacion_secundaria_2021&quot;, &quot;dist_codigo_urbanidad&quot;, &quot;GHS_BUILT_S_E2020_GLOBE_R2023A_5367_CRI&quot;, &quot;urban_coverfraction&quot;, &quot;crops_coverfraction&quot;, &quot;ebais_tt&quot;, &quot;escu_tt&quot;, &quot;igl_tt&quot;, &quot;prov_nl_mean&quot;, &quot;cant_nl_mean&quot;, &quot;dist_nl_mean&quot;, &quot;wpop_sum&quot;, &quot;ugm_sin_info&quot;) Changing the type of variables Tipo_actualizar &lt;- c( as.character, as.character, as.character, as.character, as.character, as.numeric, as.numeric, as.numeric, as.character, as.character, as.character, as.character, as.numeric, as.character, as.numeric, as.numeric, as.character, as.character, as.numeric, as.numeric, as.numeric, as.numeric, as.numeric, as.numeric, as.character, as.numeric, as.numeric, as.numeric, as.numeric, as.numeric, as.numeric, as.numeric, as.numeric, as.numeric, as.numeric, as.character) Update column types based on Nombre_Columna and Tipo_actualizar paso &lt;- map2(Nombre_Columna, Tipo_actualizar, function(nom, tipo) { Base_ugms[[nom]] &lt;&lt;- tipo(Base_ugms[[nom]]) cat(nom, &quot;\\n&quot;) }) ## un_id ## PROV_ID ## CANT_ID ## DIST_ID ## UGM_ID ## ugm_viviendas_totales_censo ## ugm_viviendas_ocupadas_censo ## ugm_viviendas_desocupadas_censo ## ugm_peligrosidad ## ugm_problema_de_acceso ## ugm_riesgos_amenazas ## ugm_cobertura_telecomunicaciones ## ugm_area_m2 ## asent ## ppp_CRI_v2 ## elev ## indig ## aprot ## dist_permisos_de_construccion_2011_2022 ## dist_poblacion_proyeccion_ajustada_2022 ## dist_poblacion_rup ## dist_poblacion_ccss_abril_2023 ## dist_matricula_educacion_primaria_2021 ## dist_matricula_educacion_secundaria_2021 ## dist_codigo_urbanidad ## GHS_BUILT_S_E2020_GLOBE_R2023A_5367_CRI ## urban_coverfraction ## crops_coverfraction ## ebais_tt ## escu_tt ## igl_tt ## prov_nl_mean ## cant_nl_mean ## dist_nl_mean ## wpop_sum ## ugm_sin_info Create a summary dataframe with column names and their data types resumen &lt;- data.frame(Nombre_Columna = names(Base_ugms)) resumen %&lt;&gt;% mutate(tipo = map_chr(Nombre_Columna, function(x) class(Base_ugms[[x]]))) # Extract character columns tipo_char &lt;- resumen$Nombre_Columna[resumen$tipo == &quot;character&quot;] # Select and display character columns from Base_ugms Base_ugms[, tipo_char] %&gt;% head(10) %&gt;% tba() un_id PROV_ID CANT_ID DIST_ID UGM_ID ugm_peligrosidad ugm_problema_de_acceso ugm_riesgos_amenazas ugm_cobertura_telecomunicaciones asent indig aprot dist_codigo_urbanidad ugm_sin_info 1 1 101 10101 10101001 2 2 2 1 0 0 0 1 0 2 1 101 10101 10101002 2 2 2 1 0 0 0 1 0 3 1 101 10101 10101003 2 2 2 1 0 0 0 1 0 4 1 101 10101 10101004 2 2 2 1 0 0 0 1 0 5 1 101 10101 10101005 2 2 2 1 0 0 0 1 0 6 1 101 10101 10101006 2 2 2 1 0 0 0 1 0 7 1 101 10101 10101007 2 2 2 1 0 0 0 1 0 8 1 101 10101 10101008 2 2 2 1 0 0 0 1 0 9 1 101 10101 10101009 2 2 2 1 0 0 0 1 0 10 1 101 10101 10101010 2 2 2 1 0 0 0 1 0 4.2.1 Standardizing Variables and Joining Datasets # Loop through character variables for (ii in tipo_char) { max_char &lt;- max(nchar(Base_ugms[[ii]]), na.rm = TRUE) Base_ugms[[ii]] &lt;- str_pad(string = Base_ugms[[ii]], width = max_char, pad = &quot;0&quot;) } UGM_censo &lt;- censo1 %&gt;% distinct(UGM_ID) # Join the UGM_censo and Base_ugms datasets Base_ugms_censo &lt;- inner_join(UGM_censo, Base_ugms) Base_ugms_censo[, tipo_char] %&gt;% head(10) %&gt;% tba() un_id PROV_ID CANT_ID DIST_ID UGM_ID ugm_peligrosidad ugm_problema_de_acceso ugm_riesgos_amenazas ugm_cobertura_telecomunicaciones asent indig aprot dist_codigo_urbanidad ugm_sin_info 00001 1 101 10101 10101001 2 2 2 1 0 0 0 1 0 00002 1 101 10101 10101002 2 2 2 1 0 0 0 1 0 00003 1 101 10101 10101003 2 2 2 1 0 0 0 1 0 00004 1 101 10101 10101004 2 2 2 1 0 0 0 1 0 00006 1 101 10101 10101006 2 2 2 1 0 0 0 1 0 00007 1 101 10101 10101007 2 2 2 1 0 0 0 1 0 00008 1 101 10101 10101008 2 2 2 1 0 0 0 1 0 00009 1 101 10101 10101009 2 2 2 1 0 0 0 1 0 00010 1 101 10101 10101010 2 2 2 1 0 0 0 1 0 00011 1 101 10101 10101011 2 2 2 1 0 0 0 1 0 Calculate the counts of missing # Calculate the counts of missing values for numeric variables nas_values &lt;- Base_ugms_censo %&gt;% summarise(across(where(is.numeric) | where(is.integer), function(x) sum(is.na(x)))) %&gt;% pivot_longer(everything(), names_to = &quot;Nombre_Columna&quot;, values_to = &quot;Num_nas&quot;) # Calculate the counts of missing values for character variables nas_values2 &lt;- Base_ugms_censo %&gt;% summarise(across(where(is.character), function(x) sum(is.na(x)))) %&gt;% pivot_longer(everything(), names_to = &quot;Nombre_Columna&quot;, values_to = &quot;Num_nas&quot;) Remove specific columns from the dataset Base_ugms_censo$dist_poblacion_rup &lt;- NULL Base_ugms_censo$dist_matricula_educacion_secundaria_2021 &lt;- NULL 4.2.2 Standardize numeric variables using z-score scaling Base_ugms_censo &lt;- Base_ugms_censo %&gt;% mutate_if(is.numeric, function(x) as.numeric(scale(x))) Save the standardized dataset saveRDS(Base_ugms_censo, &quot;Recursos/03_Input_Validation_Cov/Data/Base_ugms_estandarizada.rds&quot;) "],["binomial-unit-model-for-occupied-dwellings.html", "Chapter 5 Binomial unit model for occupied dwellings", " Chapter 5 Binomial unit model for occupied dwellings In a first instance, a statistical model was defined to predict the probability of a house being occupied. Due to a significant number of houses in the census that never responded to survey calls, refused to be interviewed, or were simply unreachable, it was necessary to assign an occupancy probability to these houses. The model used was a Bayesian mixed model with a binomial response and random effects for provinces, cantons, and districts, as detailed below: \\(U_{ij}\\) is a dichotomous variable indicating the occupancy status of the \\(i\\)-th house in the \\(j\\)-th geographic area. \\(p_{ij}\\) is the probability that the \\(i\\)-th house in the \\(j\\)-th geographic area is occupied. \\(x_{ij}^\\prime \\beta\\) represents the fixed effects considered in the model that influence the occupancy probability. \\(z_{ij}^\\prime \\gamma\\) represents the random effects that also influence the occupancy probability. We used the logit function to relate these probabilities and effects, as per the equation \\(\\text{logit}(p_{ij}) = x_{ij}^\\prime \\beta + z_{ij}^\\prime \\gamma\\). To achieve more accurate results, non-informative prior distributions for the parameters of the Bayesian model were implemented. The final outcome provides an estimate of the number of unoccupied houses in different geographical subdivisions of the country. "],["preparing-the-environment-and-data.html", "5.1 Preparing the Environment and Data", " 5.1 Preparing the Environment and Data In the following code block, we initiate the process by preparing our R environment. This involves clearing the workspace to remove any existing variables and loading the necessary libraries for data manipulation, visualization, and statistical analysis. We use libraries such as ‘tidyverse’ for data manipulation and visualization, ‘data.table’ for efficient data manipulation, ‘openxlsx’ for reading Excel files, ‘magrittr’ for data manipulation using pipe operators, ‘lme4’ for fitting linear mixed-effects models, ‘rstan’ for Bayesian data analysis using Stan, and ‘rstanarm’ for fitting Bayesian regression models. Additionally, we define the ‘select’ function from the ‘dplyr’ package for column selection. After setting up the environment, we proceed to read the census data. We read the census information from the ‘censo_viviendas.rds’ file and extract specific columns that are relevant to our analysis, including ‘un_ID’ and ‘Filtros’. Similarly, we read the standardized UGM covariates from the ‘Base_ugms_estandarizada.rds’ file. These initial steps lay the foundation for our subsequent data analysis and modeling. # Clear the workspace by removing all variables rm(list = ls()) # Load required libraries library(tidyverse) # For data manipulation and visualization library(data.table) # For efficient data manipulation library(openxlsx) # For reading Excel files library(magrittr) # For data manipulation using pipe operators library(lme4) # For fitting linear mixed-effects models library(rstan) # For Bayesian data analysis using Stan library(rstanarm) # For fitting Bayesian regression models select &lt;- dplyr::select # Define the &#39;select&#39; function from dplyr package cat(&quot;\\f&quot;) # Clear the console ## Reading census data. # Read census data from the &#39;censo_viviendas.rds&#39; file and select specific columns censo_vivienda &lt;- readRDS(&quot;Recursos/04_Model_binomial/Data/censo_viviendas.rds&quot;) %&gt;% select(un_ID:Filtros) Covariables_UGM &lt;- readRDS(&quot;Recursos/04_Model_binomial/Data/Base_ugms_estandarizada.rds&quot;) # Read UGM covariates from the &#39;Base_ugms_estandarizada.rds&#39; file "],["defining-desocupada-column-classifying-occupancy-status.html", "5.2 Defining ‘Desocupada’ Column: Classifying Occupancy Status", " 5.2 Defining ‘Desocupada’ Column: Classifying Occupancy Status This section focuses on defining the ‘Desocupada’ column in the census data, which indicates whether a dwelling is unoccupied. The values are determined based on specific conditions derived from the ‘greenpoint2’ and ‘Filtros’ columns, as well as the number of individuals living in the dwelling. The classification process is essential for subsequent analysis and modeling. # Define the &#39;Desocupada&#39; column based on specific conditions censo_vivienda %&lt;&gt;% mutate( Desocupada = case_when( greenpoint2 == &quot;Censado con informacion n=0&quot; ~ 1, greenpoint2 == &quot;Censado con informacion n&gt;0&quot; ~ 0, greenpoint2 == &quot;Sin informacion pero n&gt;0&quot; ~ 0, Filtros == &quot;Censado en papel&quot; &amp; H01A_TOTAL_PERSONAS &gt; 0 ~ 0, Filtros == &quot;Censado en papel&quot; &amp; H01A_TOTAL_PERSONAS == 0 ~ 1, greenpoint2 == &quot;Sin informacion pero n&gt;=0&quot; ~ NA_real_ ) ) 5.2.1 Counting Combinations of Occupancy Status and Greenpoint Values In this section, we perform a data aggregation to calculate the counts of various combinations of occupancy status and ‘greenpoint2’ values. By grouping the data based on these variables, we can observe the distribution of dwelling occupancy patterns and the corresponding greenpoint categories. The resulting summary, including the counts, is saved to a file for reference and further analysis. # Grouping and summarizing to get counts for different combinations conteos &lt;- censo_vivienda %&gt;% group_by(greenpoint2, Desocupada) %&gt;% summarise(total = n(), .groups = &quot;drop&quot;) conteos greenpoint2 Desocupada total Censado con informacion n=0 1 175921 Censado con informacion n&gt;0 0 776478 Papel n=0 1 1334 Papel n&gt;0 0 23344 Sin informacion pero n&gt;0 0 285810 Sin informacion pero n&gt;=0 NA 505032 # Grouping and summarizing data to create a binomial model base dataset base_conteo_viviendas &lt;- censo_vivienda %&gt;% group_by(UGM_ID) %&gt;% summarise( Desocupadas = sum(Desocupada, na.rm = TRUE), Ocupadas = sum(1 - Desocupada, na.rm = TRUE), n_vivienda = n() ) base_conteo_viviendas UGM_ID Desocupadas Ocupadas n_vivienda 10101001 0 1 1 10101002 0 2 2 10101003 5 1 6 10101004 1 2 3 10101006 1 0 1 10101007 1 0 1 10101008 2 0 2 10101009 8 1 9 10101010 1 0 1 10101011 1 1 2 10101012 0 3 3 10101013 1 0 1 10101018 1 0 1 10101019 0 1 1 10101020 7 2 9 10101021 3 1 4 10101022 0 34 122 10101026 2 0 2 10101028 1 0 1 10101036 2 0 2 Summarize the numeric columns in ‘base_conteo_viviendas’ and save the results readRDS(&quot;Recursos/04_Model_binomial/RecurseBooks/base_conteo2.rds&quot;) %&gt;% tba() Desocupadas Ocupadas n_vivienda 177255 1085632 1767919 Inner join the binomial model base dataset with standardized covariates base_conteo_viviendas &lt;- inner_join(base_conteo_viviendas, Covariables_UGM, by = &quot;UGM_ID&quot;) The provided code includes the following options: options(mc.cores = parallel::detectCores()): This option sets the number of cores used for parallel computation in Stan models. The parallel::detectCores() function automatically detects the number of available CPU cores on your machine. By setting the number of cores, you can leverage parallel processing to speed up the estimation process of the Stan model. rstan::rstan_options(auto_write = TRUE): This option is related to writing compiled Stan models to disk for caching purposes. When auto_write is set to TRUE, it indicates that compiled Stan models should be automatically saved to disk to speed up the compilation process in future runs. This can improve the running time of the model, especially if you run the same model multiple times. Both of these options contribute to improving the efficiency and speed of fitting Stan models by utilizing parallel processing and caching compiled models. options(mc.cores = parallel::detectCores()) rstan::rstan_options(auto_write = TRUE) # Speed up running time modelo_binomial &lt;- stan_glmer( cbind(Desocupadas, Ocupadas) ~ 1 + (1 | PROV_ID) + (1 | CANT_ID) + (1 | DIST_ID) + ugm_peligrosidad + ugm_problema_de_acceso + ugm_riesgos_amenazas + ugm_cobertura_telecomunicaciones + dist_permisos_de_construccion_2011_2022 + dist_poblacion_proyeccion_ajustada_2022 + dist_poblacion_ccss_abril_2023 + dist_matricula_educacion_primaria_2021 + dist_codigo_urbanidad + GHS_BUILT_S_E2020_GLOBE_R2023A_5367_CRI + urban_coverfraction + crops_coverfraction + asent + ppp_CRI_v2 + elev + indig + aprot + ebais_tt + escu_tt + igl_tt + dist_nl_mean , data = base_conteo_viviendas, family = binomial(link = &quot;logit&quot;), iter = 15000, # total number of iterations per chain cores = 4, ) saveRDS(object = modelo_binomial, file = &quot;Recursos/04_Model_binomial/Data/Binomial_bayes_vivienda_desocupadas.rds&quot;) "],["consolidation-of-census-housing-databases.html", "Chapter 6 Consolidation of CENSUS housing databases", " Chapter 6 Consolidation of CENSUS housing databases # Clear the workspace by removing all variables rm(list = ls()) # Load required libraries library(tidyverse) # For data manipulation and visualization library(data.table) # For efficient data manipulation library(openxlsx) # For reading Excel files library(magrittr) # For data manipulation using pipe operators library(lme4) # For fitting linear mixed-effects models library(posterior) # For Bayesian data analysis library(rstanarm) # For fitting Bayesian regression models library(rstan) # For Bayesian data analysis using Stan cat(&quot;\\f&quot;) # Clear the console # Read census data from the &#39;censo_viviendas.rds&#39; file censo_vivienda &lt;- readRDS(&quot;Recursos/04_Model_binomial/Data/censo_viviendas.rds&quot;) # Read UGMS covariates from the &#39;Base_ugms_estandarizada.rds&#39; file Base_ugms &lt;- readRDS(&quot;Recursos/04_Model_binomial/Data/Base_ugms_estandarizada.rds&quot;) # Read binomial Bayesian model for unoccupied housing from the &#39;Binomial_bayes_vivienda_desocupadas.rds&#39; file modelo_binomial &lt;- readRDS(&quot;Recursos/04_Model_binomial/Data/Binomial_bayes_vivienda_desocupadas.rds&quot;) "],["defining-occupied-and-unoccupied-houses..html", "6.1 Defining occupied and unoccupied houses.", " 6.1 Defining occupied and unoccupied houses. censo_vivienda %&lt;&gt;% mutate(Desocupada = case_when( greenpoint2 == &quot;Censado con informacion n=0&quot; ~ 1, greenpoint2 == &quot;Censado con informacion n&gt;0&quot; ~ 0, greenpoint2 == &quot;Sin informacion pero n&gt;0&quot; ~ 0, Filtros == &quot;Censado en papel&quot; &amp; H01A_TOTAL_PERSONAS &gt; 0 ~ 0, Filtros == &quot;Censado en papel&quot; &amp; H01A_TOTAL_PERSONAS == 0 ~ 1, greenpoint2 == &quot;Sin informacion pero n&gt;=0&quot; ~ NA_real_ ) ) The code first calculates the linear predictor using the posterior_linpred function for the modelo_binomial model, based on the Base_ugms data. It then transforms these linear predictions to obtain predicted probabilities of unoccupied dwellings using the logistic function (plogis). # Waiting time of 5 to 10 minutes pred_linear &lt;- posterior_linpred(modelo_binomial, newdata = Base_ugms, draws = 1000) pred_unoccupied &lt;- plogis(pred_linear) The next code block (commented out) deals with saving and loading the predicted unoccupied values from a file named “pred_unoccupied.rds.” It checks the dimensions of the predicted values and the Base_ugms, and summarizes the means of the predicted values, checking for values below 0 and above 1 #saveRDS(pred_unoccupied, &quot;Recursos/04_Model_binomial/Data/pred_unoccupied.rds&quot;) pred_unoccupied &lt;- readRDS(&quot;Recursos/04_Model_binomial/Data/pred_unoccupied.rds&quot;) # Check dimensions of the predicted values and the base dim(pred_unoccupied) dim(Base_ugms) # Count the number of predicted values below 0 and above 1 sum(colMeans(pred_unoccupied) &lt; 0) sum(colMeans(pred_unoccupied) &gt; 1) # Summarize the means of predicted values summary(colMeans(pred_unoccupied)) Calculate the 2.5th and 97.5th percentiles of predicted values q0.05 &lt;- apply(pred_unoccupied, MARGIN = 2, function(x) quantile(x, 0.05)) q0.95 &lt;- apply(pred_unoccupied, MARGIN = 2, function(x) quantile(x, 0.95)) # Calculate the standard deviation of predicted values sd_pred &lt;- apply(pred_unoccupied, MARGIN = 2, sd) summary(sd_pred) Create a data frame with prediction intervals intervalos &lt;- data.frame(UGM_ID = Base_ugms$UGM_ID, Pred_unoccupied = colMeans(pred_unoccupied), UpperLim_unoccupied = colMeans(pred_unoccupied) + 3 * sd_pred * q0.975, LowerLim_unoccupied = colMeans(pred_unoccupied) - 3 * sd_pred * q0.025 ) Inner join between censo_vivienda and intervalos based on UGM_ID censo_vivienda %&lt;&gt;% inner_join(intervalos, by = &quot;UGM_ID&quot;) # Calculate new values for Desocupada and prediction intervals censo_vivienda %&lt;&gt;% mutate( Desocupada2 = case_when(is.na(Desocupada) ~ Pred_unoccupied, TRUE ~ Desocupada), LimInf_desocupadas = case_when(is.na(Desocupada) ~ LowerLim_unoccupied, TRUE ~ LimInf_desocupadas), LimSup_desocupadas = case_when(is.na(Desocupada) ~ UpperLim_unoccupied, TRUE ~ LimSup_desocupadas) ) "],["summary-measures-and-results-validation.html", "6.2 Summary Measures and Results Validation", " 6.2 Summary Measures and Results Validation In this section, we calculate various summary measures to validate the results of our model. We calculate the mean and sum of different variables for the original unoccupied dwellings, the updated unoccupied dwellings, and the predicted unoccupied dwellings. We also proceed to calculate the mean estimation, confidence intervals, and percentages of unoccupied dwellings. # Calculate means and sums of different variables mean_original_desocupada &lt;- mean(censo_vivienda$Desocupada, na.rm = TRUE) mean_updated_desocupada &lt;- mean(censo_vivienda$Desocupada2) mean_predicted_desocupada &lt;- mean(censo_vivienda$Pred_unoccupied) sum_original_desocupada &lt;- sum(censo_vivienda$Desocupada, na.rm = TRUE) sum_updated_desocupada &lt;- sum(censo_vivienda$Desocupada2) sum_predicted_desocupada &lt;- sum(censo_vivienda$Pred_unoccupied) Calculate mean estimation, confidence intervals, and percentages result_summary &lt;- censo_vivienda %&gt;% mutate(MEInf_desocupadas = Desocupada2 - LimInf_desocupadas, MESup_desocupadas = LimSup_desocupadas - Desocupada2) %&gt;% summarise( total = sum(Desocupada2), Porcen = mean(Desocupada2) , LimInf_desocupadas = (Porcen - (mean(MEInf_desocupadas)/sqrt(n()))) * 100, LimSup_desocupadas = (Porcen + (mean(MESup_desocupadas)/sqrt(n()))) * 100, Porcen = Porcen * 100 ) total Porcen LimInf_desocupadas LimSup_desocupadas 220936.2 12.497 12.4969 12.497 Group by PROV_ID and calculate MEInf_desocupadas and MESup_desocupadas prov_summary &lt;- censo_vivienda %&gt;% group_by(PROV_ID) %&gt;% mutate( MEInf_desocupadas = Desocupada2 - LimInf_desocupadas, MESup_desocupadas = LimSup_desocupadas - Desocupada2 ) %&gt;% summarise( total = sum(Desocupada2), Porcen = mean(Desocupada2), LimInf_desocupadas = (Porcen - (mean(MEInf_desocupadas) / sqrt(n()))) * 100, LimSup_desocupadas = (Porcen + (mean(MESup_desocupadas) / sqrt(n()))) * 100, Porcen = Porcen * 100, Leng_IC = LimSup_desocupadas - LimInf_desocupadas ) PROV_ID total Porcen LimInf_desocupadas LimSup_desocupadas Leng_IC 1 45529.82 8.5835 8.5835 8.5835 0.0001 2 41160.36 11.1431 11.1430 11.1431 0.0001 3 17470.38 9.4604 9.4604 9.4605 0.0001 4 13329.65 7.6866 7.6866 7.6867 0.0001 5 32031.88 21.4326 21.4321 21.4333 0.0012 6 45351.21 23.4420 23.4418 23.4423 0.0005 7 26062.89 15.5966 15.5965 15.5967 0.0002 Group by CANT_ID and calculate MEInf_desocupadas and MESup_desocupadas cant_summary &lt;- censo_vivienda %&gt;% group_by(CANT_ID) %&gt;% mutate( MEInf_desocupadas = Desocupada2 - LimInf_desocupadas, MESup_desocupadas = LimSup_desocupadas - Desocupada2 ) %&gt;% summarise( total = sum(Desocupada2), Porcen = mean(Desocupada2), LimInf_desocupadas = (Porcen - (mean(MEInf_desocupadas) / sqrt(n()))) * 100, LimSup_desocupadas = (Porcen + (mean(MESup_desocupadas) / sqrt(n()))) * 100, Porcen = Porcen * 100, Leng_IC = LimSup_desocupadas - LimInf_desocupadas ) CANT_ID total Porcen LimInf_desocupadas LimSup_desocupadas Leng_IC 101 7171.275 7.3095 7.3095 7.3095 1e-04 102 1330.895 5.5770 5.5770 5.5771 1e-04 103 3419.079 4.9146 4.9145 4.9147 1e-04 104 1902.457 12.7750 12.7749 12.7752 3e-04 105 1791.999 24.9686 24.9677 24.9697 2e-03 106 1778.785 8.0209 8.0207 8.0211 3e-04 107 1844.608 14.1588 14.1586 14.1591 5e-04 108 2024.655 4.8765 4.8764 4.8765 1e-04 109 1212.172 5.3084 5.3083 5.3085 2e-04 110 1620.085 6.3151 6.3151 6.3152 2e-04 Group by DIST_ID and calculate MEInf_desocupadas and MESup_desocupadas dist_summary &lt;- censo_vivienda %&gt;% group_by(DIST_ID) %&gt;% mutate( MEInf_desocupadas = Desocupada2 - LimInf_desocupadas, MESup_desocupadas = LimSup_desocupadas - Desocupada2 ) %&gt;% summarise( total = sum(Desocupada2), Porcen = mean(Desocupada2), LimInf_desocupadas = (Porcen - (mean(MEInf_desocupadas) / sqrt(n()))) * 100, LimSup_desocupadas = (Porcen + (mean(MESup_desocupadas) / sqrt(n()))) * 100, Porcen = Porcen * 100, Leng_IC = LimSup_desocupadas - LimInf_desocupadas ) DIST_ID total Porcen LimInf_desocupadas LimSup_desocupadas Leng_IC 10101 379.6071 26.1078 26.1054 26.1108 0.0054 10102 416.0615 8.6535 8.6532 8.6540 0.0008 10103 490.3833 7.6959 7.6957 7.6962 0.0004 10104 801.3848 15.3434 15.3428 15.3441 0.0013 10105 902.0885 13.3130 13.3128 13.3132 0.0004 10106 430.8623 6.2308 6.2308 6.2309 0.0001 10107 226.6559 2.0111 2.0111 2.0112 0.0000 10108 555.6962 13.3420 13.3417 13.3425 0.0009 10109 1110.6140 5.2551 5.2550 5.2552 0.0002 10110 1078.2147 6.6812 6.6812 6.6813 0.0001 Save modified censo_vivienda without Pred_unoccupied column censo_vivienda_modified &lt;- censo_vivienda %&gt;% dplyr::select(-Pred_unoccupied) saveRDS(censo_vivienda_modified, file = &quot;Recursos/04_Model_binomial/Data/01_censo_vivienda_desocupadas.rds&quot;) "],["estimation-of-the-number-of-people-per-household.html", "Chapter 7 Estimation of the number of people per household", " Chapter 7 Estimation of the number of people per household ### Cleaning R environment ### # Clear the workspace by removing all variables rm(list = ls()) ### Libraries ### # Load required libraries library(tidyverse) # For data manipulation and visualization library(data.table) # For efficient data manipulation library(openxlsx) # For reading Excel files library(magrittr) # For data manipulation using pipe operators library(lme4) # For fitting linear mixed-effects models library(rstan) # For Bayesian data analysis using Stan library(rstanarm) # For fitting Bayesian regression models cat(&quot;\\f&quot;) # Clear the console "],["reading-the-census-data..html", "7.1 Reading the census data.", " 7.1 Reading the census data. # Read census data from the &#39;censo_viviendas.rds&#39; file censo_vivienda &lt;- readRDS(&quot;Recursos/05_Model_for_people/Data/censo_viviendas.rds&quot;) # Read UGM covariates from the &#39;Base_ugms_estandarizada.rds&#39; file Base_ugms &lt;- readRDS(&quot;Recursos/05_Model_for_people/Data/Base_ugms_estandarizada.rds&quot;) "],["preparing-data-for-model-1.html", "7.2 Preparing data for Model 1", " 7.2 Preparing data for Model 1 # Calculate the mean of total persons per UGM, excluding specific conditions base_ugm_estima_todas &lt;- censo_vivienda %&gt;% filter( !greenpoint2 %in% c(&quot;Sin informacion pero n&gt;0&quot;, &quot;Sin informacion pero n&gt;=0&quot;)) %&gt;% group_by(UGM_ID) %&gt;% summarise(tot_personas = sum(H01A_TOTAL_PERSONAS, na.rm = TRUE) ) # Check the number of rows and missing values nrow(base_ugm_estima_todas) sum(is.na(base_ugm_estima_todas$tot_personas)) # Join the UGM mean total persons with UGM covariates base_ugm_estima_todas &lt;- inner_join(base_ugm_estima_todas, Base_ugms, by = &quot;UGM_ID&quot;) # Check the number of rows after joining nrow(base_ugm_estima_todas) Fit a Stan GLM model to estimate total population means # Estimated time of 2 to 3 hours modelo_todas &lt;- glm( tot_personas ~ 1 + PROV_ID + CANT_ID + DIST_ID + dist_codigo_urbanidad + ugm_peligrosidad + ugm_problema_de_acceso + ugm_riesgos_amenazas + ugm_cobertura_telecomunicaciones + dist_permisos_de_construccion_2011_2022 + dist_poblacion_proyeccion_ajustada_2022 + dist_poblacion_ccss_abril_2023 + dist_matricula_educacion_primaria_2021 + GHS_BUILT_S_E2020_GLOBE_R2023A_5367_CRI + urban_coverfraction + crops_coverfraction + asent + ppp_CRI_v2 + elev + indig + aprot + ebais_tt + escu_tt + igl_tt + dist_nl_mean , data = base_ugm_estima_todas, family = poisson(link = &quot;log&quot;) ) # Save the fitted model to a file saveRDS(modelo_todas, &quot;Recursos/05_Model_for_people/Data/fit_poisson_todas.rds&quot;) "],["preparing-data-for-model-2.html", "7.3 Preparing data for Model 2", " 7.3 Preparing data for Model 2 # Calculate the mean of total persons per UGM for occupied households base_ugm_estima_ocupadas &lt;- censo_vivienda %&gt;% filter( greenpoint2 %in% c(&quot;Censado con informacion n&gt;0&quot;, &quot;Papel n&gt;0&quot;)) %&gt;% group_by(UGM_ID) %&gt;% summarise(tot_personas = sum(H01A_TOTAL_PERSONAS, na.rm = TRUE) ) # Check the number of rows and missing values nrow(base_ugm_estima_ocupadas) sum(is.na(base_ugm_estima_ocupadas$tot_personas)) # Join the UGM mean total persons for occupied households with UGM covariates base_ugm_estima_ocupadas &lt;- inner_join(base_ugm_estima_ocupadas, Base_ugms, by = &quot;UGM_ID&quot;) # Check the number of rows after joining nrow(base_ugm_estima_ocupadas) Fit a Stan GLM model for occupied households modelo_ocupadas &lt;- glm( tot_personas ~ 1 + PROV_ID + CANT_ID + DIST_ID + dist_codigo_urbanidad + ugm_peligrosidad + ugm_problema_de_acceso + ugm_riesgos_amenazas + ugm_cobertura_telecomunicaciones + dist_permisos_de_construccion_2011_2022 + dist_poblacion_proyeccion_ajustada_2022 + dist_poblacion_ccss_abril_2023 + dist_matricula_educacion_primaria_2021 + dist_codigo_urbanidad + GHS_BUILT_S_E2020_GLOBE_R2023A_5367_CRI + urban_coverfraction + crops_coverfraction + asent + ppp_CRI_v2 + elev + indig + aprot + ebais_tt + escu_tt + igl_tt + dist_nl_mean , data = base_ugm_estima_ocupadas, family = poisson(link = &quot;log&quot;) ) # Save the fitted model for occupied households to a file saveRDS(modelo_ocupadas, &quot;Recursos/05_Model_for_people/Data/fit_poisson_ocupadas.rds&quot;) "],["consolidating-the-number-of-people-per-household.html", "Chapter 8 consolidating the number of people per household", " Chapter 8 consolidating the number of people per household ### Cleaning R environment ### rm(list = ls()) ################# ### Libraries ### ################# library(tidyverse) library(data.table) library(openxlsx) library(magrittr) library(lme4) # For fitting linear mixed-effects models library(rstan) # For Bayesian data analysis using Stan library(rstanarm) # For fitting Bayesian regression models library(merTools) cat(&quot;\\f&quot;) Read census data and models. censo_vivienda &lt;- readRDS(&quot;Recursos/05_Model_for_people/Data/01_censo_vivienda_desocupadas.rds&quot;) Base_ugms &lt;- readRDS(&quot;Recursos/05_Model_for_people/Data/Base_ugms_estandarizada.rds&quot;) modelo_todas &lt;- readRDS(&quot;Recursos/05_Model_for_people/Data/fit_poisson_todas.rds&quot;) modelo_ocupadas &lt;- readRDS(&quot;Recursos/05_Model_for_people/Data/fit_poisson_ocupadas.rds&quot;) Make predictions using the models pred_todas &lt;- predict(modelo_todas, newdata = Base_ugms, type = &quot;response&quot;, se.fit = TRUE) saveRDS(pred_todas,file = &quot;Recursos/05_Model_for_people/Data/pred_todas.rds&quot;) pred_todas &lt;- readRDS(file = &quot;Recursos/05_Model_for_people/Data/pred_todas.rds&quot;) Base_ugms$pred_todas &lt;- pred_todas$fit Base_ugms$pred_todas_se &lt;- pred_todas$se.fit hist(Base_ugms$pred_todas) pred_ocupadas &lt;- predict(modelo_ocupadas, newdata = Base_ugms, type = &quot;response&quot;, se.fit = TRUE) saveRDS(pred_ocupadas,file = &quot;Recursos/05_Model_for_people/Data/pred_ocupadas.rds&quot;) pred_ocupadas &lt;- readRDS(file = &quot;Recursos/05_Model_for_people/Data/pred_ocupadas.rds&quot;) Base_ugms$pred_ocupadas &lt;- pred_ocupadas$fit Base_ugms$pred_ocupadas_se &lt;- pred_ocupadas$se.fit hist(Base_ugms$pred_ocupadas) summary(Base_ugms$pred_todas) summary(Base_ugms$pred_ocupadas) Merge census information with predictions censo_temp &lt;- censo_vivienda %&gt;% full_join(Base_ugms) %&gt;% group_by(UGM_ID) %&gt;% mutate( pred_conteos = case_when( greenpoint2 == &quot;Sin informacion pero n&gt;0&quot; ~ pred_ocupadas, greenpoint2 == &quot;Sin informacion pero n&gt;=0&quot; ~ pred_todas , TRUE ~ H01A_TOTAL_PERSONAS ), MEInf_pred_conteos = case_when( greenpoint2 == &quot;Sin informacion pero n&gt;0&quot; ~ 1.96*pred_ocupadas_se, greenpoint2 == &quot;Sin informacion pero n&gt;=0&quot; ~ 1.96*pred_todas_se , TRUE ~ 0 ), MESup_pred_conteos = case_when( greenpoint2 == &quot;Sin informacion pero n&gt;0&quot; ~ 1.96*pred_ocupadas_se, greenpoint2 == &quot;Sin informacion pero n&gt;=0&quot; ~ 1.96*pred_todas_se , TRUE ~ 0 ) ) Calculate sum of predictions sum(censo_temp$pred_conteos) # Summary of estimates per UGM censo_temp %&gt;% group_by(UGM_ID) %&gt;% summarise(Min_ugm = min(pred_conteos), Max_ugm = max(pred_conteos)) %&gt;% View() # Summary of estimates filtered by greenpoint2 censo_temp %&gt;% filter(greenpoint2 == &quot;Sin informacion pero n&gt;=0&quot; ) %&gt;% group_by(UGM_ID) %&gt;% summarise(Min_ugm = min(pred_conteos), Max_ugm = max(pred_conteos))%&gt;% View() Save consolidated information to a file saveRDS(censo_temp, file = &quot;Recursos/05_Model_for_people/Data/02_censo_vivienda_personas.rds&quot;) "],["multinomial-model-for-estimating-people-by-age-range-and-sex.html", "Chapter 9 Multinomial model for estimating people by age range and sex", " Chapter 9 Multinomial model for estimating people by age range and sex In the final step, we model the demographic structure of Small Geographic Units (UGMs) at the province level. This structure consists of 40 subgroups based on the combination of gender and age groups. To estimate the demographics of unobserved households, we make use of conditional prediction based on the outcomes from the previous step. Given the nature of the phenomenon under study, a multinomial distribution is considered suitable for the count of individuals across the 40 groups. Here’s an explanation of the model: \\(G_i\\) follows a Multinomial distribution \\(Multinomial(p_{G_i})\\). The log-odds of \\(p_{G_i}\\) are modeled by \\(x_i^&#39; \\beta\\). In this context, \\(G_i\\) represents the count for each of the forty demographic groups. \\(p_{G_i}\\) is a vector of size 40 containing the probabilities that a person classified in each group resides in a household. Cleaning R environment The code removes all objects from the current R environment, ensuring a clean slate for the subsequent operations. # Clearing the R environment by removing all variables from memory. rm(list = ls()) # Loading necessary libraries for data analysis. library(tidyverse) # Data manipulation and visualization library(data.table) # Fast data manipulation library(openxlsx) # Reading Excel files library(magrittr) # Pipe operator library(lme4) # For fitting linear mixed-effects models library(nnet) # For fitting neural networks cat(&quot;\\f&quot;) # Clears console output Data Reading # Reading the preprocessed census data file containing information about households. censo_vivienda &lt;- readRDS(&quot;Recursos/06_Model_Multinomial/Data/02_censo_vivienda_personas.rds&quot;) # Filtering the census data to retain relevant columns for age and gender analysis. censo_vivienda_age_gender &lt;- censo_vivienda %&gt;% filter( !greenpoint2 %in% c(&quot;Sin informacion pero n&gt;0&quot;, &quot;Sin informacion pero n&gt;=0&quot;)) %&gt;% dplyr::select(PROV_ID, HOMBRES_GRUPO1_sum:MUJERES_GRUPO20_sum) Data Preparation: The code creates a new dataset censo_vivienda_edad_sexo by filtering out specific entries from censo_vivienda. It selects columns related to age and gender groups and provinces. This filtered dataset is then aggregated at the PROV_ID level using the summarise_if function. # Summarizing the age and gender data by grouping it based on province (PROV_ID). censo_personas &lt;- censo_vivienda_age_gender %&gt;% group_by(PROV_ID) %&gt;% summarise_if(is.numeric, sum) Multinomial Model: A multinomial model is created using the multinom function. It predicts the distribution of age and gender groups within households based on the province (PROV_ID). The model is stored in the variable model. # Fitting a multinomial model to estimate the distribution of age and gender within households, # using province as the predictor. model &lt;- multinom( censo_personas[,-1] %&gt;% as.matrix() ~ censo_personas$PROV_ID) ## # weights: 320 (273 variable) ## initial value 9098525.262706 ## iter 10 value 8725423.620363 ## iter 20 value 8724936.747528 ## iter 30 value 8724362.718376 ## iter 40 value 8723575.429512 ## iter 50 value 8719973.199033 ## iter 60 value 8714415.379026 ## iter 70 value 8692534.417677 ## iter 80 value 8664249.357504 ## iter 90 value 8663007.095699 ## iter 100 value 8662293.319310 ## final value 8662293.319310 ## stopped after 100 iterations Model Prediction The predict function is used to predict the distribution probabilities for the multinomial model. The prediction results are not displayed here but can be obtained using the predict function. # Predicting the distribution probabilities using the fitted model. predict(model,type = &quot;probs&quot;) Saving Model The trained multinomial model is saved as an RDS file (“Recursos/06_Model_Multinomial/Data/Modelo_multinomial.rds”) using the saveRDS function. # Saving the fitted multinomial model to a file. saveRDS(model, &quot;Recursos/06_Model_Multinomial/Data/Multinomial_model.rds&quot;) "],["creating-the-census-base-with-predictions-from-the-multinomial-model.html", "Chapter 10 Creating the census base with predictions from the multinomial model", " Chapter 10 Creating the census base with predictions from the multinomial model ### Cleaning R environment ### rm(list = ls()) ### Libraries ### library(tidyverse) # Set of packages for data manipulation and visualization library(data.table) # For efficient data operations library(openxlsx) # Excel file manipulation library(magrittr) # Pipe operations (%&gt;%) library(lme4) # Linear mixed-effects models cat(&quot;\\f&quot;) # Page break in R console Reading the census data. censo_vivienda &lt;- readRDS(&quot;Recursos/06_Model_Multinomial/Data/02_censo_vivienda_personas.rds&quot;) # Reading the previously created multinomial model. model &lt;- readRDS(&quot;Recursos/06_Model_Multinomial/Data/Multinomial_model.rds&quot;) # Calculate probabilities for each outcome category using the model. probabilidad &lt;- predict(model, type = &quot;probs&quot;) %&gt;% as.data.frame() %&gt;% select_all(~paste0(.,&quot;_prob&quot;)) %&gt;% mutate(PROV_ID = as.character(1:7)) # Create a copy of the census data to work with. censo_vivienda_pred &lt;- censo_vivienda # Calculate the sum of predicted counts. sum(censo_vivienda_pred$pred_conteos) # Identify column names corresponding to age groups. var_grupo &lt;- grep(x = names(censo_vivienda_pred), pattern = &quot;*_GRUPO\\\\d{,2}_sum$&quot;, value = TRUE) "],["results-by-provinces.html", "10.1 Results by Provinces", " 10.1 Results by Provinces PROV_ID = 1 # Filter census data for PROV_ID = 1 and specific greenpoint2 categories. PROV_1 &lt;- censo_vivienda_pred %&gt;% filter(PROV_ID == &quot;1&quot; , greenpoint2 %in% c(&quot;Sin informacion pero n&gt;=0&quot;, &quot;Sin informacion pero n&gt;0&quot;)) # Calculate predicted counts for each age group in PROV_1. PROV_1[, var_grupo] &lt;- matrix(PROV_1$pred_conteos, nrow = nrow(PROV_1)) %*% matrix(as.numeric(probabilidad[1, paste0(var_grupo, &quot;_prob&quot;)]), ncol = 40) # Calculate lower bound of predicted counts for each age group in PROV_1. PROV_1[,paste0(var_grupo, &quot;_MEInf&quot;) ] &lt;- matrix(PROV_1$MEInf_pred_conteos,nrow = nrow(PROV_1)) %*% matrix(as.numeric(probabilidad[1,paste0(var_grupo, &quot;_prob&quot;) ]),ncol = 40 ) # Calculate upper bound of predicted counts for each age group in PROV_1. PROV_1[,paste0(var_grupo, &quot;_MESup&quot;) ] &lt;- matrix(PROV_1$MESup_pred_conteos,nrow = nrow(PROV_1)) %*% matrix(as.numeric(probabilidad[1,paste0(var_grupo, &quot;_prob&quot;) ]),ncol = 40 ) # Calculate the sum of predicted counts for each age group in PROV_1. rowSums(PROV_1[,var_grupo]) # Calculate the sum of predicted counts in PROV_1. sum(PROV_1[,var_grupo]) sum(PROV_1$pred_conteos) # Calculate the sum of lower bounds of predicted counts in PROV_1. sum(PROV_1[,paste0(var_grupo, &quot;_MEInf&quot;) ]) sum(PROV_1$MEInf_pred_conteos) # Calculate the sum of upper bounds of predicted counts in PROV_1. sum(PROV_1[,paste0(var_grupo, &quot;_MESup&quot;) ]) sum(PROV_1$MESup_pred_conteos) PROV_ID = 2 # Filter census data for PROV_ID = 2 and specific greenpoint2 categories. PROV_2 &lt;- censo_vivienda_pred %&gt;% filter(PROV_ID == &quot;2&quot; , greenpoint2 %in% c(&quot;Sin informacion pero n&gt;=0&quot;, &quot;Sin informacion pero n&gt;0&quot;)) # Calculate predicted counts for each age group in PROV_2. PROV_2[,var_grupo] &lt;- matrix(PROV_2$pred_conteos,nrow = nrow(PROV_2)) %*% matrix(as.numeric(probabilidad[2,paste0(var_grupo, &quot;_prob&quot;) ]),ncol = 40 ) # Calculate lower bound of predicted counts for each age group in PROV_2. PROV_2[,paste0(var_grupo, &quot;_MEInf&quot;) ] &lt;- matrix(PROV_2$MEInf_pred_conteos,nrow = nrow(PROV_2)) %*% matrix(as.numeric(probabilidad[2,paste0(var_grupo, &quot;_prob&quot;) ]),ncol = 40 ) # Calculate upper bound of predicted counts for each age group in PROV_2. PROV_2[,paste0(var_grupo, &quot;_MESup&quot;) ] &lt;- matrix(PROV_2$MESup_pred_conteos,nrow = nrow(PROV_2)) %*% matrix(as.numeric(probabilidad[2,paste0(var_grupo, &quot;_prob&quot;) ]),ncol = 40 ) # Calculate the sum of predicted counts for each age group in PROV_2. rowSums(PROV_2[,var_grupo]) # Calculate the sum of predicted counts in PROV_2. sum(PROV_2[,var_grupo]) sum(PROV_2$pred_conteos) # Calculate the sum of lower bounds of predicted counts in PROV_2. sum(PROV_2[,paste0(var_grupo, &quot;_MEInf&quot;) ]) sum(PROV_2$MEInf_pred_conteos) # Calculate the sum of upper bounds of predicted counts in PROV_2. sum(PROV_2[,paste0(var_grupo, &quot;_MESup&quot;) ]) sum(PROV_2$MESup_pred_conteos) PROV_ID = 3 PROV_3 &lt;- censo_vivienda_pred %&gt;% filter( PROV_ID == &quot;3&quot; , greenpoint2 %in% c(&quot;Sin informacion pero n&gt;=0&quot;, &quot;Sin informacion pero n&gt;0&quot;) ) # Display summary statistics of the selected age group data in PROV_3. summary(PROV_3[, var_grupo]) # Calculate predicted counts for each age group in PROV_3. PROV_3[, var_grupo] &lt;- matrix(PROV_3$pred_conteos, nrow = nrow(PROV_3)) %*% matrix(as.numeric(probabilidad[3, paste0(var_grupo, &quot;_prob&quot;)]), ncol = 40) # Calculate lower bound of predicted counts for each age group in PROV_3. PROV_3[, paste0(var_grupo, &quot;_MEInf&quot;)] &lt;- matrix(PROV_3$MEInf_pred_conteos, nrow = nrow(PROV_3)) %*% matrix(as.numeric(probabilidad[3, paste0(var_grupo, &quot;_prob&quot;)]), ncol = 40) # Calculate upper bound of predicted counts for each age group in PROV_3. PROV_3[, paste0(var_grupo, &quot;_MESup&quot;)] &lt;- matrix(PROV_3$MESup_pred_conteos, nrow = nrow(PROV_3)) %*% matrix(as.numeric(probabilidad[3, paste0(var_grupo, &quot;_prob&quot;)]), ncol = 40) # Calculate the sum of predicted counts for each age group in PROV_3. rowSums(PROV_3[,var_grupo]) # Calculate the sum of predicted counts in PROV_3. sum(PROV_3[,var_grupo]) sum(PROV_3$pred_conteos) # Calculate the sum of lower bounds of predicted counts in PROV_3. sum(PROV_3[,paste0(var_grupo, &quot;_MEInf&quot;) ]) sum(PROV_3$MEInf_pred_conteos) # Calculate the sum of upper bounds of predicted counts in PROV_3. sum(PROV_3[,paste0(var_grupo, &quot;_MESup&quot;) ]) sum(PROV_3$MESup_pred_conteos) PROV_ID = 4 PROV_4 &lt;- censo_vivienda_pred %&gt;% filter( PROV_ID == &quot;4&quot; , greenpoint2 %in% c(&quot;Sin informacion pero n&gt;=0&quot;, &quot;Sin informacion pero n&gt;0&quot;) ) summary(PROV_4[,var_grupo]) # Calculate predicted counts for each age group in PROV_4. PROV_4[, var_grupo] &lt;- matrix(PROV_4$pred_conteos, nrow = nrow(PROV_4)) %*% matrix(as.numeric(probabilidad[4, paste0(var_grupo, &quot;_prob&quot;)]), ncol = 40) # Calculate lower bound of predicted counts for each age group in PROV_4. PROV_4[, paste0(var_grupo, &quot;_MEInf&quot;)] &lt;- matrix(PROV_4$MEInf_pred_conteos, nrow = nrow(PROV_4)) %*% matrix(as.numeric(probabilidad[4, paste0(var_grupo, &quot;_prob&quot;)]), ncol = 40) # Calculate upper bound of predicted counts for each age group in PROV_4. PROV_4[, paste0(var_grupo, &quot;_MESup&quot;)] &lt;- matrix(PROV_4$MESup_pred_conteos, nrow = nrow(PROV_4)) %*% matrix(as.numeric(probabilidad[4, paste0(var_grupo, &quot;_prob&quot;)]), ncol = 40) # Calculate the sum of predicted counts for each age group in PROV_4. rowSums(PROV_4[,var_grupo]) # Calculate the sum of predicted counts in PROV_4. sum(PROV_4[,var_grupo]) sum(PROV_4$pred_conteos) # Calculate the sum of lower bounds of predicted counts in PROV_4. sum(PROV_4[,paste0(var_grupo, &quot;_MEInf&quot;) ]) sum(PROV_4$MEInf_pred_conteos) # Calculate the sum of upper bounds of predicted counts in PROV_4. sum(PROV_4[,paste0(var_grupo, &quot;_MESup&quot;) ]) sum(PROV_4$MESup_pred_conteos) PROV_ID = 5 PROV_5 &lt;- censo_vivienda_pred %&gt;% filter(PROV_ID == &quot;5&quot; , greenpoint2 %in% c(&quot;Sin informacion pero n&gt;=0&quot;, &quot;Sin informacion pero n&gt;0&quot;)) summary(PROV_5[,var_grupo]) # Calculate predicted counts for each age group in PROV_5. PROV_5[,var_grupo] &lt;- matrix(PROV_5$pred_conteos,nrow = nrow(PROV_5)) %*% matrix(as.numeric(probabilidad[5,paste0(var_grupo, &quot;_prob&quot;) ]),ncol = 40 ) # Calculate lower bound of predicted counts for each age group in PROV_5. PROV_5[,paste0(var_grupo, &quot;_MEInf&quot;)] &lt;- matrix(PROV_5$MEInf_pred_conteos,nrow = nrow(PROV_5)) %*% matrix(as.numeric(probabilidad[5,paste0(var_grupo, &quot;_prob&quot;) ]),ncol = 40 ) # Calculate upper bound of predicted counts for each age group in PROV_5. PROV_5[,paste0(var_grupo, &quot;_MESup&quot;)] &lt;- matrix(PROV_5$MESup_pred_conteos,nrow = nrow(PROV_5)) %*% matrix(as.numeric(probabilidad[5,paste0(var_grupo, &quot;_prob&quot;) ]),ncol = 40 ) # Calculate the sum of predicted counts for each age group in PROV_5. rowSums(PROV_5[,var_grupo]) # Calculate the sum of predicted counts in PROV_5. sum(PROV_5[,var_grupo]) sum(PROV_5$pred_conteos) # Calculate the sum of lower bounds of predicted counts in PROV_5. sum(PROV_5[,paste0(var_grupo, &quot;_MEInf&quot;) ]) sum(PROV_5$MEInf_pred_conteos) # Calculate the sum of upper bounds of predicted counts in PROV_5. sum(PROV_5[,paste0(var_grupo, &quot;_MESup&quot;) ]) sum(PROV_5$MESup_pred_conteos) PROV_ID = 6 PROV_6 &lt;- censo_vivienda_pred %&gt;% filter( PROV_ID == &quot;6&quot; , greenpoint2 %in% c(&quot;Sin informacion pero n&gt;=0&quot;, &quot;Sin informacion pero n&gt;0&quot;) ) summary(PROV_6[,var_grupo]) # Calculate predicted counts for each age group in PROV_6. PROV_6[, var_grupo] &lt;- matrix(PROV_6$pred_conteos, nrow = nrow(PROV_6)) %*% matrix(as.numeric(probabilidad[6, paste0(var_grupo, &quot;_prob&quot;)]), ncol = 40) # Calculate lower bound of predicted counts for each age group in PROV_6. PROV_6[, paste0(var_grupo, &quot;_MEInf&quot;)] &lt;- matrix(PROV_6$MEInf_pred_conteos, nrow = nrow(PROV_6)) %*% matrix(as.numeric(probabilidad[6, paste0(var_grupo, &quot;_prob&quot;)]), ncol = 40) # Calculate upper bound of predicted counts for each age group in PROV_6. PROV_6[, paste0(var_grupo, &quot;_MESup&quot;)] &lt;- matrix(PROV_6$MESup_pred_conteos, nrow = nrow(PROV_6)) %*% matrix(as.numeric(probabilidad[6, paste0(var_grupo, &quot;_prob&quot;)]), ncol = 40) # Calculate the sum of predicted counts for each age group in PROV_6. rowSums(PROV_6[,var_grupo]) # Calculate the sum of predicted counts in PROV_6. sum(PROV_6[,var_grupo]) sum(PROV_6$pred_conteos) # Calculate the sum of lower bounds of predicted counts in PROV_6. sum(PROV_6[,paste0(var_grupo, &quot;_MEInf&quot;) ]) sum(PROV_6$MEInf_pred_conteos) # Calculate the sum of upper bounds of predicted counts in PROV_6. sum(PROV_6[,paste0(var_grupo, &quot;_MESup&quot;) ]) sum(PROV_6$MESup_pred_conteos) PROV_ID = 7 PROV_7 &lt;- censo_vivienda_pred %&gt;% filter( PROV_ID == &quot;7&quot; , greenpoint2 %in% c(&quot;Sin informacion pero n&gt;=0&quot;, &quot;Sin informacion pero n&gt;0&quot;) ) summary(PROV_7[, var_grupo]) # Calculate predicted counts for each age group in PROV_7. PROV_7[, var_grupo] &lt;- matrix(PROV_7$pred_conteos, nrow = nrow(PROV_7)) %*% matrix(as.numeric(probabilidad[7, paste0(var_grupo, &quot;_prob&quot;)]), ncol = 40) # Calculate lower bound of predicted counts for each age group in PROV_7. PROV_7[, paste0(var_grupo, &quot;_MEInf&quot;)] &lt;- matrix(PROV_7$MEInf_pred_conteos, nrow = nrow(PROV_7)) %*% matrix(as.numeric(probabilidad[7, paste0(var_grupo, &quot;_prob&quot;)]), ncol = 40) # Calculate upper bound of predicted counts for each age group in PROV_7. PROV_7[, paste0(var_grupo, &quot;_MESup&quot;)] &lt;- matrix(PROV_7$MESup_pred_conteos, nrow = nrow(PROV_7)) %*% matrix(as.numeric(probabilidad[7, paste0(var_grupo, &quot;_prob&quot;)]), ncol = 40) # Calculate the sum of predicted counts for each age group in PROV_7. rowSums(PROV_7[, var_grupo]) # Calculate the sum of predicted counts in PROV_7. sum(PROV_7[, var_grupo]) sum(PROV_7$pred_conteos) # Calculate the sum of lower bounds of predicted counts in PROV_7. sum(PROV_7[, paste0(var_grupo, &quot;_MEInf&quot;)]) sum(PROV_7$MEInf_pred_conteos) # Calculate the sum of upper bounds of predicted counts in PROV_7. sum(PROV_7[, paste0(var_grupo, &quot;_MESup&quot;)]) sum(PROV_7$MESup_pred_conteos) Combine data frames of provinces with missing information prov_sin_informacion &lt;- list( PROV_1, PROV_2, PROV_3, PROV_4, PROV_5, PROV_6, PROV_7) %&gt;% bind_rows() some validations # Filter and gather data for all provinces with missing information PROV_todas &lt;- censo_vivienda_pred %&gt;% filter(greenpoint2 %in% c(&quot;Sin informacion pero n&gt;=0&quot;, &quot;Sin informacion pero n&gt;0&quot;)) # Calculate row sums and total sum of predicted counts for provinces with missing information rowSums(prov_sin_informacion[, var_grupo]) sum(prov_sin_informacion[, var_grupo]) sum(PROV_todas$pred_conteos) # Filter data for provinces with complete census information PROV_censada &lt;- censo_vivienda_pred %&gt;% filter(!greenpoint2 %in% c(&quot;Sin informacion pero n&gt;=0&quot;, &quot;Sin informacion pero n&gt;0&quot;)) Initialize columns for lower and upper bounds of predicted counts # in provinces with complete census PROV_censada[,paste0(var_grupo, &quot;_MEInf&quot;)] &lt;- 0 PROV_censada[,paste0(var_grupo, &quot;_MESup&quot;)] &lt;- 0 # Combine data frames of provinces with complete and missing information for each age group censo_vivienda_grupo_edad &lt;- bind_rows(PROV_censada, prov_sin_informacion) %&gt;% dplyr::select(un_ID, var_grupo, paste0(var_grupo, &quot;_MEInf&quot;), paste0(var_grupo, &quot;_MESup&quot;)) # Inner join the census data with the grouped age data and save the result readRDS(&quot;Recursos/06_Model_Multinomial/Data/04_censo_vivienda_personas.rds&quot;) %&gt;% inner_join(censo_vivienda_grupo_edad) %&gt;% saveRDS(&quot;Recursos/06_Model_Multinomial/Data/05_censo_vivienda_personas_grupo_edad.rds&quot;) "],["aggregated-estimations.html", "Chapter 11 Aggregated Estimations", " Chapter 11 Aggregated Estimations In this section, we illustrate the methodology employed to derive estimations for various aggregation levels, utilizing a set of custom functions tailored to this specific dataset. These functions facilitate the process of generating predictions and visualizations, allowing us to effectively analyze population estimates. ### Cleaning R environment ### rm(list = ls()) ### Libraries ### library(tidyverse) library(data.table) library(openxlsx) library(magrittr) library(lme4) library(rstan) library(rstanarm) source(&quot;Recursos/07_Resultados/Rcodes/01_Agregados.R&quot;) cat(&quot;\\f&quot;) plot_densidad: This function plots the density of a normal distribution with specified mean and standard deviation. #’ Additionally, it highlights a specific interval of the distribution with shaded area and segments in the plot. Pred_desocupado: This function performs calculations and visualizations related to unemployment data in a census. Pred_totPob: This function performs calculations and visualizations related to total population data in a census. plot_piramide_pob: Generates a population pyramid plot with bars and confidence intervals. piramide_pob: Calculates and visualizes the population pyramid from census data. Reading the census data. censo_vivienda &lt;- readRDS(&quot;Recursos/07_Resultados/Data/05_censo_vivienda_personas_grupo_edad.rds&quot;) "],["prediction-of-the-unoccupied-household-rate.html", "11.1 Prediction of the unoccupied household rate", " 11.1 Prediction of the unoccupied household rate p1 &lt;- Pred_desocupado(censo_vivienda, agrega = NULL, Plot = TRUE, filtro = NULL) tba(p1) total Porcen LimInf LimSup Len_IC SE 170596 9.6495 7.8008 15.6923 7.8915 2.0131 Pred_desocupado(censo_vivienda, agrega = &quot;PROV_ID&quot;) %&gt;% tba() PROV_ID total Porcen LimInf LimSup Len_IC SE 1 32511.23 6.1292 5.3021 9.9408 4.6388 1.1834 2 32237.42 8.7274 6.9849 15.4285 8.4436 2.1540 3 12311.19 6.6667 5.8987 10.1143 4.2157 1.0754 4 10280.48 5.9283 4.7734 11.5613 6.7879 1.7316 5 26994.96 18.0624 12.7344 29.9794 17.2451 4.3993 6 36611.60 18.9245 15.2168 27.3844 12.1677 3.1040 7 19649.10 11.7585 9.7813 18.6686 8.8873 2.2672 Pred_desocupado(censo_vivienda, agrega = &quot;CANT_ID&quot;) %&gt;% head(20) %&gt;% tba() CANT_ID total Porcen LimInf LimSup Len_IC SE 101 4704.3753 4.7950 3.8687 9.8229 5.9542 1.5189 102 904.1052 3.7886 3.3167 6.7276 3.4109 0.8701 103 2326.4401 3.3440 2.7587 6.1325 3.3738 0.8607 104 1302.8111 8.7484 7.9692 11.9333 3.9640 1.0112 105 1529.1408 21.3061 18.9280 27.2467 8.3187 2.1221 106 1303.6682 5.8785 4.8028 11.5253 6.7225 1.7149 107 1329.3520 10.2038 9.0813 14.9483 5.8670 1.4967 108 1191.2768 2.8692 2.4607 5.4149 2.9541 0.7536 109 906.0511 3.9678 3.2436 8.0984 4.8548 1.2385 110 1071.5921 4.1771 3.4247 8.4890 5.0643 1.2919 111 629.5658 2.8960 2.6462 4.4006 1.7544 0.4476 112 1188.2365 13.0146 11.3643 17.6408 6.2765 1.6011 113 1338.6913 6.3086 5.8192 8.6923 2.8730 0.7329 114 842.5751 3.6877 3.3801 5.6110 2.2309 0.5691 115 860.8183 4.3823 3.7200 8.1193 4.3993 1.1223 116 793.8269 21.9047 19.4176 28.8232 9.4056 2.3994 117 1028.0808 26.3206 21.9920 34.4197 12.4277 3.1703 118 671.6741 2.7472 2.0860 7.0503 4.9643 1.2664 119 7588.2603 12.7034 11.5004 16.7497 5.2493 1.3391 120 1000.6907 18.8206 16.7473 24.5034 7.7561 1.9786 Pred_desocupado(censo_vivienda, agrega = &quot;DIST_ID&quot;) %&gt;% head(20) %&gt;% tba() DIST_ID total Porcen LimInf LimSup Len_IC SE 10101 259.9300 17.8769 14.8636 26.9333 12.0698 3.0790 10102 242.6324 5.0464 3.5641 13.1547 9.5906 2.4466 10103 325.8134 5.1132 4.0814 10.8335 6.7521 1.7225 10104 525.2972 10.0574 8.1812 17.8866 9.7055 2.4759 10105 622.1515 9.1817 8.2921 13.0957 4.8036 1.2254 10106 260.6938 3.7700 3.5110 5.3212 1.8102 0.4618 10107 162.3146 1.4402 1.2844 2.5274 1.2430 0.3171 10108 357.2789 8.5781 7.3951 13.9366 6.5415 1.6688 10109 855.4386 4.0477 2.5018 13.3719 10.8702 2.7730 10110 626.1736 3.8801 3.3093 7.2516 3.9423 1.0057 10111 466.6511 3.3683 2.8908 6.2913 3.4005 0.8675 10201 193.1655 4.6201 4.3063 6.4739 2.1676 0.5530 10202 200.4354 2.3603 1.8712 5.6881 3.8169 0.9737 10203 510.5042 4.5617 4.0439 7.6111 3.5672 0.9100 10301 194.1877 1.6909 1.3653 3.8786 2.5133 0.6411 10302 313.4239 2.8655 2.5148 5.0408 2.5260 0.6444 10303 178.4447 3.0514 2.7513 4.8938 2.1425 0.5466 10304 160.4965 3.4126 3.0166 5.7444 2.7278 0.6959 10305 122.9297 3.7331 3.3143 6.2113 2.8970 0.7390 10306 135.8658 9.8668 9.0079 13.5051 4.4971 1.1472 p1 &lt;- Pred_desocupado(censo_vivienda, agrega = &quot;DIST_ID&quot;, Plot = TRUE, filtro = &quot;10101&quot;) tba(p1) DIST_ID total Porcen LimInf LimSup Len_IC SE 10101 259.93 17.8769 14.8636 26.9333 12.0698 3.079 "],["total-population-prediction.html", "11.2 Total Population Prediction", " 11.2 Total Population Prediction ## National level result p1 &lt;- Pred_totPob(censo_vivienda, agrega = NULL, Plot = TRUE) tba(p1) total SE LimInf LimSup Len_IC 4946930 142207.6 4713709 5180150 466441.1 ## Provincial level result Pred_totPob(censo_vivienda, agrega = &quot;PROV_ID&quot;, Plot = FALSE) %&gt;% tba() PROV_ID total SE LimInf LimSup Len_IC 1 1530576.8 41244.79 1462935.4 1598218.3 135282.90 2 1081285.5 34928.27 1024003.2 1138567.9 114564.74 3 556988.1 12840.36 535929.9 578046.3 42116.39 4 488545.0 19039.91 457319.5 519770.5 62450.91 5 376403.3 11948.63 356807.5 395999.0 39191.51 6 462538.7 12163.66 442590.3 482487.1 39896.81 7 450592.3 10042.02 434123.4 467061.2 32937.82 p1 &lt;- Pred_totPob(censo_vivienda, agrega = &quot;PROV_ID&quot;, filtro = &quot;1&quot;, Plot = TRUE) tba(p1) PROV_ID total SE LimInf LimSup Len_IC 1 1530577 41244.79 1462935 1598218 135282.9 ## Canton level result Pred_totPob(censo_vivienda, agrega = &quot;CANT_ID&quot;, Plot = FALSE, filtro = NULL) %&gt;% head(10) %&gt;% tba() CANT_ID total SE LimInf LimSup Len_IC 101 281842.11 6236.7553 271613.83 292070.39 20456.5574 102 68507.40 1866.2504 65446.75 71568.05 6121.3012 103 228526.32 6772.9845 217418.63 239634.02 22215.3891 104 39408.22 869.5673 37982.13 40834.31 2852.1809 105 17538.35 304.1923 17039.48 18037.23 997.7509 106 64000.23 2099.7100 60556.71 67443.75 6887.0487 107 33842.91 912.9030 32345.75 35340.08 2994.3218 108 123340.97 3504.8231 117593.06 129088.88 11495.8199 109 66265.86 3008.8440 61331.36 71200.37 9869.0085 110 83597.98 2654.4832 79244.62 87951.33 8706.7048 ## District level result p1 &lt;- Pred_totPob(censo_vivienda, agrega = &quot;DIST_ID&quot;, Plot = TRUE, filtro = &quot;10110&quot;) tba(p1) DIST_ID total SE LimInf LimSup Len_IC 10110 48209.95 701.333 47059.76 49360.13 2300.372 "],["prediction-of-total-population-by-age-and-gender.html", "11.3 Prediction of Total Population by Age and Gender", " 11.3 Prediction of Total Population by Age and Gender piramide_pob( censo = censo_vivienda, Plot = FALSE, agrega = NULL, filtro = NULL ) %&gt;% tba() grupo total SE LimInf LimSup Len_IC HOMBRES_GRUPO1 132715.613 3538.5296 126912.424 138518.801 11606.3771 HOMBRES_GRUPO2 167537.132 4578.1619 160028.946 175045.318 15016.3711 HOMBRES_GRUPO3 182328.109 5216.9996 173772.230 190883.989 17111.7587 HOMBRES_GRUPO4 180165.851 5189.0721 171655.772 188675.929 17020.1564 HOMBRES_GRUPO5 191782.430 5695.3272 182442.094 201122.767 18680.6731 HOMBRES_GRUPO6 196681.972 5950.4734 186923.195 206440.748 19517.5529 HOMBRES_GRUPO7 197411.070 5831.3041 187847.732 206974.409 19126.6774 HOMBRES_GRUPO8 191008.448 5694.5553 181669.377 200347.519 18678.1415 HOMBRES_GRUPO9 156522.833 4345.9776 149395.430 163650.236 14254.8066 HOMBRES_GRUPO10 136569.728 3926.0488 130131.008 143008.448 12877.4402 HOMBRES_GRUPO11 135995.420 3837.4780 129701.956 142288.884 12586.9279 HOMBRES_GRUPO12 131888.989 3722.7379 125783.699 137994.279 12210.5804 HOMBRES_GRUPO13 124940.164 3636.1568 118976.867 130903.461 11926.5942 HOMBRES_GRUPO14 106462.067 3190.2168 101230.112 111694.023 10463.9111 HOMBRES_GRUPO15 72514.563 2030.2378 69184.973 75844.153 6659.1799 HOMBRES_GRUPO16 46304.067 1199.7564 44336.467 48271.668 3935.2009 HOMBRES_GRUPO17 29636.441 776.7665 28362.544 30910.338 2547.7942 HOMBRES_GRUPO18 17569.383 501.4791 16746.957 18391.809 1644.8513 HOMBRES_GRUPO19 10052.158 364.0234 9455.160 10649.157 1193.9969 HOMBRES_GRUPO20 5693.759 252.7038 5279.325 6108.193 828.8686 MUJERES_GRUPO1 133932.122 3859.4112 127602.687 140261.556 12658.8686 MUJERES_GRUPO2 159219.926 4341.0499 152100.604 166339.247 14238.6437 MUJERES_GRUPO3 168190.704 4687.5265 160503.161 175878.247 15375.0868 MUJERES_GRUPO4 170967.814 4858.5844 162999.736 178935.892 15936.1569 MUJERES_GRUPO5 191028.640 5721.8012 181644.886 200412.394 18767.5078 MUJERES_GRUPO6 196498.415 5882.7348 186850.730 206146.100 19295.3702 MUJERES_GRUPO7 202199.447 5917.3901 192494.927 211903.966 19409.0394 MUJERES_GRUPO8 202895.997 5970.9001 193103.721 212688.273 19584.5523 MUJERES_GRUPO9 180427.823 5269.6683 171785.567 189070.079 17284.5122 MUJERES_GRUPO10 148689.282 4216.8396 141773.665 155604.899 13831.2340 MUJERES_GRUPO11 151500.141 4202.3081 144608.356 158391.927 13783.5705 MUJERES_GRUPO12 150358.720 4204.6298 143463.127 157254.313 13791.1857 MUJERES_GRUPO13 141620.661 4066.5684 134951.489 148289.833 13338.3444 MUJERES_GRUPO14 119528.269 3458.0552 113857.058 125199.479 11342.4210 MUJERES_GRUPO15 85609.538 2485.4344 81533.426 89685.650 8152.2249 MUJERES_GRUPO16 54136.719 1433.8634 51785.183 56488.255 4703.0721 MUJERES_GRUPO17 35611.090 934.7107 34078.165 37144.016 3065.8511 MUJERES_GRUPO18 21527.179 582.6755 20571.591 22482.766 1911.1756 MUJERES_GRUPO19 12157.783 374.7621 11543.173 12772.393 1229.2197 MUJERES_GRUPO20 6679.249 260.7253 6251.659 7106.838 855.1791 p1 &lt;- piramide_pob( censo = censo_vivienda, Plot = TRUE, agrega = NULL, filtro = NULL) p1 &lt;- piramide_pob( censo = censo_vivienda, Plot = FALSE, agrega = &quot;PROV_ID&quot;, filtro = NULL ) p1 &lt;- piramide_pob( censo = censo_vivienda, Plot = TRUE, agrega = &quot;PROV_ID&quot;, filtro = &quot;1&quot; ) p1&lt;- piramide_pob( censo = censo_vivienda, Plot = TRUE, agrega = &quot;PROV_ID&quot;, filtro = &quot;2&quot; ) p1 &lt;- piramide_pob( censo = censo_vivienda, Plot = TRUE, agrega = &quot;CANT_ID&quot;, filtro = &quot;101&quot; ) p1&lt;- piramide_pob( censo = censo_vivienda, Plot = TRUE, agrega = &quot;CANT_ID&quot;, filtro = &quot;102&quot; ) "]]
