[["index.html", "Workshop Materials", " Workshop Materials In the following link, you will find the R routines developed for the workshop.. Descargar "],["installation-of-libraries-and-required-software-for-bayesian-area-models..html", "1 Installation of Libraries and Required Software for Bayesian Area Models. ", " 1 Installation of Libraries and Required Software for Bayesian Area Models. "],["step-1-installing-software.html", "1.1 Step 1: Installing Software", " 1.1 Step 1: Installing Software Below is a list of the necessary software for the proper development of the training. It is recommended to install these packages before starting with the practical development. Download and install Rbase (https://cran.r-project.org/bin/windows/base/) Download and install Rtools (https://cran.r-project.org/bin/windows/Rtools/) Download and install Rstudio (https://posit.co/download/rstudio-desktop/) Download and install Quarto (https://quarto.org/docs/get-started/) Download and install Anaconda (https://www.anaconda.com/products/individual) Download and install Google Cloud (https://cloud.google.com/sdk/docs/install?hl=es-419) "],["step-2-installing-the-following-libraries-in-r..html", "1.2 Step 2: Installing the following libraries in R.", " 1.2 Step 2: Installing the following libraries in R. 1.2.1 Data Visualization and Manipulation: tidyverse: A collection of packages for data manipulation and visualization. magrittr: Provides a pipe %&gt;% operator to make code more readable. scales: Tools for scaling visualizations, like adjusting axis breaks. sf: For working with spatial data and maps. tmap: Creates thematic maps and overlays. 1.2.2 Statistical Modeling: lme4: Fits linear and generalized linear mixed-effects models. rstanarm: Fits Bayesian models using Stan for various statistical tasks. 1.2.3 Survey Analysis: srvyr: Tools for working with survey data alongside the dplyr package. survey: For analyzing complex survey data. 1.2.4 Data Manipulation and Transformation: dplyr: Data manipulation tools. tidyr: Tools for reshaping and tidying data. reshape2: Reshaping data frames. 1.2.5 Bayesian Analysis: bayesplot: Visualization of Bayesian models. posterior: Tools for working with posterior distributions. rstan: R interface to Stan, a platform for Bayesian modeling. 1.2.6 Geospatial Analysis: rgee: Interface to Google Earth Engine. trafo: Tools for transforming spatial data. maptools: Tools for reading and manipulating geographic data. usmap: Maps of the United States. 1.2.7 Miscellaneous: sampling: Tools for survey sampling. haven: For reading and writing SPSS, Stata, and SAS files. RColorBrewer: Provides color palettes. kableExtra: Enhances table rendering in R Markdown. formatR: Formatting tools for R code. printr: Custom printing of data frames and tables. remotes: Tools for package development and installation. latex2exp: Converts LaTeX code into expressions. To install each package, use the command install.packages(\"package_name\"). install.packages(&quot;patchwork&quot;) install.packages(&quot;lme4&quot;) install.packages(&quot;tidyverse&quot;) install.packages(&quot;rstanarm&quot;) install.packages(&quot;magrittr&quot;) install.packages(&quot;reticulate&quot;) install.packages(&quot;rgee&quot;) install.packages(&quot;sf&quot;) install.packages(&quot;tmap&quot;) install.packages(&quot;trafo&quot;) install.packages(&quot;scales&quot;) install.packages(&quot;srvyr&quot;) install.packages(&quot;survey&quot;) install.packages(&quot;haven&quot;) install.packages(&quot;sampling&quot;) install.packages(&quot;RColorBrewer&quot;) install.packages(&quot;maptools&quot;) install.packages(&quot;data.table&quot;) install.packages(&quot;forcats&quot;) install.packages(&quot;tidyr&quot;) install.packages(&quot;reshape2&quot;) install.packages(&quot;bayesplot&quot;) install.packages(&quot;posterior&quot;) install.packages(&quot;gridExtra&quot;) install.packages(&quot;ggalt&quot;) install.packages(&quot;usmap&quot;) install.packages(&quot;kableExtra&quot;) install.packages(&quot;formatR&quot;) install.packages(&quot;printr&quot;) install.packages(&quot;remotes&quot;) install.packages(&quot;latex2exp&quot;) install.packages(&quot;gtsummary&quot;) 1.2.8 Step-by-Step Guide to Install rstan Follow these steps to install the rstan package: Install Rtools (if using Windows): Download and install Rtools. Install StanHeaders: Open R or RStudio. Run the command: install.packages(\"StanHeaders\", repos = c(\"https://mc-stan.org/r-packages/\", getOption(\"repos\"))). Install rstan: Run the command: install.packages(\"rstan\", repos=c(\"https://mc-stan.org/r-packages/\", getOption(\"repos\"))). Verify the installation: Load the package using: library(rstan). Validate the installation: Run a simple model to ensure that rstan is working properly. You can use the example code provided in the documentation. Remember to follow these steps carefully to ensure a successful installation of rstan and its dependencies. "],["step-3-validation-of-installation---ensuring-proper-rstan-installation.html", "1.3 Step 3: Validation of Installation - Ensuring Proper rstan Installation", " 1.3 Step 3: Validation of Installation - Ensuring Proper rstan Installation library(rstan) library(posterior) library(bayesplot) # Example Stan code stan_code &lt;- &quot; parameters { real y[2]; } model { y[1] ~ normal(0, 1); y[2] ~ double_exponential(0, 2); } &quot; # Fit the model fit1 &lt;- stan(model_code = stan_code, iter = 10, verbose = FALSE) # Print the fit1 object print(fit1) # Further fitting and summarizing fit2 &lt;- stan(fit = fit1, iter = 10000, verbose = FALSE) summary(fit2)$summary In this section, we validate the correct installation of rstan by running a simple Bayesian model. We load the required packages, including rstan, posterior, and bayesplot. We then define a basic Stan model using the Stan code provided. We fit this model using stan() with a small number of iterations (iter = 10) to quickly verify the installation. Next, we demonstrate fitting the model further (fit2) with more iterations (iter = 10000) to show how to perform a more comprehensive analysis. The summary of the fitted model is printed using the summary() function. Make sure to evaluate this code in an R environment after installing the required packages to verify that rstan has been installed correctly and is functioning as expected. "],["step-4-creating-a-google-earth-engine-account.html", "1.4 Step 4: Creating a Google Earth Engine Account:", " 1.4 Step 4: Creating a Google Earth Engine Account: https://developers.google.com/earth-engine/datasets/ After successfully creating your account, it’s important to follow these steps to ensure everything is set up correctly: Access the provided link: https://developers.google.com/earth-engine/datasets/catalog/WHRC_biomass_tropical. Scroll down to the bottom of the page and locate the code displayed in the image below: Click on the Open in Code Editor option, which will open a new browser tab. Follow the instructions provided until you achieve the result shown in the image below: In the previous tab, find and click the Run button to obtain the outcome displayed in the image below: Note: Repeat the process as needed to ensure you achieve the desired outcome. "],["standardization-and-validation-of-available-census-data-variables.html", "2 Standardization and Validation of Available Census Data Variables", " 2 Standardization and Validation of Available Census Data Variables In the following code set, a series of processes are carried out for data cleaning and preparation. These steps include removing objects from the workspace, loading necessary libraries, reading census data, assigning missing values based on certain conditions, and calculating descriptive statistics for numeric and character variables. Additionally, adjustments are made to character variables to ensure consistent length. The final results are summarized in a data structure and saved in files for further analysis and reference. censo &lt;- readRDS(&quot;Recursos/01_Input_Validation/Data/Data_census_V2023-06-12.rds&quot;) %&gt;% select(-geometry) %&gt;% as.data.frame() # Creating a summary data frame for column names and their respective data types. resumen &lt;- data.frame(Nombre_Columna = names(censo)) resumen %&lt;&gt;% mutate(tipo = map_chr(Nombre_Columna, function(x) class(censo[[x]]))) resumen &lt;- readRDS(&quot;Recursos/01_Input_Validation/RecurseBooks/resumen1.rds&quot;) tba(head(resumen,10)) Nombre_Columna tipo un_ID integer PROV_ID character CANT_ID character DIST_ID character UGM_ID character LLAVEV character RESUL_ENTREVISTA_VIV integer TIPO_VIVIENDA_PRECENSO character V01_TIPO_VIVIENDA integer V02_OCUPACION_VIVIENDA integer "],["assigning-missing-values-to-the-h01a_total_personas-variable.html", "2.1 Assigning Missing Values to the ‘H01A_TOTAL_PERSONAS’ Variable", " 2.1 Assigning Missing Values to the ‘H01A_TOTAL_PERSONAS’ Variable In this section, actions related to the ‘H01A_TOTAL_PERSONAS’ variable are performed. Missing values (NA) are assigned to this variable based on specific conditions, which include: Dwellings that were not visited (category 9). Dwellings that rejected the visit or are pending (classification 2). Dwellings with other reasons (category 8). Next, a count of cases before and after the assignment of missing values is conducted. The ‘mutate’ function is used to create a new temporary column ‘H01A_TOTAL_PERSONAS_temp’ in which NA values are assigned according to the specified conditions. The information is then grouped by the ‘V02_OCUPACION_VIVIENDA’ variable, and the number of missing values (‘nas’) before and after the assignment is calculated, along with the total count of missing values after the assignment. Subsequently, another assignment of missing values is performed directly to the ‘H01A_TOTAL_PERSONAS’ variable within the ‘censo’ dataset. This is done following the same conditions mentioned earlier. censo %&gt;% mutate( H01A_TOTAL_PERSONAS_temp = case_when( V02_OCUPACION_VIVIENDA == &quot;9&quot; ~ NA_real_, V02_OCUPACION_VIVIENDA == &quot;2&quot; ~ NA_real_, V02_OCUPACION_VIVIENDA == &quot;8&quot; ~ NA_real_, TRUE ~ H01A_TOTAL_PERSONAS ) ) %&gt;% group_by(V02_OCUPACION_VIVIENDA) %&gt;% summarise(nas_antes = sum(is.na(H01A_TOTAL_PERSONAS)), nas_despues = sum(is.na(H01A_TOTAL_PERSONAS_temp))) %&gt;% mutate(total_nas_despues = sum(nas_despues)) ## Assignment of Missing Values censo %&lt;&gt;% mutate( H01A_TOTAL_PERSONAS = case_when( V02_OCUPACION_VIVIENDA == &quot;9&quot; ~ NA_real_, V02_OCUPACION_VIVIENDA == &quot;2&quot; ~ NA_real_, V02_OCUPACION_VIVIENDA == &quot;8&quot; ~ NA_real_, TRUE ~ H01A_TOTAL_PERSONAS ) ) "],["descriptive-values-of-the-census-data.html", "2.2 Descriptive Values of the Census Data", " 2.2 Descriptive Values of the Census Data Numeric Variables In this section, various descriptive statistics are calculated for the numeric variables within the ‘censo’ dataset. These statistics provide insights into the distribution and characteristics of the numeric data. ‘max_values’: The maximum values of numeric and integer variables are calculated using the ‘summarise’ and ‘pivot_longer’ functions. The result is a table that lists the maximum values for each variable. ‘min_values’: Similarly, the minimum values of numeric and integer variables are computed and organized into a table format. ‘media_values’: The mean (average) values of numeric and integer variables are calculated and presented in tabular form. ‘mediana_values’: The median values of numeric and integer variables are determined and displayed as a table. ‘SD_values’: Standard deviations (SD) of numeric and integer variables are computed and organized into a table structure. ‘nas_values’: The number of missing values (NAs) for each numeric and integer variable is counted and presented in tabular format. max_values &lt;- censo %&gt;% summarise(across(where(is.numeric) | where(is.integer), max)) %&gt;% pivot_longer(everything(), names_to = &quot;Nombre_Columna&quot;, values_to = &quot;Valor_Maximo&quot;) min_values &lt;- censo %&gt;% summarise(across(where(is.numeric) | where(is.integer), min)) %&gt;% pivot_longer(everything(), names_to = &quot;Nombre_Columna&quot;, values_to = &quot;Valor_Minimo&quot;) media_values &lt;- censo %&gt;% summarise(across(where(is.numeric) | where(is.integer), mean)) %&gt;% pivot_longer(everything(), names_to = &quot;Nombre_Columna&quot;, values_to = &quot;Valor_Media&quot;) mediana_values &lt;- censo %&gt;% summarise(across(where(is.numeric) | where(is.integer), median)) %&gt;% pivot_longer(everything(), names_to = &quot;Nombre_Columna&quot;, values_to = &quot;Valor_Mediana&quot;) SD_values &lt;- censo %&gt;% summarise(across(where(is.numeric) | where(is.integer), sd)) %&gt;% pivot_longer(everything(), names_to = &quot;Nombre_Columna&quot;, values_to = &quot;Valor_sd&quot;) nas_values &lt;- censo %&gt;% summarise(across(where(is.numeric) | where(is.integer), function(x)sum(is.na(x)))) %&gt;% pivot_longer(everything(), names_to = &quot;Nombre_Columna&quot;, values_to = &quot;Num_nas&quot;) Character Variables For character variables within the ‘censo’ dataset, specific descriptive statistics are generated: ‘max_char’: This table contains the maximum lengths of character variables. It calculates the maximum number of characters within each character variable. ‘min_char’: Similar to ‘max_char’, this table provides the minimum lengths of character variables. ‘nas_values_char’: This table displays the counts of missing values (NAs) for each character variable. max_char &lt;- censo %&gt;% summarise(across(where(is.character), function(x)max(nchar(x)))) %&gt;% pivot_longer(everything(), names_to = &quot;Nombre_Columna&quot;, values_to = &quot;leng_max&quot;) min_char &lt;- censo %&gt;% summarise(across(where(is.character), function(x)min(nchar(x)))) %&gt;% pivot_longer(everything(), names_to = &quot;Nombre_Columna&quot;, values_to = &quot;leng_min&quot;) nas_values_char &lt;- censo %&gt;% summarise(across(where(is.character) , function(x)sum(is.na(x)))) %&gt;% pivot_longer(everything(), names_to = &quot;Nombre_Columna&quot;, values_to = &quot;Num_nas_char&quot;) "],["organizing-results-in-a-database.html", "2.3 Organizing Results in a Database", " 2.3 Organizing Results in a Database In this section, the collected descriptive statistics are organized and combined into a comprehensive summary database named ‘resumen2’. To achieve this, the ‘reduce’ function is used with a list of tables containing the various statistics. The tables include statistics related to character variables (‘nas_values_char’, ‘min_char’, ‘max_char’), numeric variables (‘nas_values’, ‘SD_values’, ‘mediana_values’, ‘media_values’, ‘min_values’, ‘max_values’), and a table that holds information about variable names and types (‘resumen’). The ‘full_join’ function is applied iteratively using ‘reduce’ to combine all these tables together. The ‘by’ parameter specifies that the join should be performed based on the ‘Nombre_Columna’ (Column Name) variable, ensuring that the statistics for each variable are correctly matched and aligned. The final result is the ‘resumen2’ database, which provides a consolidated view of descriptive statistics for each variable in the ‘censo’ dataset, incorporating information about NAs, minimums, maximums, standard deviations, medians, means, and more. resumen2 &lt;- reduce( list( nas_values_char, min_char, max_char, nas_values, SD_values, mediana_values, media_values, min_values, max_values ), full_join, by = join_by(Nombre_Columna) ) %&gt;% full_join(x = resumen, y = ., by = join_by(Nombre_Columna)) # save data openxlsx::write.xlsx(resumen2, file = &quot;Recursos/01_Input_Validation/Data/Estado_base.xlsx&quot;) openxlsx::openXL(&quot;Recursos/01_Input_Validation/Data/Estado_base.xlsx&quot;) Nombre_Columna tipo Num_nas_char leng_min leng_max Num_nas Valor_sd Valor_Mediana Valor_Media Valor_Minimo Valor_Maximo un_ID integer NA NA NA 0 503230.4746 871621 871621.0000 1 1743241 PROV_ID character 0 1 1 NA NA NA NA NA NA CANT_ID character 0 3 3 NA NA NA NA NA NA DIST_ID character 0 5 5 NA NA NA NA NA NA UGM_ID character 0 8 8 NA NA NA NA NA NA LLAVEV character 0 1 14 NA NA NA NA NA NA RESUL_ENTREVISTA_VIV integer NA NA NA 0 1.5899 1 2.2408 1 5 TIPO_VIVIENDA_PRECENSO character 0 1 22 NA NA NA NA NA NA V01_TIPO_VIVIENDA integer NA NA NA 0 4.6571 1 2.9378 1 15 V02_OCUPACION_VIVIENDA integer NA NA NA 0 2.8114 2 2.9311 1 9 "],["updating-the-dataset-based-on-report-results.html", "2.4 Updating the Dataset Based on Report Results", " 2.4 Updating the Dataset Based on Report Results In this part of the code, the ‘censo’ dataset is updated based on the results obtained from the report. First, the ‘Nombre_Columna’ vector is defined, which contains the names of the columns to be updated. Next, the ‘Tipo_actualizar’ vector is defined, which contains the type conversion functions to be applied to each corresponding column. Using the ‘map2’ function from the ‘purrr’ package, each pair of elements in ‘Nombre_Columna’ and ‘Tipo_actualizar’ is iterated over, applying the respective type conversion function to each column in the ‘censo’ dataset. This is achieved using the ‘&lt;&lt;-’ function to update values in the original dataset. Finally, a new dataset ‘censo2’ is created that only contains the columns specified in ‘Nombre_Columna’. This ensures that the dataset is updated according to the data types and modifications made based on the report results. Nombre_Columna &lt;- c( &quot;un_ID&quot; , &quot;PROV_ID&quot; , &quot;CANT_ID&quot; , &quot;DIST_ID&quot; , &quot;UGM_ID&quot; , &quot;LLAVEV&quot; , &quot;RESUL_ENTREVISTA_VIV&quot; , &quot;TIPO_VIVIENDA_PRECENSO&quot; , &quot;V01_TIPO_VIVIENDA&quot; , &quot;V02_OCUPACION_VIVIENDA&quot; , &quot;H01A_TOTAL_PERSONAS&quot; , &quot;greenpoint&quot; , &quot;ugm_viviendas_totales_censo&quot; , &quot;ugm_viviendas_ocupadas_censo&quot; , &quot;ugm_viviendas_desocupadas_censo&quot; , &quot;ugm_peligrosidad&quot; , &quot;ugm_problema_de_acceso&quot; , &quot;ugm_riesgos_amenazas&quot; , &quot;ugm_cobertura_telecomunicaciones&quot; , &quot;asent&quot; , &quot;ppp_CRI_v2&quot; , &quot;elev&quot; , &quot;indig&quot; , &quot;aprot&quot; , &quot;dist_permisos_de_construccion_2011_2022&quot; , &quot;dist_poblacion_proyeccion_ajustada_2022&quot; , &quot;dist_poblacion_ccss_abril_2023&quot; , &quot;dist_matricula_educacion_primaria_2021&quot; , &quot;dist_codigo_urbanidad&quot; , &quot;GHS_BUILT_S_E2020_GLOBE_R2023A_5367_CRI&quot; , &quot;urban_coverfraction&quot; , &quot;crops_coverfraction&quot; , &quot;ebais_tt&quot; , &quot;escu_tt&quot; , &quot;igl_tt&quot; , &quot;prov_nl_mean&quot; , &quot;cant_nl_mean&quot; , &quot;dist_nl_mean&quot; , &quot;wpop_sum&quot; ) Tipo_actualizar &lt;- c( as.character, as.character, as.character, as.character, as.character, as.character, as.character, as.character, as.character, as.character, as.numeric, as.character, as.numeric, as.numeric, as.numeric, as.character, as.character, as.character, as.character, as.character, as.numeric, as.numeric, as.character, as.character, as.numeric, as.numeric, as.numeric, as.numeric, as.character, as.numeric, as.numeric, as.numeric, as.numeric, as.numeric, as.numeric, as.numeric, as.numeric, as.numeric, as.numeric) map2(Nombre_Columna, Tipo_actualizar, function(nom,tipo){ censo[[nom]] &lt;&lt;- tipo(censo[[nom]]) }) # Selecting columns specified in &#39;Nombre_Columna&#39; censo2 &lt;- censo %&gt;% select(all_of(Nombre_Columna)) "],["dataset-refinement-and-analysis.html", "2.5 Dataset Refinement and Analysis", " 2.5 Dataset Refinement and Analysis In this section, the ‘censo’ dataset is refined further, and some descriptive analyses are conducted on the updated dataset. Additionally, the results of these analyses are saved in the specified directory. Summary of variables censo2 %&gt;% distinct(UGM_ID, wpop_sum) %&gt;% summarise(n = sum(wpop_sum)) %&gt;% tba() n 4653649 Count of ugm_viviendas_totales_censo == 0 censo2 %&gt;% distinct(UGM_ID, ugm_viviendas_totales_censo) %&gt;% mutate(categoria = cut(ugm_viviendas_totales_censo, breaks = c(-1:5, 10, 20, 50, max(ugm_viviendas_totales_censo) ))) %&gt;% group_by(categoria) %&gt;% tally() %&gt;% tba() categoria n (-1,0] 3744 (0,1] 1760 (1,2] 1441 (2,3] 1446 (3,4] 1412 (4,5] 1527 (5,10] 7317 (10,20] 11660 (20,50] 12516 (50,285] 5170 Comparing with the number of records per UGM ugm_cero_viviendas &lt;- censo2 %&gt;% distinct(UGM_ID, ugm_viviendas_totales_censo) %&gt;% filter(ugm_viviendas_totales_censo == 0) cont_registros_ugm &lt;- censo2 %&gt;% group_by(UGM_ID) %&gt;% tally(name = &quot;Total_vivienda_ugm&quot;) inner_join(ugm_cero_viviendas, cont_registros_ugm) %&gt;% summarise(n_ugm = n(), min = min(Total_vivienda_ugm), max = max(Total_vivienda_ugm), mediana = median(Total_vivienda_ugm)) %&gt;% tba() n_ugm min max mediana 3744 1 207 12 Summary of variables for specific condition censo2 %&gt;% filter(V02_OCUPACION_VIVIENDA == &quot;8&quot;) %&gt;% summarise(n_viviendas = n(), min = min(H01A_TOTAL_PERSONAS), max = max(H01A_TOTAL_PERSONAS), mediana = median(H01A_TOTAL_PERSONAS)) %&gt;% tba() n_viviendas min max mediana 74871 0 0 0 "],["summary-and-analysis-of-data.html", "2.6 Summary and Analysis of Data", " 2.6 Summary and Analysis of Data In this section, we are summarizing and analyzing the data in order to gain insights. We will calculate different measures to understand the characteristics of the variables. Creating a summary of the column names and their data types resumen &lt;- data.frame(Nombre_Columna = names(censo2)) resumen %&lt;&gt;% mutate(tipo = map_chr(Nombre_Columna, function(x)class(censo2[[x]]))) Checking for character variables and ensuring consistent character length tipo_char &lt;- resumen$Nombre_Columna[resumen$tipo == &quot;character&quot;] for(ii in tipo_char) { max_char &lt;- max(nchar(censo2[[ii]])) censo2[[ii]] &lt;- str_pad(string = censo2[[ii]], width = max_char, pad = &quot;0&quot;) } Summarizing character variables max_char &lt;- censo2 %&gt;% summarise(across(where(is.character), function(x)max(nchar(x)))) %&gt;% pivot_longer(everything(), names_to = &quot;Nombre_Columna&quot;, values_to = &quot;leng_max&quot;) min_char &lt;- censo2 %&gt;% summarise(across(where(is.character), function(x)min(nchar(x)))) %&gt;% pivot_longer(everything(), names_to = &quot;Nombre_Columna&quot;, values_to = &quot;leng_min&quot;) nas_values_char &lt;- censo2 %&gt;% summarise(across(where(is.character) , function(x)sum(is.na(x)))) %&gt;% pivot_longer(everything(), names_to = &quot;Nombre_Columna&quot;, values_to = &quot;Num_nas_char&quot;) Summarizing numeric variables max_values &lt;- censo2 %&gt;% summarise(across(where(is.numeric) | where(is.integer), max)) %&gt;% pivot_longer(everything(), names_to = &quot;Nombre_Columna&quot;, values_to = &quot;Valor_Maximo&quot;) min_values &lt;- censo2 %&gt;% summarise(across(where(is.numeric) | where(is.integer), min)) %&gt;% pivot_longer(everything(), names_to = &quot;Nombre_Columna&quot;, values_to = &quot;Valor_Minimo&quot;) media_values &lt;- censo2 %&gt;% summarise(across(where(is.numeric) | where(is.integer), mean)) %&gt;% pivot_longer(everything(), names_to = &quot;Nombre_Columna&quot;, values_to = &quot;Valor_Media&quot;) mediana_values &lt;- censo2 %&gt;% summarise(across(where(is.numeric) | where(is.integer), median)) %&gt;% pivot_longer(everything(), names_to = &quot;Nombre_Columna&quot;, values_to = &quot;Valor_Mediana&quot;) SD_values &lt;- censo2 %&gt;% summarise(across(where(is.numeric) | where(is.integer), sd)) %&gt;% pivot_longer(everything(), names_to = &quot;Nombre_Columna&quot;, values_to = &quot;Valor_sd&quot;) nas_values &lt;- censo2 %&gt;% summarise(across(where(is.numeric) | where(is.integer), function(x)sum(is.na(x)))) %&gt;% pivot_longer(everything(), names_to = &quot;Nombre_Columna&quot;, values_to = &quot;Num_nas&quot;) Combining all the summary information resumen2 &lt;- reduce( list(nas_values_char, min_char, max_char, nas_values, SD_values, mediana_values, media_values, min_values, max_values), full_join, by = join_by(Nombre_Columna)) %&gt;% full_join(x = resumen, y = ., by = join_by(Nombre_Columna)) Saving the summary results to an Excel file openxlsx::write.xlsx(resumen2, file = &quot;Recursos/01_Input_Validation/Data/Estado_base_despues.xlsx&quot;) Saving the standardized dataset saveRDS(censo2, file = &quot;Recursos/01_Input_Validation/Data/censo_estandarizado.rds&quot;) In this code block, we are creating summaries of the dataset variables to understand their characteristics. We are calculating different measures for both character and numeric variables, such as maximum, minimum, mean, median, and standard deviation. Additionally, we are counting missing values for character variables. "]]
