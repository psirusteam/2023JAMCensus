[["index.html", "Workshop Materials", " Workshop Materials In the following link, you will find the R routines developed for the workshop.. Descargar "],["installation-of-libraries-and-required-software-for-bayesian-area-models..html", "Chapter 1 Installation of Libraries and Required Software for Bayesian Area Models. ", " Chapter 1 Installation of Libraries and Required Software for Bayesian Area Models. "],["step-1-installing-software.html", "1.1 Step 1: Installing Software", " 1.1 Step 1: Installing Software Below is a list of the necessary software for the proper development of the training. It is recommended to install these packages before starting with the practical development. Download and install Rbase (https://cran.r-project.org/bin/windows/base/) Download and install Rtools (https://cran.r-project.org/bin/windows/Rtools/) Download and install Rstudio (https://posit.co/download/rstudio-desktop/) Download and install Quarto (https://quarto.org/docs/get-started/) Download and install Anaconda (https://www.anaconda.com/products/individual) Download and install Google Cloud (https://cloud.google.com/sdk/docs/install?hl=es-419) "],["step-2-installing-the-following-libraries-in-r..html", "1.2 Step 2: Installing the following libraries in R.", " 1.2 Step 2: Installing the following libraries in R. 1.2.1 Data Visualization and Manipulation: tidyverse: A collection of packages for data manipulation and visualization. magrittr: Provides a pipe %&gt;% operator to make code more readable. scales: Tools for scaling visualizations, like adjusting axis breaks. sf: For working with spatial data and maps. tmap: Creates thematic maps and overlays. 1.2.2 Statistical Modeling: lme4: Fits linear and generalized linear mixed-effects models. rstanarm: Fits Bayesian models using Stan for various statistical tasks. 1.2.3 Survey Analysis: srvyr: Tools for working with survey data alongside the dplyr package. survey: For analyzing complex survey data. 1.2.4 Data Manipulation and Transformation: dplyr: Data manipulation tools. tidyr: Tools for reshaping and tidying data. reshape2: Reshaping data frames. 1.2.5 Bayesian Analysis: bayesplot: Visualization of Bayesian models. posterior: Tools for working with posterior distributions. rstan: R interface to Stan, a platform for Bayesian modeling. 1.2.6 Geospatial Analysis: rgee: Interface to Google Earth Engine. trafo: Tools for transforming spatial data. maptools: Tools for reading and manipulating geographic data. usmap: Maps of the United States. 1.2.7 Miscellaneous: sampling: Tools for survey sampling. haven: For reading and writing SPSS, Stata, and SAS files. RColorBrewer: Provides color palettes. kableExtra: Enhances table rendering in R Markdown. formatR: Formatting tools for R code. printr: Custom printing of data frames and tables. remotes: Tools for package development and installation. latex2exp: Converts LaTeX code into expressions. To install each package, use the command install.packages(\"package_name\"). install.packages(&quot;patchwork&quot;) install.packages(&quot;lme4&quot;) install.packages(&quot;tidyverse&quot;) install.packages(&quot;rstanarm&quot;) install.packages(&quot;magrittr&quot;) install.packages(&quot;reticulate&quot;) install.packages(&quot;rgee&quot;) install.packages(&quot;sf&quot;) install.packages(&quot;tmap&quot;) install.packages(&quot;trafo&quot;) install.packages(&quot;scales&quot;) install.packages(&quot;srvyr&quot;) install.packages(&quot;survey&quot;) install.packages(&quot;haven&quot;) install.packages(&quot;sampling&quot;) install.packages(&quot;RColorBrewer&quot;) install.packages(&quot;maptools&quot;) install.packages(&quot;data.table&quot;) install.packages(&quot;forcats&quot;) install.packages(&quot;tidyr&quot;) install.packages(&quot;reshape2&quot;) install.packages(&quot;bayesplot&quot;) install.packages(&quot;posterior&quot;) install.packages(&quot;gridExtra&quot;) install.packages(&quot;ggalt&quot;) install.packages(&quot;usmap&quot;) install.packages(&quot;kableExtra&quot;) install.packages(&quot;formatR&quot;) install.packages(&quot;printr&quot;) install.packages(&quot;remotes&quot;) install.packages(&quot;latex2exp&quot;) install.packages(&quot;gtsummary&quot;) 1.2.8 Step-by-Step Guide to Install rstan Follow these steps to install the rstan package: Install Rtools (if using Windows): Download and install Rtools. Install StanHeaders: Open R or RStudio. Run the command: install.packages(\"StanHeaders\", repos = c(\"https://mc-stan.org/r-packages/\", getOption(\"repos\"))). Install rstan: Run the command: install.packages(\"rstan\", repos=c(\"https://mc-stan.org/r-packages/\", getOption(\"repos\"))). Verify the installation: Load the package using: library(rstan). Validate the installation: Run a simple model to ensure that rstan is working properly. You can use the example code provided in the documentation. Remember to follow these steps carefully to ensure a successful installation of rstan and its dependencies. "],["step-3-validation-of-installation---ensuring-proper-rstan-installation.html", "1.3 Step 3: Validation of Installation - Ensuring Proper rstan Installation", " 1.3 Step 3: Validation of Installation - Ensuring Proper rstan Installation library(rstan) library(posterior) library(bayesplot) # Example Stan code stan_code &lt;- &quot; parameters { real y[2]; } model { y[1] ~ normal(0, 1); y[2] ~ double_exponential(0, 2); } &quot; # Fit the model fit1 &lt;- stan(model_code = stan_code, iter = 10, verbose = FALSE) # Print the fit1 object print(fit1) # Further fitting and summarizing fit2 &lt;- stan(fit = fit1, iter = 10000, verbose = FALSE) summary(fit2)$summary In this section, we validate the correct installation of rstan by running a simple Bayesian model. We load the required packages, including rstan, posterior, and bayesplot. We then define a basic Stan model using the Stan code provided. We fit this model using stan() with a small number of iterations (iter = 10) to quickly verify the installation. Next, we demonstrate fitting the model further (fit2) with more iterations (iter = 10000) to show how to perform a more comprehensive analysis. The summary of the fitted model is printed using the summary() function. Make sure to evaluate this code in an R environment after installing the required packages to verify that rstan has been installed correctly and is functioning as expected. "],["step-4-creating-a-google-earth-engine-account.html", "1.4 Step 4: Creating a Google Earth Engine Account:", " 1.4 Step 4: Creating a Google Earth Engine Account: https://developers.google.com/earth-engine/datasets/ After successfully creating your account, it’s important to follow these steps to ensure everything is set up correctly: Access the provided link: https://developers.google.com/earth-engine/datasets/catalog/WHRC_biomass_tropical. Scroll down to the bottom of the page and locate the code displayed in the image below: Click on the Open in Code Editor option, which will open a new browser tab. Follow the instructions provided until you achieve the result shown in the image below: In the previous tab, find and click the Run button to obtain the outcome displayed in the image below: Note: Repeat the process as needed to ensure you achieve the desired outcome. "],["standardization-and-validation-of-available-census-data-variables.html", "Chapter 2 Standardization and Validation of Available Census Data Variables", " Chapter 2 Standardization and Validation of Available Census Data Variables In the following code set, a series of processes are carried out for data cleaning and preparation. These steps include removing objects from the workspace, loading necessary libraries, reading census data, assigning missing values based on certain conditions, and calculating descriptive statistics for numeric and character variables. Additionally, adjustments are made to character variables to ensure consistent length. The final results are summarized in a data structure and saved in files for further analysis and reference. library(tidyverse) library(data.table) library(openxlsx) library(DataExplorer) library(magrittr) library(RColorBrewer) select&lt;- dplyr::select cat(&quot;\\f&quot;) censo &lt;- readRDS(&quot;Recursos/01_Input_Validation/Data/Data_census_V2023-06-12.rds&quot;) %&gt;% select(-geometry) %&gt;% as.data.frame() # Creating a summary data frame for column names and their respective data types. resumen &lt;- data.frame(Nombre_Columna = names(censo)) resumen %&lt;&gt;% mutate(tipo = map_chr(Nombre_Columna, function(x) class(censo[[x]]))) resumen &lt;- readRDS(&quot;Recursos/01_Input_Validation/RecurseBooks/resumen1.rds&quot;) tba(head(resumen,10)) Nombre_Columna tipo un_ID integer PROV_ID character CANT_ID character DIST_ID character UGM_ID character LLAVEV character RESUL_ENTREVISTA_VIV integer TIPO_VIVIENDA_PRECENSO character V01_TIPO_VIVIENDA integer V02_OCUPACION_VIVIENDA integer "],["assigning-missing-values-to-the-h01a_total_personas-variable.html", "2.1 Assigning Missing Values to the ‘H01A_TOTAL_PERSONAS’ Variable", " 2.1 Assigning Missing Values to the ‘H01A_TOTAL_PERSONAS’ Variable In this section, actions related to the ‘H01A_TOTAL_PERSONAS’ variable are performed. Missing values (NA) are assigned to this variable based on specific conditions, which include: Dwellings that were not visited (category 9). Dwellings that rejected the visit or are pending (classification 2). Dwellings with other reasons (category 8). Next, a count of cases before and after the assignment of missing values is conducted. The ‘mutate’ function is used to create a new temporary column ‘H01A_TOTAL_PERSONAS_temp’ in which NA values are assigned according to the specified conditions. The information is then grouped by the ‘V02_OCUPACION_VIVIENDA’ variable, and the number of missing values (‘nas’) before and after the assignment is calculated, along with the total count of missing values after the assignment. Subsequently, another assignment of missing values is performed directly to the ‘H01A_TOTAL_PERSONAS’ variable within the ‘censo’ dataset. This is done following the same conditions mentioned earlier. censo %&gt;% mutate( H01A_TOTAL_PERSONAS_temp = case_when( V02_OCUPACION_VIVIENDA == &quot;9&quot; ~ NA_real_, V02_OCUPACION_VIVIENDA == &quot;2&quot; ~ NA_real_, V02_OCUPACION_VIVIENDA == &quot;8&quot; ~ NA_real_, TRUE ~ H01A_TOTAL_PERSONAS ) ) %&gt;% group_by(V02_OCUPACION_VIVIENDA) %&gt;% summarise(nas_antes = sum(is.na(H01A_TOTAL_PERSONAS)), nas_despues = sum(is.na(H01A_TOTAL_PERSONAS_temp))) %&gt;% mutate(total_nas_despues = sum(nas_despues)) ## Assignment of Missing Values censo %&lt;&gt;% mutate( H01A_TOTAL_PERSONAS = case_when( V02_OCUPACION_VIVIENDA == &quot;9&quot; ~ NA_real_, V02_OCUPACION_VIVIENDA == &quot;2&quot; ~ NA_real_, V02_OCUPACION_VIVIENDA == &quot;8&quot; ~ NA_real_, TRUE ~ H01A_TOTAL_PERSONAS ) ) "],["descriptive-values-of-the-census-data.html", "2.2 Descriptive Values of the Census Data", " 2.2 Descriptive Values of the Census Data Numeric Variables In this section, various descriptive statistics are calculated for the numeric variables within the ‘censo’ dataset. These statistics provide insights into the distribution and characteristics of the numeric data. ‘max_values’: The maximum values of numeric and integer variables are calculated using the ‘summarise’ and ‘pivot_longer’ functions. The result is a table that lists the maximum values for each variable. ‘min_values’: Similarly, the minimum values of numeric and integer variables are computed and organized into a table format. ‘media_values’: The mean (average) values of numeric and integer variables are calculated and presented in tabular form. ‘mediana_values’: The median values of numeric and integer variables are determined and displayed as a table. ‘SD_values’: Standard deviations (SD) of numeric and integer variables are computed and organized into a table structure. ‘nas_values’: The number of missing values (NAs) for each numeric and integer variable is counted and presented in tabular format. max_values &lt;- censo %&gt;% summarise(across(where(is.numeric) | where(is.integer), max)) %&gt;% pivot_longer(everything(), names_to = &quot;Nombre_Columna&quot;, values_to = &quot;Valor_Maximo&quot;) min_values &lt;- censo %&gt;% summarise(across(where(is.numeric) | where(is.integer), min)) %&gt;% pivot_longer(everything(), names_to = &quot;Nombre_Columna&quot;, values_to = &quot;Valor_Minimo&quot;) media_values &lt;- censo %&gt;% summarise(across(where(is.numeric) | where(is.integer), mean)) %&gt;% pivot_longer(everything(), names_to = &quot;Nombre_Columna&quot;, values_to = &quot;Valor_Media&quot;) mediana_values &lt;- censo %&gt;% summarise(across(where(is.numeric) | where(is.integer), median)) %&gt;% pivot_longer(everything(), names_to = &quot;Nombre_Columna&quot;, values_to = &quot;Valor_Mediana&quot;) SD_values &lt;- censo %&gt;% summarise(across(where(is.numeric) | where(is.integer), sd)) %&gt;% pivot_longer(everything(), names_to = &quot;Nombre_Columna&quot;, values_to = &quot;Valor_sd&quot;) nas_values &lt;- censo %&gt;% summarise(across(where(is.numeric) | where(is.integer), function(x)sum(is.na(x)))) %&gt;% pivot_longer(everything(), names_to = &quot;Nombre_Columna&quot;, values_to = &quot;Num_nas&quot;) Character Variables For character variables within the ‘censo’ dataset, specific descriptive statistics are generated: ‘max_char’: This table contains the maximum lengths of character variables. It calculates the maximum number of characters within each character variable. ‘min_char’: Similar to ‘max_char’, this table provides the minimum lengths of character variables. ‘nas_values_char’: This table displays the counts of missing values (NAs) for each character variable. max_char &lt;- censo %&gt;% summarise(across(where(is.character), function(x)max(nchar(x)))) %&gt;% pivot_longer(everything(), names_to = &quot;Nombre_Columna&quot;, values_to = &quot;leng_max&quot;) min_char &lt;- censo %&gt;% summarise(across(where(is.character), function(x)min(nchar(x)))) %&gt;% pivot_longer(everything(), names_to = &quot;Nombre_Columna&quot;, values_to = &quot;leng_min&quot;) nas_values_char &lt;- censo %&gt;% summarise(across(where(is.character) , function(x)sum(is.na(x)))) %&gt;% pivot_longer(everything(), names_to = &quot;Nombre_Columna&quot;, values_to = &quot;Num_nas_char&quot;) "],["organizing-results-in-a-database.html", "2.3 Organizing Results in a Database", " 2.3 Organizing Results in a Database In this section, the collected descriptive statistics are organized and combined into a comprehensive summary database named ‘resumen2’. To achieve this, the ‘reduce’ function is used with a list of tables containing the various statistics. The tables include statistics related to character variables (‘nas_values_char’, ‘min_char’, ‘max_char’), numeric variables (‘nas_values’, ‘SD_values’, ‘mediana_values’, ‘media_values’, ‘min_values’, ‘max_values’), and a table that holds information about variable names and types (‘resumen’). The ‘full_join’ function is applied iteratively using ‘reduce’ to combine all these tables together. The ‘by’ parameter specifies that the join should be performed based on the ‘Nombre_Columna’ (Column Name) variable, ensuring that the statistics for each variable are correctly matched and aligned. The final result is the ‘resumen2’ database, which provides a consolidated view of descriptive statistics for each variable in the ‘censo’ dataset, incorporating information about NAs, minimums, maximums, standard deviations, medians, means, and more. resumen2 &lt;- reduce( list( nas_values_char, min_char, max_char, nas_values, SD_values, mediana_values, media_values, min_values, max_values ), full_join, by = join_by(Nombre_Columna) ) %&gt;% full_join(x = resumen, y = ., by = join_by(Nombre_Columna)) # save data openxlsx::write.xlsx(resumen2, file = &quot;Recursos/01_Input_Validation/Data/Estado_base.xlsx&quot;) openxlsx::openXL(&quot;Recursos/01_Input_Validation/Data/Estado_base.xlsx&quot;) Nombre_Columna tipo Num_nas_char leng_min leng_max Num_nas Valor_sd Valor_Mediana Valor_Media Valor_Minimo Valor_Maximo un_ID integer NA NA NA 0 503230.4746 871621 871621.0000 1 1743241 PROV_ID character 0 1 1 NA NA NA NA NA NA CANT_ID character 0 3 3 NA NA NA NA NA NA DIST_ID character 0 5 5 NA NA NA NA NA NA UGM_ID character 0 8 8 NA NA NA NA NA NA LLAVEV character 0 1 14 NA NA NA NA NA NA RESUL_ENTREVISTA_VIV integer NA NA NA 0 1.5899 1 2.2408 1 5 TIPO_VIVIENDA_PRECENSO character 0 1 22 NA NA NA NA NA NA V01_TIPO_VIVIENDA integer NA NA NA 0 4.6571 1 2.9378 1 15 V02_OCUPACION_VIVIENDA integer NA NA NA 0 2.8114 2 2.9311 1 9 "],["updating-the-dataset-based-on-report-results.html", "2.4 Updating the Dataset Based on Report Results", " 2.4 Updating the Dataset Based on Report Results In this part of the code, the ‘censo’ dataset is updated based on the results obtained from the report. First, the ‘Nombre_Columna’ vector is defined, which contains the names of the columns to be updated. Next, the ‘Tipo_actualizar’ vector is defined, which contains the type conversion functions to be applied to each corresponding column. Using the ‘map2’ function from the ‘purrr’ package, each pair of elements in ‘Nombre_Columna’ and ‘Tipo_actualizar’ is iterated over, applying the respective type conversion function to each column in the ‘censo’ dataset. This is achieved using the ‘&lt;&lt;-’ function to update values in the original dataset. Finally, a new dataset ‘censo2’ is created that only contains the columns specified in ‘Nombre_Columna’. This ensures that the dataset is updated according to the data types and modifications made based on the report results. Nombre_Columna &lt;- c( &quot;un_ID&quot; , &quot;PROV_ID&quot; , &quot;CANT_ID&quot; , &quot;DIST_ID&quot; , &quot;UGM_ID&quot; , &quot;LLAVEV&quot; , &quot;RESUL_ENTREVISTA_VIV&quot; , &quot;TIPO_VIVIENDA_PRECENSO&quot; , &quot;V01_TIPO_VIVIENDA&quot; , &quot;V02_OCUPACION_VIVIENDA&quot; , &quot;H01A_TOTAL_PERSONAS&quot; , &quot;greenpoint&quot; , &quot;ugm_viviendas_totales_censo&quot; , &quot;ugm_viviendas_ocupadas_censo&quot; , &quot;ugm_viviendas_desocupadas_censo&quot; , &quot;ugm_peligrosidad&quot; , &quot;ugm_problema_de_acceso&quot; , &quot;ugm_riesgos_amenazas&quot; , &quot;ugm_cobertura_telecomunicaciones&quot; , &quot;asent&quot; , &quot;ppp_CRI_v2&quot; , &quot;elev&quot; , &quot;indig&quot; , &quot;aprot&quot; , &quot;dist_permisos_de_construccion_2011_2022&quot; , &quot;dist_poblacion_proyeccion_ajustada_2022&quot; , &quot;dist_poblacion_ccss_abril_2023&quot; , &quot;dist_matricula_educacion_primaria_2021&quot; , &quot;dist_codigo_urbanidad&quot; , &quot;GHS_BUILT_S_E2020_GLOBE_R2023A_5367_CRI&quot; , &quot;urban_coverfraction&quot; , &quot;crops_coverfraction&quot; , &quot;ebais_tt&quot; , &quot;escu_tt&quot; , &quot;igl_tt&quot; , &quot;prov_nl_mean&quot; , &quot;cant_nl_mean&quot; , &quot;dist_nl_mean&quot; , &quot;wpop_sum&quot; ) Tipo_actualizar &lt;- c( as.character, as.character, as.character, as.character, as.character, as.character, as.character, as.character, as.character, as.character, as.numeric, as.character, as.numeric, as.numeric, as.numeric, as.character, as.character, as.character, as.character, as.character, as.numeric, as.numeric, as.character, as.character, as.numeric, as.numeric, as.numeric, as.numeric, as.character, as.numeric, as.numeric, as.numeric, as.numeric, as.numeric, as.numeric, as.numeric, as.numeric, as.numeric, as.numeric) map2(Nombre_Columna, Tipo_actualizar, function(nom,tipo){ censo[[nom]] &lt;&lt;- tipo(censo[[nom]]) }) # Selecting columns specified in &#39;Nombre_Columna&#39; censo2 &lt;- censo %&gt;% select(all_of(Nombre_Columna)) "],["dataset-refinement-and-analysis.html", "2.5 Dataset Refinement and Analysis", " 2.5 Dataset Refinement and Analysis In this section, the ‘censo’ dataset is refined further, and some descriptive analyses are conducted on the updated dataset. Additionally, the results of these analyses are saved in the specified directory. Summary of variables censo2 %&gt;% distinct(UGM_ID, wpop_sum) %&gt;% summarise(n = sum(wpop_sum)) %&gt;% tba() n 4653649 Count of ugm_viviendas_totales_censo == 0 censo2 %&gt;% distinct(UGM_ID, ugm_viviendas_totales_censo) %&gt;% mutate(categoria = cut(ugm_viviendas_totales_censo, breaks = c(-1:5, 10, 20, 50, max(ugm_viviendas_totales_censo) ))) %&gt;% group_by(categoria) %&gt;% tally() %&gt;% tba() categoria n (-1,0] 3744 (0,1] 1760 (1,2] 1441 (2,3] 1446 (3,4] 1412 (4,5] 1527 (5,10] 7317 (10,20] 11660 (20,50] 12516 (50,285] 5170 Comparing with the number of records per UGM ugm_cero_viviendas &lt;- censo2 %&gt;% distinct(UGM_ID, ugm_viviendas_totales_censo) %&gt;% filter(ugm_viviendas_totales_censo == 0) cont_registros_ugm &lt;- censo2 %&gt;% group_by(UGM_ID) %&gt;% tally(name = &quot;Total_vivienda_ugm&quot;) inner_join(ugm_cero_viviendas, cont_registros_ugm) %&gt;% summarise(n_ugm = n(), min = min(Total_vivienda_ugm), max = max(Total_vivienda_ugm), mediana = median(Total_vivienda_ugm)) %&gt;% tba() n_ugm min max mediana 3744 1 207 12 Summary of variables for specific condition censo2 %&gt;% filter(V02_OCUPACION_VIVIENDA == &quot;8&quot;) %&gt;% summarise(n_viviendas = n(), min = min(H01A_TOTAL_PERSONAS), max = max(H01A_TOTAL_PERSONAS), mediana = median(H01A_TOTAL_PERSONAS)) %&gt;% tba() n_viviendas min max mediana 74871 0 0 0 "],["summary-and-analysis-of-data.html", "2.6 Summary and Analysis of Data", " 2.6 Summary and Analysis of Data In this section, we are summarizing and analyzing the data in order to gain insights. We will calculate different measures to understand the characteristics of the variables. Creating a summary of the column names and their data types resumen &lt;- data.frame(Nombre_Columna = names(censo2)) resumen %&lt;&gt;% mutate(tipo = map_chr(Nombre_Columna, function(x)class(censo2[[x]]))) Checking for character variables and ensuring consistent character length tipo_char &lt;- resumen$Nombre_Columna[resumen$tipo == &quot;character&quot;] for(ii in tipo_char) { max_char &lt;- max(nchar(censo2[[ii]])) censo2[[ii]] &lt;- str_pad(string = censo2[[ii]], width = max_char, pad = &quot;0&quot;) } Summarizing character variables max_char &lt;- censo2 %&gt;% summarise(across(where(is.character), function(x)max(nchar(x)))) %&gt;% pivot_longer(everything(), names_to = &quot;Nombre_Columna&quot;, values_to = &quot;leng_max&quot;) min_char &lt;- censo2 %&gt;% summarise(across(where(is.character), function(x)min(nchar(x)))) %&gt;% pivot_longer(everything(), names_to = &quot;Nombre_Columna&quot;, values_to = &quot;leng_min&quot;) nas_values_char &lt;- censo2 %&gt;% summarise(across(where(is.character) , function(x)sum(is.na(x)))) %&gt;% pivot_longer(everything(), names_to = &quot;Nombre_Columna&quot;, values_to = &quot;Num_nas_char&quot;) Summarizing numeric variables max_values &lt;- censo2 %&gt;% summarise(across(where(is.numeric) | where(is.integer), max)) %&gt;% pivot_longer(everything(), names_to = &quot;Nombre_Columna&quot;, values_to = &quot;Valor_Maximo&quot;) min_values &lt;- censo2 %&gt;% summarise(across(where(is.numeric) | where(is.integer), min)) %&gt;% pivot_longer(everything(), names_to = &quot;Nombre_Columna&quot;, values_to = &quot;Valor_Minimo&quot;) media_values &lt;- censo2 %&gt;% summarise(across(where(is.numeric) | where(is.integer), mean)) %&gt;% pivot_longer(everything(), names_to = &quot;Nombre_Columna&quot;, values_to = &quot;Valor_Media&quot;) mediana_values &lt;- censo2 %&gt;% summarise(across(where(is.numeric) | where(is.integer), median)) %&gt;% pivot_longer(everything(), names_to = &quot;Nombre_Columna&quot;, values_to = &quot;Valor_Mediana&quot;) SD_values &lt;- censo2 %&gt;% summarise(across(where(is.numeric) | where(is.integer), sd)) %&gt;% pivot_longer(everything(), names_to = &quot;Nombre_Columna&quot;, values_to = &quot;Valor_sd&quot;) nas_values &lt;- censo2 %&gt;% summarise(across(where(is.numeric) | where(is.integer), function(x)sum(is.na(x)))) %&gt;% pivot_longer(everything(), names_to = &quot;Nombre_Columna&quot;, values_to = &quot;Num_nas&quot;) Combining all the summary information resumen2 &lt;- reduce( list(nas_values_char, min_char, max_char, nas_values, SD_values, mediana_values, media_values, min_values, max_values), full_join, by = join_by(Nombre_Columna)) %&gt;% full_join(x = resumen, y = ., by = join_by(Nombre_Columna)) Saving the summary results to an Excel file openxlsx::write.xlsx(resumen2, file = &quot;Recursos/01_Input_Validation/Data/Estado_base_despues.xlsx&quot;) Saving the standardized dataset saveRDS(censo2, file = &quot;Recursos/01_Input_Validation/Data/censo_estandarizado.rds&quot;) In this code block, we are creating summaries of the dataset variables to understand their characteristics. We are calculating different measures for both character and numeric variables, such as maximum, minimum, mean, median, and standard deviation. Additionally, we are counting missing values for character variables. "],["filtering-and-refining-census-data.html", "Chapter 3 Filtering and Refining Census Data", " Chapter 3 Filtering and Refining Census Data In the process of enhancing and purifying census database, it is imperative to establish consistent and replicable rules. In this context, the procedure of “Census Data Filtering and Refinement” becomes essential in improving data quality and eliminating irrelevant information. Throughout the following code blocks, we will explore how diverse filters and refinement techniques were applied to census data. These codes will guide us through a crucial process to ensure that the data is reliable and suitable for further analysis. Collectively, these steps will empower us to obtain more precise and valuable insights from census data. "],["reading-libraries-databases-and-other-inputs.html", "3.1 Reading Libraries, Databases, and Other Inputs", " 3.1 Reading Libraries, Databases, and Other Inputs In this section, we start by loading the necessary libraries used throughout the processing. Additionally, we define the columns that will be retained after applying the filters. We also make necessary adjustments to the databases, considering updates in the UGM codes. # Load necessary libraries library(tidyverse) # For data manipulation and visualization library(data.table) # For efficient data handling library(openxlsx) # For reading/writing Excel files library(magrittr) # For pipe operators select &lt;- dplyr::select # Alias for dplyr&#39;s select function cat(&quot;\\f&quot;) # Clear console output ## Census data reading ## Selection of columns of interest in the census. Nombre_Columna &lt;- c( &quot;un_ID&quot; , &quot;PROV_ID&quot; , &quot;CANT_ID&quot; , &quot;DIST_ID&quot; , &quot;UGM_ID&quot; , &quot;LLAVEV&quot; , &quot;V01_TIPO_VIVIENDA&quot; , &quot;V02_OCUPACION_VIVIENDA&quot; , &quot;H01A_TOTAL_PERSONAS&quot; , &quot;greenpoint2&quot;, &quot;Filters&quot; ) Reading Housing Data without Coordinates. In this section, we read the housing data from a CSV file that does not include coordinates. We then transform the data into the required format, including variables such as province ID, canton ID, and district ID based on the given codes. The resulting dataset will be used for further analysis and processing. Viviendas_sin_coordenadas &lt;- read_csv2(&quot;Recursos/02_Census_Filters/Data/Viviendas sin coordenadas.csv&quot;) # Transmute data to required format Viviendas_sin_coordenadas %&lt;&gt;% transmute( LLAVEV, PROV_ID = str_sub(CODIGO_PCD, 1,1), CANT_ID = str_sub(CODIGO_PCD, 1,3), DIST_ID = as.character(CODIGO_PCD), UGM_ID = paste0(CODIGO_PCD , ID_UGM), H01A_TOTAL_PERSONAS = H01A_TOTAL_RESIDENTES_HAB) Changing UGM Codes in the Housing Data. In this section, we modify the UGM (Urban Geographic Micro-data) codes in the housing data to ensure consistency and accuracy. Certain UGM codes are updated according to predefined mappings. This step is crucial for maintaining uniformity in the data for subsequent analysis. Viviendas_sin_coordenadas %&lt;&gt;% mutate(UGM_ID = case_when( UGM_ID == &quot;10108228&quot; ~ &quot;10108158&quot;, UGM_ID == &quot;10805037&quot; ~ &quot;10807037&quot;, UGM_ID == &quot;11803124&quot; ~ &quot;11803024&quot;, UGM_ID == &quot;11803150&quot; ~ &quot;11803050&quot;, UGM_ID == &quot;11803151&quot; ~ &quot;11803051&quot;, UGM_ID == &quot;20302131&quot; ~ &quot;20302031&quot;, UGM_ID == &quot;21305106&quot; ~ &quot;21305006&quot;, UGM_ID == &quot;30101232&quot; ~ &quot;30101132&quot;, UGM_ID == &quot;30201354&quot; ~ &quot;30201254&quot;, UGM_ID == &quot;30302158&quot; ~ &quot;30302133&quot;, UGM_ID == &quot;30305186&quot; ~ &quot;30305086&quot;, TRUE ~UGM_ID )) Read the Standardized Census Data. In this section, we read the standardized census data from a stored RDS (R Data Serialization) file. Similar to the previous step, we adjust the UGM codes to maintain data consistency. The standardized census data will serve as the foundation for the subsequent filtering and refinement processes. censo1 &lt;- readRDS(&quot;Recursos/02_Census_Filters/Data/censo_estandarizado.rds&quot;) %&gt;% mutate(UGM_ID = case_when( UGM_ID == &quot;10108228&quot; ~ &quot;10108158&quot;, UGM_ID == &quot;10805037&quot; ~ &quot;10807037&quot;, UGM_ID == &quot;11803124&quot; ~ &quot;11803024&quot;, UGM_ID == &quot;11803150&quot; ~ &quot;11803050&quot;, UGM_ID == &quot;11803151&quot; ~ &quot;11803051&quot;, UGM_ID == &quot;20302131&quot; ~ &quot;20302031&quot;, UGM_ID == &quot;21305106&quot; ~ &quot;21305006&quot;, UGM_ID == &quot;30101232&quot; ~ &quot;30101132&quot;, UGM_ID == &quot;30201354&quot; ~ &quot;30201254&quot;, UGM_ID == &quot;30302158&quot; ~ &quot;30302133&quot;, UGM_ID == &quot;30305186&quot; ~ &quot;30305086&quot;, TRUE ~UGM_ID )) Adding the Age-Sex Base. In this section, we incorporate the age-sex base into the analysis. The age-sex base is read from a stored RDS file. As in previous steps, we ensure consistency by adjusting the UGM codes. The age-sex base provides valuable demographic information and will be utilized in the subsequent filtering and refinement procedures. censo_sexo_edad &lt;- readRDS(&quot;Recursos/02_Census_Filters/Data/Censo con grupos por sexo.rds&quot;) %&gt;% select(-H01A_TOTAL_PERSONAS ) %&gt;% mutate(UGM_ID = case_when( UGM_ID == &quot;10108228&quot; ~ &quot;10108158&quot;, UGM_ID == &quot;10805037&quot; ~ &quot;10807037&quot;, UGM_ID == &quot;11803124&quot; ~ &quot;11803024&quot;, UGM_ID == &quot;11803150&quot; ~ &quot;11803050&quot;, UGM_ID == &quot;11803151&quot; ~ &quot;11803051&quot;, UGM_ID == &quot;20302131&quot; ~ &quot;20302031&quot;, UGM_ID == &quot;21305106&quot; ~ &quot;21305006&quot;, UGM_ID == &quot;30101232&quot; ~ &quot;30101132&quot;, UGM_ID == &quot;30201354&quot; ~ &quot;30201254&quot;, UGM_ID == &quot;30302158&quot; ~ &quot;30302133&quot;, UGM_ID == &quot;30305186&quot; ~ &quot;30305086&quot;, TRUE ~UGM_ID )) 3.1.1 Inner Join to Add the Age-Sex Base In this section, an inner join operation is performed to integrate the age-sex base with the census data. The difference in row count between the two bases corresponds to paper-censused households that are included later in the process. The number of rows in the age-sex base is compared to the census data and the housing data without coordinates to verify the match. ## The difference between the bases corresponds to paper-censused households ## that are included later nrow(censo_sexo_edad) - nrow(censo1) nrow(Viviendas_sin_coordenadas) ## Inner join to add the age-sex base censo1 &lt;- inner_join( censo1, censo_sexo_edad, join_by( un_ID, PROV_ID, CANT_ID, DIST_ID, UGM_ID, LLAVEV, V01_TIPO_VIVIENDA, V02_OCUPACION_VIVIENDA ) ) The code begins by calculating the difference in row count between the age-sex base (censo_sexo_edad) and the existing census data (censo1). This difference represents the number of paper-censused households that are not yet included in the census data. Additionally, the number of rows in the housing data without coordinates (Viviendas_sin_coordenadas) is determined for reference. The inner_join operation is then applied to merge the age-sex base with the census data. The join_by function specifies the columns used for the join operation, ensuring a comprehensive integration of data from both sources. This process enhances the dataset by incorporating important demographic information for further analysis. "],["applying-filters-and-analyzing-the-data.html", "3.2 Applying filters and analyzing the data", " 3.2 Applying filters and analyzing the data In this section, we’ll walk through the process of applying various filters and performing data analysis on the refined census data. 3.2.1 Applying the first filter: categorizing households with residents and determining greenpoint status In this code block, we introduce the first filter by categorizing households as having residents (&#39;si&#39;) or being empty (&#39;no&#39;) based on the total number of residents in each household. Additionally, we determine the greenpoint status of each household, considering whether the greenpoint value is &#39;0&#39; and the &#39;personas&#39; value is &#39;si&#39;. The &#39;greenpoint&#39; column is updated accordingly. # Create &#39;personas&#39; column to categorize households with or without residents censo1 %&lt;&gt;% mutate(personas = if_else(H01A_TOTAL_PERSONAS &gt; 0, &quot;si&quot;, &quot;no&quot;)) # Assign greenpoint status based on conditions censo1 %&lt;&gt;% mutate(greenpoint = if_else(greenpoint == &quot;0&quot; &amp; personas == &quot;si&quot;, &quot;1&quot;, greenpoint)) greenpoint: The house is reported as censused on the point map Analyzing the greenpoint distribution This code calculates the distribution of greenpoint status among households. It groups the data by ‘greenpoint’ status, counts the number of households in each category, and computes the percentage distribution. The results provide insights into the prevalence of greenpoint status among the census data. greenpoint_distribution &lt;- censo1 %&gt;% group_by(greenpoint) %&gt;% tally() %&gt;% # Counting households with and without greenpoint mutate(percentage = 100 * n / sum(n)) # Calculating the percentage of each category greenpoint_distribution greenpoint n percentage 0 471456 27.0448 1 1053477 60.4321 NA 218308 12.5231 Summarizing household characteristics by greenpoint status This code block summarizes household characteristics based on their greenpoint status. It calculates minimum and maximum numbers of residents in households, counts missing values for the total number of residents, and provides the total count of households for each greenpoint category. household_summary &lt;- censo1 %&gt;% group_by(greenpoint) %&gt;% summarise(min = min(H01A_TOTAL_PERSONAS), # Minimum number of residents in households max = max(H01A_TOTAL_PERSONAS), # Maximum number of residents in households num_na = sum(is.na(H01A_TOTAL_PERSONAS)), # Number of missing values for the total number of residents total = n()) # Total number of households household_summary greenpoint min max num_na total 0 0 0 0 471456 1 0 261 0 1053477 NA NA NA 218308 218308 Creating a contingency table for occupancy and greenpoint status Here, a contingency table is generated to explore the relationship between occupancy and greenpoint status. The table cross-tabulates the ‘V02_OCUPACION_VIVIENDA’ column (occupancy) with the ‘greenpoint’ column, accounting for missing values as well. This provides a visual representation of how these two variables are distributed among households. occupancy_greenpoint_table &lt;- table(censo1$V02_OCUPACION_VIVIENDA, censo1$greenpoint, useNA = &quot;a&quot;) occupancy_greenpoint_table 0 1 NA 1 0 772625 0 2 471456 3853 0 3 0 92465 0 4 0 31187 0 5 0 52463 0 6 0 23845 0 7 0 2168 0 8 0 74871 0 9 0 0 218308 NA 0 0 0 Applying the Second Filter and Refinement Continuing with the refinement process, the next filter is applied to further categorize households based on additional criteria. censo2 &lt;- censo1 %&gt;% mutate(greenpoint2 = case_when( H01A_TOTAL_PERSONAS &gt; 0 ~ &quot;Censado con informacion n&gt;0&quot;, RESUL_ENTREVISTA_VIV %in% c(1) &amp; H01A_TOTAL_PERSONAS == 0 ~ &quot;Censado con informacion n=0&quot;, RESUL_ENTREVISTA_VIV %in% c(3,4) ~ &quot;Sin informacion pero n&gt;0&quot;, is.na(greenpoint) &amp; is.na(personas) ~ &quot;Sin informacion pero n&gt;=0&quot;, V02_OCUPACION_VIVIENDA == &quot;8&quot; ~ &quot;Sin informacion pero n&gt;=0&quot;, TRUE ~ &quot;Resto&quot; )) We introduce the “greenpoint2” status to further categorize households based on various conditions. This is based on a combination of factors such as the number of residents, interview outcomes, and housing occupation. Each household is assigned to a specific category such as “Censado con informacion n&gt;0”, “Censado con informacion n=0”, and “Sin informacion pero n&gt;0”, among others. This provides a more detailed way to describe the status of households based on different criteria. readRDS(&quot;Recursos/02_Census_Filters/RecurseBooks/census2.rds&quot;) %&gt;% head(10) %&gt;% tba() 3.2.2 Applying the second filter: WorldPop criterion Starting from step 1, we also include all households with the WorldPop variable (WP) that are within 1 standard deviation from its average value. However, if these households have zero residents in the variable of interest, we mark that variable as “Not Available” (NA). Calculate summary statistics for the ‘wpop_sum’ variable Firstly, we calculate summary statistics for the ‘wpop_sum’ variable, which is a covariate related to WorldPop. The summary statistics include the mean, standard deviation, minimum, and maximum values of ‘wpop_sum’. These statistics help us establish the thresholds for the filter and are saved in a summary file. wpop_summary &lt;- censo2 %&gt;% distinct(UGM_ID,wpop_sum) %&gt;% summarise(media = mean(wpop_sum), # Mean value of &#39;wpop_sum&#39; sd = sd(wpop_sum), # Standard deviation of &#39;wpop_sum&#39; min = min(wpop_sum), # Minimum value of &#39;wpop_sum&#39; max = max(wpop_sum)) # Maximum value of &#39;wpop_sum&#39; wpop_summary media sd min max 96.9652 143.1986 0 6214.269 Calculation of Lower and Upper Thresholds We use the summary statistics to calculate the lower and upper thresholds based on one standard deviation from the mean. These thresholds will help us identify households that meet the criteria of the second filter. # Calculate the lower and upper thresholds based on one standard deviation from the mean li &lt;- 96.96515 - 143.1986 * 1 # Lower threshold ls &lt;- 96.96515 + 143.1986 * 1 # Upper threshold We identify and count households that meet the criteria of the second filter. We focus on households with zero residents (‘H01A_TOTAL_PERSONAS’) but have ‘wpop_sum’ values outside the calculated threshold. We perform this count and group it by the ‘V02_OCUPACION_VIVIENDA’ variable. # Identify and count households that meet the criteria for the second filter filter_2_counts &lt;- censo2 %&gt;% filter(H01A_TOTAL_PERSONAS == 0, wpop_sum &gt; ls | wpop_sum &lt; li) %&gt;% group_by(V02_OCUPACION_VIVIENDA) %&gt;% summarise(n = n()) filter_2_counts V02_OCUPACION_VIVIENDA n 2 129652 3 22968 4 8210 5 10514 6 4635 7 532 8 17160 Application of the Second Filter and Column Updates We apply the second filter to households and update the ‘greenpoint2’ and ‘Filtros’ columns accordingly. The ‘greenpoint2’ column is updated to reflect the new classification based on the WorldPop Criterion, while the ‘Filtros’ column indicates the application of the WorldPop Criterion or is set as NA as appropriate. # Apply the second filter and update &#39;greenpoint2&#39; and &#39;Filtros&#39; columns censo3 &lt;- censo2 %&gt;% mutate( greenpoint2 = case_when( H01A_TOTAL_PERSONAS == 0 &amp; (wpop_sum &gt; ls | wpop_sum &lt; li) ~ &quot;Sin informacion pero n&gt;=0&quot;, TRUE ~ greenpoint2 ), Filtros = case_when( H01A_TOTAL_PERSONAS == 0 &amp; (wpop_sum &gt; ls | wpop_sum &lt; li) ~ &quot;Criterio WorldPop&quot;, TRUE ~ NA_character_ ) ) un_ID PROV_ID CANT_ID DIST_ID UGM_ID LLAVEV RESUL_ENTREVISTA_VIV TIPO_VIVIENDA_PRECENSO V01_TIPO_VIVIENDA V02_OCUPACION_VIVIENDA H01A_TOTAL_PERSONAS greenpoint ugm_viviendas_totales_censo ugm_viviendas_ocupadas_censo ugm_viviendas_desocupadas_censo ugm_peligrosidad ugm_problema_de_acceso ugm_riesgos_amenazas ugm_cobertura_telecomunicaciones asent ppp_CRI_v2 elev indig aprot dist_permisos_de_construccion_2011_2022 dist_poblacion_proyeccion_ajustada_2022 dist_poblacion_ccss_abril_2023 dist_matricula_educacion_primaria_2021 dist_codigo_urbanidad GHS_BUILT_S_E2020_GLOBE_R2023A_5367_CRI urban_coverfraction crops_coverfraction ebais_tt escu_tt igl_tt prov_nl_mean cant_nl_mean dist_nl_mean wpop_sum HOMBRES_GRUPO1_sum HOMBRES_GRUPO2_sum HOMBRES_GRUPO3_sum HOMBRES_GRUPO4_sum HOMBRES_GRUPO5_sum HOMBRES_GRUPO6_sum HOMBRES_GRUPO7_sum HOMBRES_GRUPO8_sum HOMBRES_GRUPO9_sum HOMBRES_GRUPO10_sum HOMBRES_GRUPO11_sum HOMBRES_GRUPO12_sum HOMBRES_GRUPO13_sum HOMBRES_GRUPO14_sum HOMBRES_GRUPO15_sum HOMBRES_GRUPO16_sum HOMBRES_GRUPO17_sum HOMBRES_GRUPO18_sum HOMBRES_GRUPO19_sum HOMBRES_GRUPO20_sum MUJERES_GRUPO1_sum MUJERES_GRUPO2_sum MUJERES_GRUPO3_sum MUJERES_GRUPO4_sum MUJERES_GRUPO5_sum MUJERES_GRUPO6_sum MUJERES_GRUPO7_sum MUJERES_GRUPO8_sum MUJERES_GRUPO9_sum MUJERES_GRUPO10_sum MUJERES_GRUPO11_sum MUJERES_GRUPO12_sum MUJERES_GRUPO13_sum MUJERES_GRUPO14_sum MUJERES_GRUPO15_sum MUJERES_GRUPO16_sum MUJERES_GRUPO17_sum MUJERES_GRUPO18_sum MUJERES_GRUPO19_sum MUJERES_GRUPO20_sum personas greenpoint2 Filtros 0218491 1 101 10101 10101001 10101001001001 3 VIVIENDA EN APARTAMENT 01 2 0 0 0 0 0 2 2 2 1 0 17.4872 1157.488 0 0 413 3233 14597 1374 1 3773 100 0 44.0027 0 0.9933 10.802 62.9502 63 34.5930 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 no Sin informacion pero n&gt;0 NA 0141265 1 101 10101 10101002 10101001002001 1 VIVIENDA EN APARTAMENT 01 1 6 1 2 2 0 2 2 2 1 0 17.5313 1156.738 0 0 413 3233 14597 1374 1 4907 100 0 44.0000 0 0.0000 10.802 62.9502 63 9.4928 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 2 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 si Censado con informacion n&gt;0 NA 0151378 1 101 10101 10101002 10101001002002 1 VIVIENDA INDEPENDIENTE 01 1 3 1 2 2 0 2 2 2 1 0 17.5313 1158.038 0 0 413 3233 14597 1374 1 4907 100 0 44.9932 0 0.0000 10.802 62.9502 63 9.4928 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 si Censado con informacion n&gt;0 NA 0218056 1 101 10101 10101003 10101001003006 3 00VIVIENDA EN EDIFICIO 01 2 0 0 5 0 5 2 2 2 1 0 15.9573 1152.401 0 0 413 3233 14597 1374 1 4794 100 0 44.9932 0 0.0000 10.802 62.9502 63 13.1767 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 no Sin informacion pero n&gt;0 NA 0217145 1 101 10101 10101003 10101001003005 1 VIVIENDA INDEPENDIENTE 09 3 0 1 5 0 5 2 2 2 1 0 15.9573 1156.873 0 0 413 3233 14597 1374 1 4794 100 0 45.0000 0 0.9960 10.802 62.9502 63 13.1767 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 no Censado con informacion n=0 NA 0216224 1 101 10101 10101003 10101001003003 1 VIVIENDA INDEPENDIENTE 01 3 0 1 5 0 5 2 2 2 1 0 15.8496 1157.138 0 0 413 3233 14597 1374 1 3604 100 0 44.0027 0 0.9933 10.802 62.9502 63 13.1767 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 no Censado con informacion n=0 NA 0215255 1 101 10101 10101003 10101001003001 1 VIVIENDA EN APARTAMENT 01 3 0 1 5 0 5 2 2 2 1 0 15.8496 1157.801 0 0 413 3233 14597 1374 1 4794 100 0 44.0027 0 1.0000 10.802 62.9502 63 13.1767 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 no Censado con informacion n=0 NA 0215972 1 101 10101 10101003 10101001003002 1 VIVIENDA INDEPENDIENTE 01 3 0 1 5 0 5 2 2 2 1 0 15.8496 1157.138 0 0 413 3233 14597 1374 1 3604 100 0 44.0027 0 0.9933 10.802 62.9502 63 13.1767 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 no Censado con informacion n=0 NA 0216229 1 101 10101 10101003 10101001003004 1 VIVIENDA INDEPENDIENTE 01 3 0 1 5 0 5 2 2 2 1 0 15.8496 1157.138 0 0 413 3233 14597 1374 1 3604 100 0 44.0027 0 0.9933 10.802 62.9502 63 13.1767 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 no Censado con informacion n=0 NA 0925743 1 101 10101 10101004 10101001004002 3 VIVIENDA INDEPENDIENTE 04 2 0 0 1 0 1 2 2 2 1 0 17.4872 1158.147 0 0 413 3233 14597 1374 1 3773 100 0 44.0000 0 0.0027 10.802 62.9502 63 13.6008 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 no Sin informacion pero n&gt;0 NA Summary of Data Based on ‘greenpoint2’ We summarize the data based on the updated ‘greenpoint2’ variable. We calculate the distribution and percentages of households in each ‘greenpoint2’ category. These summaries help us understand the impact of the filter on household classification. # Summarizing the data based on the &#39;greenpoint2&#39; variable summary_greenpoint2 &lt;- censo3 %&gt;% group_by(greenpoint2) %&gt;% tally() %&gt;% mutate(percentage = 100 * n / sum(n)) summary_greenpoint2 greenpoint2 n percentage Censado con informacion n=0 175921 10.0916 Censado con informacion n&gt;0 776478 44.5422 Sin informacion pero n&gt;0 285810 16.3953 Sin informacion pero n&gt;=0 505032 28.9709 Summary of Data Based on ‘greenpoint2’ and ‘Filtros’ We generate an additional summary that considers the combination of the ‘greenpoint2’ and ‘Filtros’ variables. This provides more detailed information on how the WorldPop Criterion affects the existing categories. # Summarizing the data based on the combination of &#39;greenpoint2&#39; and &#39;Filtros&#39; variables summary_greenpoint2_filtros &lt;- censo3 %&gt;% group_by(greenpoint2, Filtros) %&gt;% tally() %&gt;% mutate(percentage = 100 * n / sum(n)) summary_greenpoint2_filtros greenpoint2 Filtros n percentage Censado con informacion n=0 Entrevista igual a 1 y Número de personas igual a 0 175921 10.0916 Censado con informacion n&gt;0 Número de personas mayor a 0 776478 44.5422 Sin informacion pero n&gt;0 Entrevista es 3 o 4 285810 16.3953 Sin informacion pero n&gt;=0 Criterio WorldPop 135370 7.7654 Sin informacion pero n&gt;=0 Fuera de periodo(20 días) 151354 8.6823 Sin informacion pero n&gt;=0 Sin conteo de personas 218308 12.5231 3.2.3 Summary of Statistics Based on ‘greenpoint2’ We calculate additional statistics for the ‘greenpoint2’ categories. These statistics include the minimum, maximum, number of missing values, and the total number of households in each category. This data is essential for understanding the distribution of residents in the filtered households. Each of these stages contributes to the process of applying the second filter and refining census data based on the WorldPop Criterion. The generated summaries and data are useful for further analysis and are saved for future reference. # Summarizing the data for &#39;greenpoint2&#39; variable summary_greenpoint2_stats &lt;- censo3 %&gt;% group_by(greenpoint2) %&gt;% summarise(min = min(H01A_TOTAL_PERSONAS), max = max(H01A_TOTAL_PERSONAS), num_na = sum(is.na(H01A_TOTAL_PERSONAS)), total = n()) summary_greenpoint2_stats greenpoint2 min max num_na total Censado con informacion n=0 0 0 0 212980 Censado con informacion n&gt;0 1 261 0 776478 Sin informacion pero n&gt;0 0 0 0 341804 Sin informacion pero n&gt;=0 NA NA 218308 411979 3.2.4 Defining the Third Filter In this section, we introduce the implementation of the third filter, building upon the foundation laid by Filters 1 and 2. The third filter addresses households within UGMs that were surveyed after an interval greater than 20 days, and despite being classified as unoccupied, there is a lack of certainty regarding their occupancy status. These households are reclassified as having an unknown status. Reading the ‘Desocupadas fuera periodo.xlsx’ File We start by reading the ‘Desocupadas fuera periodo.xlsx’ file to gather information about households that were vacant but visited outside the standard interval. We specifically extract the ‘UGM_ID’ column for further analysis. # Reading the &#39;Desocupadas fuera periodo.xlsx&#39; file and selecting the UGM_ID column upms_reporte &lt;- openxlsx::read.xlsx( xlsxFile = &quot;Recursos/02_Census_Filters/Data/Desocupadas fuera periodo.xlsx&quot;) %&gt;% select(UGM_ID = ID_UGM) Applying Filters Based on ‘upms_reporte’ and Specific Conditions Using the gathered information from ‘upms_reporte’ and considering certain conditions, we apply additional filters to the existing data. We update the ‘greenpoint2’ and ‘Filtros’ columns based on the specified criteria. # Creating &#39;censo4&#39; by applying filters based on &#39;upms_reporte&#39; and specific conditions censo4 &lt;- censo3 %&gt;% mutate( greenpoint2 = case_when( UGM_ID %in% upms_reporte$UGM_ID &amp; H01A_TOTAL_PERSONAS == 0 ~ &quot;Sin informacion pero n&gt;=0&quot;, TRUE ~ greenpoint2 ), Filtros = case_when( UGM_ID %in% upms_reporte$UGM_ID &amp; H01A_TOTAL_PERSONAS == 0 ~ &quot;Fuera de periodo(20 días)&quot;, TRUE ~ Filtros ) ) Applying Additional Filters and Creating ‘Filtros’ Values We proceed by further refining the data by applying additional filters. The ‘Filtros’ values are updated based on various conditions such as the number of residents, the result of the interview (‘RESUL_ENTREVISTA_VIV’), and the occupation of the dwelling (‘V02_OCUPACION_VIVIENDA’). # Applying additional filters and creating &#39;Filtros&#39; values censo4 %&lt;&gt;% mutate(Filtros = case_when( is.na(Filtros) &amp; H01A_TOTAL_PERSONAS &gt; 0 ~ &quot;Número de personas mayor a 0&quot;, is.na(Filtros) &amp; RESUL_ENTREVISTA_VIV %in% c(1) &amp; H01A_TOTAL_PERSONAS == 0 ~ &quot;Entrevista igual a 1 y Número de personas igual a 0&quot;, is.na(Filtros) &amp; RESUL_ENTREVISTA_VIV %in% c(3,4) ~ &quot;Entrevista es 3 o 4&quot;, is.na(Filtros) &amp; is.na(greenpoint) &amp; is.na(personas) ~ &quot;Sin conteo de personas&quot;, is.na(Filtros) &amp; V02_OCUPACION_VIVIENDA == &quot;8&quot; ~ &quot;Ocupación de la vivienda es 8&quot;, TRUE ~ Filtros )) Summarizing Data Based on ‘greenpoint2’ and ‘Filtros’ Variables We generate a summary of the data based on the updated ‘greenpoint2’ and ‘Filtros’ variables. The summary provides insights into the distribution of households across different categories. # Summarizing data based on &#39;greenpoint2&#39; and &#39;Filtros&#39; variables summary_greenpoint2_filtros &lt;- censo4 %&gt;% group_by(greenpoint2, Filtros) %&gt;% tally() %&gt;% ungroup() %&gt;% mutate(percentage = 100 * n / sum(n)) greenpoint2 Filtros n percentage Censado con informacion n=0 Entrevista igual a 1 y Número de personas igual a 0 175921 10.0916 Censado con informacion n&gt;0 Número de personas mayor a 0 776478 44.5422 Sin informacion pero n&gt;0 Entrevista es 3 o 4 285810 16.3953 Sin informacion pero n&gt;=0 Criterio WorldPop 135370 7.7654 Sin informacion pero n&gt;=0 Fuera de periodo(20 días) 151354 8.6823 Sin informacion pero n&gt;=0 Sin conteo de personas 218308 12.5231 Summarizing Data Based on ‘greenpoint2’ Variable Similarly, we create another summary of the data, this time focusing solely on the ‘greenpoint2’ variable. This summary helps us understand the impact of the third filter on the classification of households. # Summarizing data based on &#39;greenpoint2&#39; variable summary_greenpoint2 &lt;- censo4 %&gt;% group_by(greenpoint2) %&gt;% tally() %&gt;% mutate(percentage = 100 * n / sum(n)) greenpoint2 n percentage Censado con informacion n=0 175921 10.0916 Censado con informacion n&gt;0 776478 44.5422 Sin informacion pero n&gt;0 285810 16.3953 Sin informacion pero n&gt;=0 505032 28.9709 3.2.5 Combining non-coordinated houses Selecting non-coordinated houses from the ‘censo_sexo_edad’ dataset and inner joining with ‘Viviendas_sin_coordenadas’ # Filtering non-coordinated houses from &#39;censo_sexo_edad&#39; dataset Viviendas_sin_coordenadas2 &lt;- censo_sexo_edad %&gt;% filter(is.na(un_ID)) %&gt;% inner_join(Viviendas_sin_coordenadas) %&gt;% # Adding a unique identifier &#39;un_ID&#39; to the newly joined houses mutate(un_ID = paste0(&quot;A&quot;, 1:n())) # Adding the newly joined houses to the &#39;censo4&#39; dataset censo4 &lt;- bind_rows(censo4, Viviendas_sin_coordenadas2) # Modifying &#39;Filtros&#39; column based on &#39;greenpoint2&#39; values censo4 %&lt;&gt;% mutate(Filtros = ifelse(is.na(greenpoint2), &quot;Censado en papel&quot;, greenpoint2)) # Modifying &#39;greenpoint2&#39; column based on conditions censo4 %&lt;&gt;% mutate(greenpoint2 = case_when( Filtros == &quot;Censado en papel&quot; &amp; H01A_TOTAL_PERSONAS == 0 ~ &quot;Papel n=0&quot;, Filtros == &quot;Censado en papel&quot; &amp; H01A_TOTAL_PERSONAS &gt; 0 ~ &quot;Papel n&gt;0&quot;, TRUE ~greenpoint2 )) 3.2.6 Aggregating statistics and summaries # Summarizing statistics for the &#39;censo4&#39; dataset based on &#39;greenpoint2&#39; column summary1 &lt;- censo4 %&gt;% group_by(greenpoint2) %&gt;% summarise(min = min(H01A_TOTAL_PERSONAS), max = max(H01A_TOTAL_PERSONAS), num_na = sum(is.na(H01A_TOTAL_PERSONAS)), total = n()) greenpoint2 min max num_na total Censado con informacion n=0 0 0 0 175921 Censado con informacion n&gt;0 1 261 0 776478 Sin informacion pero n&gt;0 0 0 0 285810 Sin informacion pero n&gt;=0 NA NA 218308 505032 Summarizing statistics for the ‘censo4’ dataset based on ‘greenpoint2’ and ‘Filtros’ columns summary2 &lt;- censo4 %&gt;% group_by(greenpoint2, Filtros) %&gt;% summarise(min = min(H01A_TOTAL_PERSONAS), max = max(H01A_TOTAL_PERSONAS), num_na = sum(is.na(H01A_TOTAL_PERSONAS)), total = n()) greenpoint2 Filtros min max num_na total Censado con informacion n=0 Entrevista igual a 1 y Número de personas igual a 0 0 0 0 175921 Censado con informacion n&gt;0 Número de personas mayor a 0 1 261 0 776478 Sin informacion pero n&gt;0 Entrevista es 3 o 4 0 0 0 285810 Sin informacion pero n&gt;=0 Criterio WorldPop 0 0 0 135370 Sin informacion pero n&gt;=0 Fuera de periodo(20 días) 0 0 0 151354 Sin informacion pero n&gt;=0 Sin conteo de personas NA NA 218308 218308 Summarizing statistics for the ‘censo4’ dataset based on ‘greenpoint2’ and ‘Filtros’ columns summary3 &lt;- censo4 %&gt;% group_by(greenpoint2, Filtros) %&gt;% summarise(total = n(), nas = sum(is.na(H01A_TOTAL_PERSONAS))) greenpoint2 Filtros total nas Censado con informacion n=0 Entrevista igual a 1 y Número de personas igual a 0 175921 0 Censado con informacion n&gt;0 Número de personas mayor a 0 776478 0 Sin informacion pero n&gt;0 Entrevista es 3 o 4 285810 0 Sin informacion pero n&gt;=0 Criterio WorldPop 135370 0 Sin informacion pero n&gt;=0 Fuera de periodo(20 días) 151354 0 Sin informacion pero n&gt;=0 Sin conteo de personas 218308 218308 Counting occurrences of ‘un_ID’ and filtering for duplicates duplicated_un_ID &lt;- censo4 %&gt;% group_by(un_ID) %&gt;% tally() %&gt;% filter(n &gt; 1) duplicated_un_ID 3.2.7 Extracting and Saving Subset # Selecting columns from &#39;censo4&#39; that match &#39;Nombre_Columna&#39; and contain &#39;GRUPO&#39; paso &lt;- censo4 %&gt;% select( all_of(Nombre_Columna), matches(&quot;GRUPO&quot;) ) # Saving the &#39;paso&#39; dataset as an RDS file in the specified directory saveRDS(paso, file = &quot;Recursos/02_Census_Filters/data/censo_viviendas.rds&quot;) "],["standardization-and-validation-of-covariates.html", "Chapter 4 Standardization and validation of covariates", " Chapter 4 Standardization and validation of covariates Similarly, just as the census variables underwent a validation process, the covariates dataset is subject to a similar procedure. This involves ensuring uniformity in the length of identifiers such as UGM, Cantos, regions, etc. Additionally, a validation is conducted to identify any missing values (NAs) in the dataset. Following this, a descriptive analysis is performed on the data. "],["environment-preparation-and-library-loading.html", "4.1 Environment Preparation and Library Loading", " 4.1 Environment Preparation and Library Loading This code is responsible for reviewing and improving the data we have. First, it clears anything we have in memory. Then, it loads some special tools that we are going to use. After that, it reads information about the census and geographic areas. # Clear the workspace by removing all variables rm(list = ls()) ################# ### Libraries ### ################# # Load required libraries library(tidyverse) # For data manipulation and visualization library(data.table) # For efficient data manipulation library(openxlsx) # For reading Excel files library(magrittr) # For data handling operations # Clear the console cat(&quot;\\f&quot;) ## Reading census data. # Load the &#39;censo_viviendas.rds&#39; file containing census data censo1 &lt;- readRDS(&quot;Recursos/03_Input_Validation_Cov/Data/censo_viviendas.rds&quot;) ## Reading UGMS bases. # Load the &#39;ugm_merged.rds&#39; file containing UGMS base data Base_ugms &lt;- readRDS(&quot;Recursos/03_Input_Validation_Cov/Data/ugm_merged.rds&quot;) # Count distinct UGM_ID values in census data n_distinct(censo1$UGM_ID) ## [1] 48060 #48060 # Count distinct UGM_ID values in UGMS base data n_distinct(Base_ugms$UGM_ID) # Not all UGMs have houses ## [1] 50760 #50760 "],["descriptive-values-of-the-ugms-base.html", "4.2 Descriptive values of the UGMS base", " 4.2 Descriptive values of the UGMS base We begin by creating a summary dataframe that includes the column names and their corresponding data types. Subsequently, we enhance this summary by adding a column indicating the data type of each column, achieved through the use of the map_chr function on the column names and their corresponding data. # Create a summary dataframe with column names and their data types resumen &lt;- data.frame(Nombre_Columna = names(Base_ugms)) resumen %&lt;&gt;% mutate(tipo = map_chr(Nombre_Columna, function(x)class(Base_ugms[[x]]))) Numeric Variables # Calculate maximum values for numeric and integer columns max_values &lt;- Base_ugms %&gt;% summarise(across(where(is.numeric) | where(is.integer), max)) %&gt;% pivot_longer(everything(), names_to = &quot;Nombre_Columna&quot;, values_to = &quot;Valor_Maximo&quot;) # Calculate minimum values for numeric and integer columns min_values &lt;- Base_ugms %&gt;% summarise(across(where(is.numeric) | where(is.integer), min)) %&gt;% pivot_longer(everything(), names_to = &quot;Nombre_Columna&quot;, values_to = &quot;Valor_Minimo&quot;) # Calculate mean values for numeric and integer columns media_values &lt;- Base_ugms %&gt;% summarise(across(where(is.numeric) | where(is.integer), mean)) %&gt;% pivot_longer(everything(), names_to = &quot;Nombre_Columna&quot;, values_to = &quot;Valor_Media&quot;) # Calculate median values for numeric and integer columns mediana_values &lt;- Base_ugms %&gt;% summarise(across(where(is.numeric) | where(is.integer), median)) %&gt;% pivot_longer(everything(), names_to = &quot;Nombre_Columna&quot;, values_to = &quot;Valor_Mediana&quot;) # Calculate standard deviation values for numeric and integer columns SD_values &lt;- Base_ugms %&gt;% summarise(across(where(is.numeric) | where(is.integer), sd)) %&gt;% pivot_longer(everything(), names_to = &quot;Nombre_Columna&quot;, values_to = &quot;Valor_sd&quot;) # Calculate the number of missing values for numeric and integer columns nas_values &lt;- Base_ugms %&gt;% summarise(across(where(is.numeric) | where(is.integer), function(x)sum(is.na(x)))) %&gt;% pivot_longer(everything(), names_to = &quot;Nombre_Columna&quot;, values_to = &quot;Num_nas&quot;) Character Variables # Calculate maximum lengths of characters for character columns max_char &lt;- Base_ugms %&gt;% summarise(across(where(is.character), function(x)max(nchar(x)))) %&gt;% pivot_longer(everything(), names_to = &quot;Nombre_Columna&quot;, values_to = &quot;leng_max&quot;) # Calculate minimum lengths of characters for character columns min_char &lt;- Base_ugms %&gt;% summarise(across(where(is.character), function(x)min(nchar(x)))) %&gt;% pivot_longer(everything(), names_to = &quot;Nombre_Columna&quot;, values_to = &quot;leng_min&quot;) # Calculate the number of missing values for character columns nas_values_char &lt;- Base_ugms %&gt;% summarise(across(where(is.character) , function(x)sum(is.na(x)))) %&gt;% pivot_longer(everything(), names_to = &quot;Nombre_Columna&quot;, values_to = &quot;Num_nas_char&quot;) Organizing results in a database. # Combine all results into a single dataframe resumen2 &lt;- reduce( list( nas_values_char, min_char, max_char, nas_values, SD_values, mediana_values, media_values, min_values, max_values ), full_join, by = join_by(Nombre_Columna) ) %&gt;% full_join(x = resumen, y = ., by = join_by(Nombre_Columna)) resumen2 %&gt;% head(10) %&gt;% tba() Nombre_Columna tipo Num_nas_char leng_min leng_max Num_nas Valor_sd Valor_Mediana Valor_Media Valor_Minimo Valor_Maximo un_id integer NA NA NA 0 14653.29 25380.5 25380.5 1 50760 PROV_ID character 0 1 1 NA NA NA NA NA NA CANT_ID character 0 3 3 NA NA NA NA NA NA DIST_ID character 0 5 5 NA NA NA NA NA NA UGM_ID character 0 8 8 NA NA NA NA NA NA ugm_viviendas_totales_censo integer NA NA NA 1 NA NA NA NA NA ugm_viviendas_ocupadas_censo integer NA NA NA 1 NA NA NA NA NA ugm_viviendas_desocupadas_censo integer NA NA NA 1 NA NA NA NA NA ugm_peligrosidad numeric NA NA NA 1 NA NA NA NA NA ugm_problema_de_acceso numeric NA NA NA 1 NA NA NA NA NA Variables of interest Nombre_Columna &lt;- c( &quot;un_id&quot;, &quot;PROV_ID&quot;, &quot;CANT_ID&quot;, &quot;DIST_ID&quot;, &quot;UGM_ID&quot;, &quot;ugm_viviendas_totales_censo&quot;, &quot;ugm_viviendas_ocupadas_censo&quot;, &quot;ugm_viviendas_desocupadas_censo&quot;, &quot;ugm_peligrosidad&quot;, &quot;ugm_problema_de_acceso&quot;, &quot;ugm_riesgos_amenazas&quot;, &quot;ugm_cobertura_telecomunicaciones&quot;, &quot;ugm_area_m2&quot;, &quot;asent&quot;, &quot;ppp_CRI_v2&quot;, &quot;elev&quot;, &quot;indig&quot;, &quot;aprot&quot;, &quot;dist_permisos_de_construccion_2011_2022&quot;, &quot;dist_poblacion_proyeccion_ajustada_2022&quot;, &quot;dist_poblacion_rup&quot;, &quot;dist_poblacion_ccss_abril_2023&quot;, &quot;dist_matricula_educacion_primaria_2021&quot;, &quot;dist_matricula_educacion_secundaria_2021&quot;, &quot;dist_codigo_urbanidad&quot;, &quot;GHS_BUILT_S_E2020_GLOBE_R2023A_5367_CRI&quot;, &quot;urban_coverfraction&quot;, &quot;crops_coverfraction&quot;, &quot;ebais_tt&quot;, &quot;escu_tt&quot;, &quot;igl_tt&quot;, &quot;prov_nl_mean&quot;, &quot;cant_nl_mean&quot;, &quot;dist_nl_mean&quot;, &quot;wpop_sum&quot;, &quot;ugm_sin_info&quot;) Changing the type of variables Tipo_actualizar &lt;- c( as.character, as.character, as.character, as.character, as.character, as.numeric, as.numeric, as.numeric, as.character, as.character, as.character, as.character, as.numeric, as.character, as.numeric, as.numeric, as.character, as.character, as.numeric, as.numeric, as.numeric, as.numeric, as.numeric, as.numeric, as.character, as.numeric, as.numeric, as.numeric, as.numeric, as.numeric, as.numeric, as.numeric, as.numeric, as.numeric, as.numeric, as.character) Update column types based on Nombre_Columna and Tipo_actualizar paso &lt;- map2(Nombre_Columna, Tipo_actualizar, function(nom, tipo) { Base_ugms[[nom]] &lt;&lt;- tipo(Base_ugms[[nom]]) cat(nom, &quot;\\n&quot;) }) ## un_id ## PROV_ID ## CANT_ID ## DIST_ID ## UGM_ID ## ugm_viviendas_totales_censo ## ugm_viviendas_ocupadas_censo ## ugm_viviendas_desocupadas_censo ## ugm_peligrosidad ## ugm_problema_de_acceso ## ugm_riesgos_amenazas ## ugm_cobertura_telecomunicaciones ## ugm_area_m2 ## asent ## ppp_CRI_v2 ## elev ## indig ## aprot ## dist_permisos_de_construccion_2011_2022 ## dist_poblacion_proyeccion_ajustada_2022 ## dist_poblacion_rup ## dist_poblacion_ccss_abril_2023 ## dist_matricula_educacion_primaria_2021 ## dist_matricula_educacion_secundaria_2021 ## dist_codigo_urbanidad ## GHS_BUILT_S_E2020_GLOBE_R2023A_5367_CRI ## urban_coverfraction ## crops_coverfraction ## ebais_tt ## escu_tt ## igl_tt ## prov_nl_mean ## cant_nl_mean ## dist_nl_mean ## wpop_sum ## ugm_sin_info Create a summary dataframe with column names and their data types resumen &lt;- data.frame(Nombre_Columna = names(Base_ugms)) resumen %&lt;&gt;% mutate(tipo = map_chr(Nombre_Columna, function(x) class(Base_ugms[[x]]))) # Extract character columns tipo_char &lt;- resumen$Nombre_Columna[resumen$tipo == &quot;character&quot;] # Select and display character columns from Base_ugms Base_ugms[, tipo_char] %&gt;% head(10) %&gt;% tba() un_id PROV_ID CANT_ID DIST_ID UGM_ID ugm_peligrosidad ugm_problema_de_acceso ugm_riesgos_amenazas ugm_cobertura_telecomunicaciones asent indig aprot dist_codigo_urbanidad ugm_sin_info 1 1 101 10101 10101001 2 2 2 1 0 0 0 1 0 2 1 101 10101 10101002 2 2 2 1 0 0 0 1 0 3 1 101 10101 10101003 2 2 2 1 0 0 0 1 0 4 1 101 10101 10101004 2 2 2 1 0 0 0 1 0 5 1 101 10101 10101005 2 2 2 1 0 0 0 1 0 6 1 101 10101 10101006 2 2 2 1 0 0 0 1 0 7 1 101 10101 10101007 2 2 2 1 0 0 0 1 0 8 1 101 10101 10101008 2 2 2 1 0 0 0 1 0 9 1 101 10101 10101009 2 2 2 1 0 0 0 1 0 10 1 101 10101 10101010 2 2 2 1 0 0 0 1 0 4.2.1 Standardizing Variables and Joining Datasets # Loop through character variables for (ii in tipo_char) { max_char &lt;- max(nchar(Base_ugms[[ii]]), na.rm = TRUE) Base_ugms[[ii]] &lt;- str_pad(string = Base_ugms[[ii]], width = max_char, pad = &quot;0&quot;) } UGM_censo &lt;- censo1 %&gt;% distinct(UGM_ID) # Join the UGM_censo and Base_ugms datasets Base_ugms_censo &lt;- inner_join(UGM_censo, Base_ugms) Base_ugms_censo[, tipo_char] %&gt;% head(10) %&gt;% tba() un_id PROV_ID CANT_ID DIST_ID UGM_ID ugm_peligrosidad ugm_problema_de_acceso ugm_riesgos_amenazas ugm_cobertura_telecomunicaciones asent indig aprot dist_codigo_urbanidad ugm_sin_info 00001 1 101 10101 10101001 2 2 2 1 0 0 0 1 0 00002 1 101 10101 10101002 2 2 2 1 0 0 0 1 0 00003 1 101 10101 10101003 2 2 2 1 0 0 0 1 0 00004 1 101 10101 10101004 2 2 2 1 0 0 0 1 0 00006 1 101 10101 10101006 2 2 2 1 0 0 0 1 0 00007 1 101 10101 10101007 2 2 2 1 0 0 0 1 0 00008 1 101 10101 10101008 2 2 2 1 0 0 0 1 0 00009 1 101 10101 10101009 2 2 2 1 0 0 0 1 0 00010 1 101 10101 10101010 2 2 2 1 0 0 0 1 0 00011 1 101 10101 10101011 2 2 2 1 0 0 0 1 0 Calculate the counts of missing # Calculate the counts of missing values for numeric variables nas_values &lt;- Base_ugms_censo %&gt;% summarise(across(where(is.numeric) | where(is.integer), function(x) sum(is.na(x)))) %&gt;% pivot_longer(everything(), names_to = &quot;Nombre_Columna&quot;, values_to = &quot;Num_nas&quot;) # Calculate the counts of missing values for character variables nas_values2 &lt;- Base_ugms_censo %&gt;% summarise(across(where(is.character), function(x) sum(is.na(x)))) %&gt;% pivot_longer(everything(), names_to = &quot;Nombre_Columna&quot;, values_to = &quot;Num_nas&quot;) Remove specific columns from the dataset Base_ugms_censo$dist_poblacion_rup &lt;- NULL Base_ugms_censo$dist_matricula_educacion_secundaria_2021 &lt;- NULL 4.2.2 Standardize numeric variables using z-score scaling Base_ugms_censo &lt;- Base_ugms_censo %&gt;% mutate_if(is.numeric, function(x) as.numeric(scale(x))) Save the standardized dataset saveRDS(Base_ugms_censo, &quot;Recursos/03_Input_Validation_Cov/Data/Base_ugms_estandarizada.rds&quot;) "]]
